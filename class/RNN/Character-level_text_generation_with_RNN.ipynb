{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/RNN/Character-level_text_generation_with_RNN.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Character-level_text_generation_with_RNN.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xyQAB371QNRK"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAKzQV3UQNRK"
   },
   "source": [
    "### Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "r9U1NwwiGao5"
   },
   "outputs": [],
   "source": [
    "## download the dataser\n",
    "# quijote : https://www.gutenberg.org/files/2000/2000-0.txt\n",
    "'''path = keras.utils.get_file(\n",
    "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    ")'''\n",
    "path = keras.utils.get_file(\n",
    "    \"quijote_spanish.txt\", origin=\"https://www.gutenberg.org/files/2000/2000-0.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEZ6FnzjGao5",
    "outputId": "448d833f-ec3d-4037-c2f8-6566bfbfdd49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 2090426\n",
      "corpus words: 351160\n"
     ]
    }
   ],
   "source": [
    "text = open(path).read().lower()\n",
    "## don quijote\n",
    "text = text[39972:]\n",
    "print('corpus length:', len(text))\n",
    "print('corpus words:', len(text.split(' ')))\n",
    "# text = text[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-GgVsFIGao6",
    "outputId": "74d520ca-a658-410e-8180-5c221b0ef072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processed texts:\n",
      "\n",
      "en un lugar de la mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor. una olla de algo más v\n"
     ]
    }
   ],
   "source": [
    "# print the firsts characters\n",
    "#print(text[:200])\n",
    "# remove newlines chars \n",
    "text = text.replace(\"\\n\", \" \").replace(\"  \", \" \").strip()  \n",
    "print()\n",
    "print('processed texts:')\n",
    "print()\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OORRPlvDGao6"
   },
   "source": [
    "### Text simple processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcX2QPi-Gao6",
    "outputId": "64eb80c2-16ed-4003-f88a-928952a77b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 69\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(\"Total chars:\", len(chars))\n",
    "\n",
    "char_indices = {c:i for i, c in enumerate(chars)}\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9AgEunWGao7",
    "outputId": "6162ef23-99ca-453c-9d22-7803c6f1a30a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent characters: [(' ', 382810), ('e', 221073), ('a', 192139), ('o', 152804), ('s', 125010), ('n', 108122), ('r', 100824), ('l', 88474), ('d', 86723), ('u', 77776)]\n",
      "less frequent characters: [('4', 9), ('8', 9), ('9', 9), ('ï', 4), ('ù', 2), ('$', 2), (']', 1), ('à', 1), ('%', 1), ('@', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "char_counts = Counter(text)\n",
    "char_counts_sort = [\n",
    "    (ch, count)\n",
    "    for ch, count in sorted(char_counts.items(), key=lambda x: -x[1])\n",
    "]\n",
    "print('Most frequent characters:', char_counts_sort[:10])\n",
    "print('less frequent characters:', char_counts_sort[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2ojq9NrGao7",
    "outputId": "b35f705d-4bde-478c-aa35-6296caf5d885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "max_chars = 35\n",
    "## We replace the less used characters with unknown_char\n",
    "unknown_char = 'ò'\n",
    "\n",
    "chars = {ch for ch,count in char_counts_sort[:max_chars-1]}\n",
    "print(unknown_char in chars)\n",
    "char_indices = {c:i+1 for i, c in enumerate(chars)}\n",
    "char_indices[unknown_char] = 0\n",
    "indices_char = {i:c for c,i in char_indices.items()}\n",
    "chars.add(unknown_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GXDImInIGao8"
   },
   "outputs": [],
   "source": [
    "# reduce the size\n",
    "text = text[:200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isL_xU24Gao8"
   },
   "source": [
    "Next we generate the input and output arrays:\n",
    "\n",
    "The input will consist on sentences of a fixed (maxlen) lenght, while the outputs will be the next characters in the text.\n",
    "\n",
    "So, if the text is \"Welcome to deep learning course\" with maxlen = 5, we will have:\n",
    "\n",
    "Input = [ w, e, l, c, o, e, l, c, o, m, l, c, o, m, e, ... ] Output = [ m, e, , ... ]\n",
    "In order to avoid overfitting (and improve performances) we can add a step to the structure so that with step = 3, for example:\n",
    "\n",
    "Input = [ w, e, l, c, o, c, o, m, e, , m, e, , t, o, ... ] Output = [ m, t, , ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZHBgup2QNRL",
    "outputId": "b421d805-ea95-416c-d296-383e4ba931a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 66654\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3kMTe-RGao8",
    "outputId": "0f90ef0e-966d-4a65-93ff-9d6db187ec31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en un lugar de la mancha, de cuyo nombre',\n",
       " 'un lugar de la mancha, de cuyo nombre no',\n",
       " 'lugar de la mancha, de cuyo nombre no qu',\n",
       " 'ar de la mancha, de cuyo nombre no quier',\n",
       " 'de la mancha, de cuyo nombre no quiero a',\n",
       " 'la mancha, de cuyo nombre no quiero acor']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moytr1PBGao9",
    "outputId": "705c363c-0853-439d-8d24-ff0d42776002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ', 'i', 'o', 'c', 'd']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3V4GaHYcGao9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66654, 40, 60) (66654,)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros(len(sentences), dtype=np.int32)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices.get(char, 0)] = 1\n",
    "    y[i] = char_indices.get(next_chars[i], 0)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXRHOB50QNRL"
   },
   "source": [
    "## Build the model: a single LSTM layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wUd7xS1PQNRL"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(len(chars), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Xgj88iRAGao9"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=0.2):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vkJoOcL9Gao-",
    "outputId": "b5c91c74-a2ef-4b7c-8ad9-7ac80c7bb2ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 53s 185ms/step - loss: 3.1277 - accuracy: 0.1772\n",
      "\n",
      "Generating text after epoch: 1\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"como agraviado, no es bien que vos cumpl\"\n",
      "...Generated:   o  e s  e lo  e  e no  ee ee e  e se eo le de ce  e  es e  e  e  e  e  e  e  e lo ce se  e  e  e le  e se le  e  e de co  e  e  e  o se  e de  e  e  \n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"como agraviado, no es bien que vos cumpl\"\n",
      "...Generated:   ee e s te  ee  o  e  e s se re  a o e no  es ce  oo so la o n co eo e a ce ai a de no se  s  e —tra le nic se yaeon le dele e ens e bae aon  iec ee c\n",
      "\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \"como agraviado, no es bien que vos cumpl\"\n",
      "...Generated:  oi lerefanpn y,n se ca  aell, leídioetal —en soets ymms neq a qt cetiñd,e.a re ,i sislee aeoers ue cj moíeveraeie ?y meame .bp, etía dúdar5mil eha  an\n",
      "\n",
      "261/261 [==============================] - 50s 194ms/step - loss: 2.3912 - accuracy: 0.3093\n",
      "\n",
      "Generating text after epoch: 2\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"me a mí desde aquí a algún castillo dond\"\n",
      "...Generated:  e de de cor a con an es que de de se lo co can en es se po can an en en an en en en an en en ar sue cas le as cos al de pan de de la que por de de  en\n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"me a mí desde aquí a algún castillo dond\"\n",
      "...Generated:  o del ar que es cero ven se ho lan te cuse ciabla  al lo to han pes cunta  ue aua que pa eo coro tilos ma di ento po ces sa sense cos a sos le as de p\n",
      "\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \"me a mí desde aquí a algún castillo dond\"\n",
      "...Generated:  e, de lía só y a da¡ue sczares hosqua, colaque tmran y goiao a ces airo dve poy cue duo tahintosmra sadarses coide, er suman ie pano a ton laceaña as \n",
      "\n",
      "261/261 [==============================] - 51s 194ms/step - loss: 2.2035 - accuracy: 0.3376\n",
      "\n",
      "Generating text after epoch: 3\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"oso y de estruendo, como convenía a la n\"\n",
      "...Generated:  o de pan an la al se con en en en al en al en en le mo la con en ento de le me la mo de la de la men al en de la la la as enta de de la con en an an s\n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"oso y de estruendo, como convenía a la n\"\n",
      "...Generated:  o ven on aber pora que la porde en en de las se cando pos mino les la de se pues dos valla an carriy cor que tito se que les esta se corado  astero de\n",
      "\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \"oso y de estruendo, como convenía a la n\"\n",
      "...Generated:  tidojobadesa éu a e:tien pon tahpenhe; que —l men vidlijavov al: dusuequelaso, sol ses, partinda que e tos sezira cin a prmra. cor ul án percal adema \n",
      "\n",
      "261/261 [==============================] - 56s 216ms/step - loss: 2.1208 - accuracy: 0.3542\n",
      "\n",
      "Generating text after epoch: 4\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"a de caballero andante. — de ese parecer\"\n",
      "...Generated:   en en me cara de la mon de era de conte de la la de pon en la men al por ente se has de la se pante de la lo se manta de pares de por ente des que la\n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"a de caballero andante. — de ese parecer\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5a379f4be401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mx_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0m_read_variable_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 \u001b[0m_read_variable_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0;34m'recurrent_kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m                 \u001b[0m_read_variable_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_read_variable_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m   1764\u001b[0m   \u001b[0;34m\"\"\"Read the value of a variable if it is variable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \"\"\"\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[1;32m    663\u001b[0m           self._handle, self._dtype)\n\u001b[1;32m    664\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    468\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    471\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[1;32m    472\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "batch_size = 256\n",
    "\n",
    "epoch = 0\n",
    "for epoch_ind in range(int(epochs/10)):\n",
    "    if epoch_ind < 4:\n",
    "        epoch += 1\n",
    "        model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    else:\n",
    "        epoch += 10\n",
    "        model.fit(x, y, batch_size=batch_size, epochs=10)\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "        for i in range(150):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices.get(char, 0)] = 1.0\n",
    "            preds = model(x_pred).numpy()[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnJTL_VJZaYi"
   },
   "source": [
    "### Sabina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RRefCIyGapC"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6inpv1mGapC",
    "outputId": "f3ec0d0d-7347-4a8b-e29c-9c6e4f621cfa"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.letras.com/joaquin-sabina/'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIG1O9VIGapC"
   },
   "outputs": [],
   "source": [
    "def check_is_paragraph(row):\n",
    "    return all([\n",
    "        b.name == 'br' or type(b) == bs4.element.NavigableString\n",
    "        for b in row.contents\n",
    "    ])\n",
    "\n",
    "def get_paragraph_text_0(row):\n",
    "    sentences = []\n",
    "    for b in row.contents:\n",
    "        phrase = ''\n",
    "        if type(b) == bs4.element.NavigableString:\n",
    "            phrase = b.strip()\n",
    "        elif b.name == 'br':\n",
    "            phrase = b.get_text().strip()\n",
    "        if phrase:\n",
    "            sentences.append(phrase)\n",
    "    return sentences\n",
    "\n",
    "def get_paragraph_text(row):\n",
    "    sentences = []\n",
    "    for b1 in row.contents:\n",
    "        phrase = ''\n",
    "        if type(b1) == bs4.element.NavigableString:\n",
    "            phrase = b1.strip()\n",
    "        elif len(b1.contents) > 1 and check_is_paragraph(b1):\n",
    "            phrase = ' '.join(get_paragraph_text_0(b1))\n",
    "        elif b1.name == 'br':\n",
    "            phrase = b1.get_text().strip()\n",
    "        if phrase:\n",
    "            sentences.append(phrase)\n",
    "    return sentences\n",
    "\n",
    "def get_song(song_soup):\n",
    "    first = False\n",
    "    song = []\n",
    "    for i, row in enumerate(song_soup.findAll('p')):\n",
    "        is_paragraph = check_is_paragraph(row)\n",
    "        if not first and is_paragraph:\n",
    "            first = True\n",
    "        if first and not is_paragraph:\n",
    "            break\n",
    "        if is_paragraph:\n",
    "            paragraph = get_paragraph_text(row)\n",
    "            song += paragraph\n",
    "    return '\\n'.join(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0rGU5_cGapC",
    "outputId": "3a21cd4e-9a07-4157-df74-5e00650774f3"
   },
   "outputs": [],
   "source": [
    "complete_songs = []\n",
    "all_rows = soup.findAll('a', {'class':\"song-name\"}, href=True)\n",
    "for row in all_rows:\n",
    "    song_url = 'https://www.letras.com' + row['href']\n",
    "    song_page = requests.get(song_url)\n",
    "    song_soup = BeautifulSoup(song_page.text, 'html.parser')\n",
    "    song = get_song(song_soup)\n",
    "    print('######################')\n",
    "    print(song_url)\n",
    "    print(song)\n",
    "    complete_songs.append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TQ1Hh99GapD"
   },
   "outputs": [],
   "source": [
    "text_sabina = ' '.join(complete_songs).replace('\\n', ' ').replace('  ', ' ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWUtcVk5GapD",
    "outputId": "92960220-cc2b-4125-9b33-131644f41178"
   },
   "outputs": [],
   "source": [
    "len(text_sabina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVW1ssYYaJLi"
   },
   "outputs": [],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "def get_sentences(text, maxlen, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    print(\"Number of sequences:\", len(sentences))\n",
    "    return sentences, next_chars\n",
    "\n",
    "def preprocess_text(sentences, chars, char_indices):\n",
    "    x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros(len(sentences), dtype=np.int32)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices.get(char, 0)] = 1\n",
    "        y[i] = char_indices.get(next_chars[i], 0)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpuALxMDayA8",
    "outputId": "0ae87ce6-c2ac-49dc-823a-9701639482f1"
   },
   "outputs": [],
   "source": [
    "sentences, next_chars = get_sentences(text_sabina, maxlen, step)\n",
    "x, y = preprocess_text(sentences, chars, char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5hREkqXaJLl",
    "outputId": "e542c962-e97e-49a3-82f6-564e8e6a6a18"
   },
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnWoy7_sbZ-j"
   },
   "source": [
    "### Continues with the songs of Sabina with the model trained with Don Quixote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbUrQy91aJLm"
   },
   "outputs": [],
   "source": [
    "def continue_sentence(model, sentence, sentence_length, char_indices, maxlen, chars, diversity=0.2):\n",
    "    generated = \"\"\n",
    "    for i in range(sentence_length):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices.get(char, 0)] = 1.0\n",
    "        preds = model(x_pred).numpy()[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        sentence = sentence[1:] + next_char\n",
    "        generated += next_char\n",
    "    print(\"...Generated: \", generated)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pMC5z6EuGapD",
    "outputId": "735dfaf8-d662-4854-d4bb-1e2dd92485a2"
   },
   "outputs": [],
   "source": [
    "ind = np.random.randint(len(sentences))\n",
    "sentence = sentences[ind]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "b2srfeBAGapD",
    "outputId": "f11f60f7-7e08-45ca-cc65-eb9af477dabe"
   },
   "outputs": [],
   "source": [
    "generated = continue_sentence(model, sentence, 50, char_indices, maxlen, chars, diversity=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXI3o_SVe3xY"
   },
   "outputs": [],
   "source": [
    "model_sabina= keras.models.clone_model(model)\n",
    "model_sabina.set_weights(model.get_weights())\n",
    "model_sabina.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gJb8cfYGapE",
    "outputId": "a086d366-804b-4028-9be9-4fd873862e5a"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "epoch = 0\n",
    "for epoch_ind in range(int(epochs/5)):\n",
    "    if epoch_ind <= 2:\n",
    "        model_sabina.fit(x, y, batch_size=1024 * 8, epochs=1)\n",
    "    elif epoch_ind < 10:\n",
    "        epoch += 1\n",
    "        model_sabina.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    else:\n",
    "        epoch += 5\n",
    "        model_sabina.fit(x, y, batch_size=batch_size, epochs=5)\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text_sabina) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "        generated = \"\"\n",
    "        sentence = text_sabina[start_index: start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "        for i in range(250):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices.get(char, 0)] = 1.0\n",
    "            preds = model_sabina(x_pred).numpy()[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: Create a model with regularization and compare the results only with the corpus of Sabina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sabina = keras.Sequential()\n",
    "model_sabina.add(keras.Input(shape=(maxlen, len(chars))))\n",
    "model_sabina.add(...)\n",
    "model_sabina.add(layers.Dense(len(chars), activation=...))\n",
    "model_sabina.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 128\n",
    "\n",
    "epoch = 0\n",
    "for epoch_ind in range(int(epochs/5)):\n",
    "    if epoch_ind < 5:\n",
    "        epoch += 1\n",
    "        model_sabina.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    else:\n",
    "        epoch += 5\n",
    "        model_sabina.fit(x, y, batch_size=batch_size, epochs=5)\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text_sabina) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "        generated = \"\"\n",
    "        sentence = text_sabina[start_index: start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "        for i in range(250):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices.get(char, 0)] = 1.0\n",
    "            preds = model_sabina(x_pred).numpy()[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[https://keras.io/examples/generative/lstm_character_level_text_generation/](https://keras.io/examples/generative/lstm_character_level_text_generation/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
