{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/RNN/IMBD_RNN.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/IMBD_RNN.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Example\n",
    " Two-class classification, or binary classification, may be the most widely applied kind of machine-learning problem. In this example, you’ll learn to classify movie reviews as positive or negative, based on the text content of the reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def show_loss_accuracy_evolution(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Sparse Categorical Crossentropy')\n",
    "    ax1.plot(hist['epoch'], hist['loss'], label='Train Error')\n",
    "    ax1.plot(hist['epoch'], hist['val_loss'], label='Val Error')\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.plot(hist['epoch'], hist['accuracy'], label='Train Accuracy')\n",
    "    ax2.plot(hist['epoch'], hist['val_accuracy'], label='Val Accuracy')\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset: The IMDB dataset\n",
    "We’ll work with the IMDB dataset: a set of 50,000 highly polarized reviews from the Internet Movie Database. They’re split into 25,000 reviews for training and 25,000 reviews for testing, each set consisting of 50% negative and 50% positive reviews. The  parameter `num_words` controls how many words different we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/aezponda/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/aezponda/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "num_words = 10000\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=num_words)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform word_id to word and reverse\n",
    "word2int = imdb.get_word_index()\n",
    "word2int = {w: i+3 for w, i in word2int.items()}\n",
    "word2int[\"<PAD>\"] = 0\n",
    "word2int[\"<START>\"] = 1\n",
    "word2int[\"<UNK>\"] = 2\n",
    "word2int[\"<UNUSED>\"] = 3\n",
    "int2word = {i: w for w, i in word2int.items()}\n",
    "num_words = num_words+3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For transforming an id-sequence to a phrase use get_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_words(sentence, int2word):\n",
    "    return ' '.join([int2word.get(i, '<UNK>') for i in sentence])\n",
    "\n",
    "\n",
    "get_words(train_data[0], int2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP model\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "You need to convert your raw text to an appropriate input to a sequential model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "def vectorize_text_sentence(text, word2int):\n",
    "    tokens = text.split(' ')\n",
    "    tokens_id = [word2int.get(tk,2) for tk in tokens]\n",
    "    return tokens_id\n",
    "\n",
    "text = get_words(train_data[0], int2word)\n",
    "print(text)\n",
    "print(vectorize_text_sentence(text, word2int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a bag of words model. BoW is a simplifying representation used in natural language processing. In this model, a text (such as a sentence or a document) is represented as the Each key is the word, and each value is the frequency of occurrences of that word in the given text document.\n",
    "\n",
    "- **Input document**: `\"John likes to watch movies Mary likes movies too\"`\n",
    "- **BoW**: `{'John': 0.11, 'likes': 0.22, 'to': 0.11, 'watch': 0.11, 'movies': 0.22, 'Mary': 0.11, 'too': 0.11}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_example John likes to watch movies Mary likes movies too\n",
      "text splitted ['John', 'likes', 'to', 'watch', 'movies', 'Mary', 'likes', 'movies', 'too']\n",
      "bag_of_words {'John': 0.1111111111111111, 'likes': 0.2222222222222222, 'to': 0.1111111111111111, 'watch': 0.1111111111111111, 'movies': 0.2222222222222222, 'Mary': 0.1111111111111111, 'too': 0.1111111111111111}\n",
      "bag_of_words norm=False {'John': 1, 'likes': 2, 'to': 1, 'watch': 1, 'movies': 2, 'Mary': 1, 'too': 1}\n",
      "bag_of_words with indexes {308: 1, 1232: 2, 8: 1, 106: 1, 102: 2, 1083: 1, 99: 1}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_bag_of_words(sequence, norm=True):\n",
    "    word_count = Counter(sequence)\n",
    "    if norm:\n",
    "        total = sum(word_count.values())\n",
    "        word_freq = {w: n / total for w, n in word_count.items()}\n",
    "        return word_freq\n",
    "    else:\n",
    "        return dict(word_count.items())\n",
    "\n",
    "\n",
    "text_example = \"John likes to watch movies Mary likes movies too\"\n",
    "print('text_example', text_example)\n",
    "text_sequence = text_example.split()\n",
    "print('text splitted', text_sequence)\n",
    "bag_of_words = get_bag_of_words(text_sequence)\n",
    "print('bag_of_words', bag_of_words)\n",
    "print('bag_of_words norm=False', get_bag_of_words(text_sequence, norm=False))\n",
    "print(\n",
    "    'bag_of_words with indexes', {\n",
    "        word2int[w.lower()]: p\n",
    "        for w, p in get_bag_of_words(text_sequence, norm=False).items()\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we convert every BoW to a vector of `dim=num_words` with `vectorize_sequences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 10003), (25000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize_sequence(sequence, num_words, norm=True):\n",
    "    vec = np.zeros(num_words)\n",
    "    bow = get_bag_of_words(sequence, norm)\n",
    "    for w, freq in bow.items():\n",
    "        if w < num_words:\n",
    "            vec[w] = freq\n",
    "    return vec\n",
    "\n",
    "\n",
    "def vectorize_sequences(sequences, num_words=num_words, norm=True):\n",
    "    \"\"\"Creates an all-zero matrix of shape (len(sequences), num_words)\"\"\"\n",
    "    results = np.zeros((len(sequences), num_words))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, :] = vectorize_sequence(sequence, num_words, norm)\n",
    "    return results\n",
    "\n",
    "\n",
    "x_train = vectorize_sequences(train_data, num_words=num_words)\n",
    "x_test = vectorize_sequences(test_data, num_words=num_words)\n",
    "y_train =np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train a model \n",
    "Define, compile and fit your sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "history = model.fit(x_train, y_train, validation_split=0.2, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss_accuracy_evolution(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "You need to obtain a Test Accuracy > 0.85. Try to get more than 0.9!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictioins with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['the film was really bad and i am very disappointed',\n",
    "           'The film was very funny entertaining and good we had a great time . brilliant film',\n",
    "           'this film was just brilliant']\n",
    "sequences = [vectorize_text_sentence(review.lower(), word2int)\n",
    "             for review in reviews]\n",
    "\n",
    "x_pred = vectorize_sequences(sequences, num_words=num_words)\n",
    "np.round(model.predict(x_pred), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model\n",
    "\n",
    "Lets use a recurrent neural network and compare results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN model\n",
    "\n",
    "There are three built-in RNN layers in Keras:\n",
    "\n",
    "1. [`keras.layers.SimpleRNN`](https://keras.io/api/layers/recurrent_layers/simple_rnn/), a fully-connected RNN where the output from previous\n",
    "timestep is to be fed to next timestep.\n",
    "\n",
    "```python\n",
    "tf.keras.layers.SimpleRNN(\n",
    "    units,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    ")\n",
    "````\n",
    "\n",
    "2. [`keras.layers.GRU`](https://keras.io/api/layers/recurrent_layers/gru/), first proposed in\n",
    "[Cho et al., 2014](https://arxiv.org/abs/1406.1078).\n",
    "```python\n",
    "tf.keras.layers.GRU(\n",
    "    units,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    ")\n",
    "```\n",
    "\n",
    "3. [`keras.layers.LSTM`](https://keras.io/api/layers/recurrent_layers/lstm/), first proposed in\n",
    "[Hochreiter & Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf).\n",
    "```python\n",
    "tf.keras.layers.LSTM(\n",
    "    units,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    ")\n",
    "````\n",
    "For more information, see the\n",
    "[RNN API documentation](https://keras.io/api/layers/recurrent_layers/).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In sequence classification we are going to use the **many-to-one** architecture with default parameter `return_sequences=False`.\n",
    "\n",
    "The shape of the output  for this architecture  is `(batch_size, units)`.\n",
    "where `units` corresponds to the `units` argument passed to the layer's constructor.\n",
    "\n",
    "Lets see one some examples for understanding the input/output dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim (batch, timesteps, feature):  (32, 10, 4)\n",
      "return_state=False output shape:  (32, 2)\n"
     ]
    }
   ],
   "source": [
    "# dims of input: [batch, timesteps, features]\n",
    "inputs = tf.random.normal([32, 10, 4])\n",
    "print('input dim (batch, timesteps, feature): ', inputs.shape)\n",
    "# return_sequences=False, return_state=False\n",
    "lstm = tf.keras.layers.LSTM(units= 2)\n",
    "output = lstm(inputs)\n",
    "print('return_state=False output shape: ',output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep RNN\n",
    "We can stack multiple layers of RNNs on top of each other. Each hidden state is continuously passed to both the next time step of the current layer and the current time step of the next layer.\n",
    "\n",
    "For stack another RNN layer to an existing one, we need to use the states with `return_sequences=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64)\n"
     ]
    }
   ],
   "source": [
    "## We can modify the input vector before the rnn cell with TimeDistributed\n",
    "timesteps = 10\n",
    "features = 8 # dimension of the innput of every cell\n",
    "\n",
    "#Shape [batch, timesteps, features] \n",
    "inputs = tf.keras.Input(shape=(timesteps, features), name='input')\n",
    "lstm_1 = layers.LSTM(64, return_sequences=True, name='lstm_1')(inputs)\n",
    "lstm_2 = layers.LSTM(64, return_sequences=True, name='lstm_2')(lstm_1)\n",
    "# last lstm layer depends in [one to many or  many to many]\n",
    "lstm_3 = layers.LSTM(64, return_sequences=False, name='lstm_3')(lstm_2)\n",
    "model = keras.Model(inputs=inputs, outputs=lstm_3, name='rnn_example')\n",
    "#print(model.summary())\n",
    "inputs = tf.random.normal([32, timesteps, features])\n",
    "print(model(inputs).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNNs\n",
    "\n",
    "For sequences other than time series (e.g. text), it is often the case that a RNN model\n",
    "can perform better if it not only processes sequence from start to end, but also\n",
    "backwards. For example, to predict the next word in a sentence, it is often useful to\n",
    "have the context around the word, not only just the words that come before it.\n",
    "\n",
    "Keras provides an easy API for you to build such bidirectional RNNs: the\n",
    "`keras.layers.Bidirectional` wrapper.\n",
    "\n",
    "[link to documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 10, 128)           37376     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 79,242\n",
      "Trainable params: 79,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# If you crete a second layer you must set return_sequences=True\n",
    "model.add(\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(timesteps, features))\n",
    ")\n",
    "# Second Bidirectional layer\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "# Output\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "num_words = 2000\n",
    "((train_data, train_labels), (test_data, test_labels)\n",
    " ) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "#  limit the data for class time\n",
    "'''size = 15000\n",
    "(train_data, train_labels), (test_data, test_labels) = (\n",
    "    (train_data[:size], train_labels[:size]), (test_data[:size], test_labels[:size]))\n",
    "'''\n",
    "# Transform word_id to word and reverse\n",
    "word2int = imdb.get_word_index()\n",
    "word2int = {w: i+3 for w, i in word2int.items()}\n",
    "word2int[\"<PAD>\"] = 0\n",
    "word2int[\"<START>\"] = 1\n",
    "word2int[\"<UNK>\"] = 2\n",
    "word2int[\"<UNUSED>\"] = 3\n",
    "int2word = {i: w for w, i in word2int.items()}\n",
    "num_words = num_words+3\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "For data preprocessing we first use [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences):\n",
    "```python\n",
    "tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences, maxlen=None, dtype='int32', padding='pre',\n",
    "    truncating='pre', value=0.0\n",
    ")\n",
    "```\n",
    "- **padding**:\t'pre' or 'post' (optional, defaults to 'pre'): pad either before or after each sequence.\n",
    "- **truncating**:\tString, 'pre' or 'post' (optional, defaults to 'pre'): remove values from sequences larger than maxlen, either at the beginning or at the end of the sequences.\n",
    "\n",
    "\n",
    "Our RNN will take sequences of constant length. In our case this length is the `maxlen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence:  [1, 2, 3]\n",
      "input sequence with padding:  [[0 0 1 2 3]]\n",
      "input sequence:  [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "input sequence with padding:  [[5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "input_seq = [1, 2, 3]\n",
    "max_len = 5\n",
    "print('input sequence: ', input_seq)\n",
    "pad_seq = sequence.pad_sequences([input_seq], maxlen=max_len)\n",
    "print('input sequence with padding: ', pad_seq)\n",
    "\n",
    "input_seq = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "max_len = 5\n",
    "print('input sequence: ', input_seq)\n",
    "pad_seq = sequence.pad_sequences([input_seq], maxlen=max_len)\n",
    "print('input sequence with padding: ', pad_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence:  [1, 2, 3]\n",
      "input sequence with padding:  [[1 2 3 0 0]]\n",
      "input sequence:  [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "input sequence with padding:  [[1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "input_seq = [1, 2, 3]\n",
    "max_len = 5\n",
    "print('input sequence: ', input_seq)\n",
    "pad_seq = sequence.pad_sequences([input_seq], maxlen=max_len, padding='post')\n",
    "print('input sequence with padding: ', pad_seq)\n",
    "\n",
    "input_seq = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "max_len = 5\n",
    "print('input sequence: ', input_seq)\n",
    "pad_seq = sequence.pad_sequences([input_seq], maxlen=max_len, truncating='post')\n",
    "print('input sequence with padding: ', pad_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 100)\n",
      "test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "max_len = 100\n",
    "x_train_seq = sequence.pad_sequences(train_data, maxlen=max_len, truncating='post', padding='post')\n",
    "x_test_seq = sequence.pad_sequences(test_data, maxlen=max_len, truncating='post', padding='post')\n",
    "\n",
    "print('train shape:', x_train_seq.shape)\n",
    "print('test shape:', x_test_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RNN model\n",
    "\n",
    "For the input of the first rnn layer we need a tensor of `(timesteps, features)` or `(batchsize, timesteps, features)`. We have a matrix of sentences of `(train_size, max_len)`. Every sentence is a  `max_len`, we need to convert it to a sentence of one-hot vectors of dim `(max_len, num_words)`. \n",
    "For get the one-hot encoding of every sequence we are going to use:\n",
    "\n",
    "```python\n",
    "layers.Embedding(input_dim=num_words, output_dim=num_words,\n",
    "  input_length=max_len, embeddings_initializer='identity', trainable=False)\n",
    "```\n",
    "\n",
    "This layer converts the input tensor `(batch_size, max_len)` to one-hot encoded sequences `(batch_size, max_len, num_words)`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 2 2 0]]] (1, 1, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 5, 3), dtype=float32, numpy=\n",
       "array([[[[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = np.array([[[0, 1, 2, 2, 0]]])\n",
    "print(seq, seq.shape)\n",
    "layers.Embedding(input_dim=3, output_dim=3,\n",
    "                 input_length=5, embeddings_initializer='identity',\n",
    "                 trainable=False)(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model\n",
    "Use `keras.layers.SimpleRNN`,  `keras.layers.GRU`,  `keras.layers.LSTM` or `keras.layers.Bidirectional`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(max_len,), name='input'))\n",
    "## one-hot encoding\n",
    "model.add(layers.Embedding(input_dim=num_words, output_dim=num_words,\n",
    "                           input_length=max_len, embeddings_initializer='identity',\n",
    "                           trainable=False))\n",
    "## complete the model with recurrent layers\n",
    "#model.add(...)\n",
    "model.add(layers.SimpleRNN(64, return_sequences=False))\n",
    "## add binary classification output\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "88/88 [==============================] - 89s 1s/step - loss: 0.6956 - accuracy: 0.5121 - val_loss: 0.6905 - val_accuracy: 0.5332\n",
      "Epoch 2/5\n",
      "88/88 [==============================] - 84s 951ms/step - loss: 0.6758 - accuracy: 0.5823 - val_loss: 0.6752 - val_accuracy: 0.5704\n",
      "Epoch 3/5\n",
      "88/88 [==============================] - 86s 973ms/step - loss: 0.5483 - accuracy: 0.7460 - val_loss: 0.4788 - val_accuracy: 0.7888\n",
      "Epoch 4/5\n",
      "88/88 [==============================] - 83s 939ms/step - loss: 0.3384 - accuracy: 0.8597 - val_loss: 0.4751 - val_accuracy: 0.7964\n",
      "Epoch 5/5\n",
      "88/88 [==============================] - 83s 945ms/step - loss: 0.2286 - accuracy: 0.9184 - val_loss: 0.5436 - val_accuracy: 0.7736\n"
     ]
    }
   ],
   "source": [
    "## set the loss and see the results\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "epochs = 5\n",
    "history = model.fit(x_train_seq, train_labels,\n",
    "                    validation_split=0.1, epochs=epochs,\n",
    "                    batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAFzCAYAAAAHXuXxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAACQdElEQVR4nOzdZ3RU1duG8Wtn0guBUEKH0HsNIAISRQVREVCaDbAgKiq2v9h7ee0VEJViRVGxImCLIIIU6b1KD50U0rPfDxMghDZgZk7K/VtrVjKnzZ1hwuSZs8+zjbUWERERERERkcLOz+kAIiIiIiIiIp5QASsiIiIiIiJFggpYERERERERKRJUwIqIiIiIiEiRoAJWREREREREigQVsCIiIiIiIlIk+Dsd4EyVK1fO1qxZs0COlZKSQlhYWIEcy5eU27eU27eU27eKam4ouOwLFizYY60tXwCRSiy9Nyu3rym3bym3bxXV3OCb9+YiV8DWrFmT+fPnF8ix4uPjiYuLK5Bj+ZJy+5Zy+5Zy+1ZRzQ0Fl90Y8+9/T1Oy6b1ZuX1NuX1LuX2rqOYG37w3awixiIiIiIiIFAkqYEVERERERKRIUAErIiIiIiIiRUKRuwZWRKS4y8zMZOvWraSlpXn9sSIjI1m5cqXXH8cbzjR7cHAwVatWJSAgwIup5LCzfR0X1ddkUc+t3w8RKSpUwIqIFDJbt24lIiKCmjVrYozx6mMlJSURERHh1cfwljPJbq1l7969bN26lZiYGC8nEzj713FRfU0W5dzh4eH6/RCRIsOrQ4iNMd2MMauNMeuMMSNOsP5+Y8yi3NsyY0y2MSbKm5lERAq7tLQ0ypYt6/XitSQxxlC2bFmfnNUWN72Oiw79fohIUeK1AtYY4wLeAS4BGgEDjDGN8m5jrX3JWtvCWtsCeBD4w1q7z1uZRESKCv3RX/D0nPqenvOiQ/9WIlJUePMMbFtgnbV2g7U2A5gIXHGK7QcAn3kxj4iIeGDv3r20aNGCFi1aULFiRapUqXLkfkZGxin3nT9/PnfeeecZPV7NmjVp2rTpkcc40/1FTsTXr2OAhQsXYoxh2rRpZxtbREROw5vXwFYBtuS5vxVod6INjTGhQDdgmBfziIiIB8qWLcuiRYsAeOKJJwgPD+e+++47sj4rKwt//xO/fcTGxhIbG3vGj/n7779Trly5k67P/5hZWVkeHTc7OxuXy3XGeaToc+J1/Nlnn9GxY0c+++wzunbtela5PaHXtYiUZN4sYE80FsWeZNvLgVknGz5sjBkCDAGIjo4mPj6+QAImJycX2LF8Sbl9S7l9S7ndXUGTkpIK5Fink52dfcrHSk9PJyAggGuuuYYyZcqwZMkSmjdvTu/evRkxYgRpaWkEBwczatQo6taty8yZM3nzzTeZNGkSzz33HFu3bmXTpk1s3bqVW2+9lVtvvfW4x7DWkpycTFBQ0DHLu3fvTrt27ZgzZw7du3fnp59+OuZ+48aNeeyxx8jKyqJVq1a89tprBAUF0aRJE6699lp+++03hgwZwlVXXXXkmGlpaUXy9SUFY9CgQURFRbFw4UJatWpFv379GD58OKmpqYSEhDBu3Djq169PfHw8L7/8Mj/88ANPPPEEmzdvZsOGDWzevJnhw4ef8OystZYvv/ySn3/+mU6dOh353QB48cUX+eijj/Dz8+OSSy7hhRdeYN26dQwdOpTdu3fjcrmYNGkSW7ZsOfK4AMOGDSM2NpZBgwZRs2ZNbrjhBqZPn86wYcNISkpizJgxZGRkUKdOHT766CNCQ0NJSEhg6NChbNiwAYBRo0bx008/Ua5cOe666y4AHn74YaKjozXaQUSKJG8WsFuBannuVwW2n2Tb/pxi+LC1dgwwBiA2NtbGxcUVSMD4+HgK6li+pNy+pdy+pdywcuXKI91Mn/x+OSu2JxbIcQ9rVLkUj1/eGDh959SgoCCCgoIICAhg06ZN/P7777hcLhITE5k1axb+/v788ssvPPvss3z11VeEhobi7+9PREQEQUFBrF+/nt9//52kpCTq16/P3Xfffdw0HcYYLr/88iNnlAYOHMjdd9+Ny+Xi0KFD/PnnnwBMnz79yP20tDTq1KnDb7/9Rr169bj++uv5+OOPGT58OMYYIiMjmT179nE/T3BwMC1btiyop1I8dCavY0/PLuZ9HZ+JNWvW8Msvvxx5Hc+YMePI6/ihhx7iq6++Om6fVatWHfM6vvXWW497Hc+ZM4eYmBhq165NXFwcU6ZMoXfv3vz000988803/P3334SGhrJvn/uz+muuuYYRI0bQq1cv0tLSyMnJYcuWLcc9dl7BwcFHfh/27t3LzTffDMAjjzzCBx98wB133MGdd95J586dmTx5MtnZ2SQnJ1O5cmV69+7NXXfdRU5ODhMnTmTu3Lln/NyJiBQG3ixg5wF1jTExwDbcRerV+TcyxkQCnYFrvZjlGDk5lukrdrI/OYes7Bz8XV5txiwiUiz06dPnSGFx8OBBBg4cyNq1azHGkJmZecJ9Lr300iNFcIUKFUhISKBq1arHbXeyIcT9+vU74f3Vq1dTo0YN6tWrB7iL3nfeeYfhw4efcD+Rw7z1Op40aRL9+/cHoH///nz00Uf07t2bX375hcGDBxMaGgpAVFQUSUlJbNu2jV69egEcOVN7Onlf18uWLeORRx7hwIEDJCcnHxmy/Ntvv/Hhhx8C4HK5iIyMJDIykrJly7Jw4UISEhJo2bIlZcuW9fQpExE5razsHKavSMA/+2QDbguO1wpYa22WMWYYMA1wAWOttcuNMUNz14/O3bQXMN1am+KtLPltO5DK0I//AeDx2dOoVT6MetER1IsOz/0aQbWoUFx+6sgnIs46mzNM3hIWFnbk+0cffZTzzz+fyZMns2nTppOefc47LNjlcnl87eqJHjPvfWtP/QaZfz9x1pm8jr09n6o3XsfZ2dl89913TJ06lWefffbIvMNJSUlYa4/r8Huy16+/vz85OTlH7uef1iZv9kGDBvHNN9/QvHlzxo8ff9qh8TfddBPjx49n586d3HDDDafcVkTEUynpWXwxfwsf/LmRrftTGdIsiIu9/JjePAOLtXYKMCXfstH57o8HxnszR37REYFMuaEuX8/diCuqOqsTkljw736+W3x0hHOQvx91KhwtaA8Xt1VKh+CnwlZESriDBw9SpUoVAMaPH+/zx2/QoAGbN29m3bp1R67/69y5s89zSNFWUK/jX375hSZNmvDrr78eWTZw4EC++eYbLr74Yp566imuvvrqI0OIo6KiqFq1Kt988w09e/YkPT2d7OxsatSowYoVK0hPTyctLY1ff/2Vjh07nvAxk5KSqFSpEpmZmXzyySdHfo4uXbowatQohg8fTnZ2NikpKZQqVYpevXrx2GOPkZmZyaeffnrWP6uICMCuxDTG/7WJj+f8S2JaFrE1yvDoZY0I2LXS64/t1QK2sApM30ejT9vQwLjw21UJSlWCmIpkhFZkt4liS2Zp1qRGsDQxhfnrDjJ54dGCNTTQlaewDaduboFbOTJYc6iJSInxv//9j4EDB/Lqq69ywQUX/OfjnX/++UeGdTZr1uzIEMiTCQ4OZuTIkfTp04esrCzatGnD0KFD/3MOKVkK6nX82Wefcfnllx+z7MorrzzSQGnRokXExsYSGBhI9+7dee655/joo4+45ZZbeOyxxwgICGDSpEnUqlWLvn370qxZM+rWrXvK67Wffvpp2rVrR40aNWjatOmRZmxvvPEGQ4YM4YMPPsDlcjFq1Cjat29PYGAg559/PqVLl1YHYxE5a2sTknhv5ga+WbidzJwcujaqyM3n1aJ1jTIAxO9e5fUM5nTDsAqb2NhYO3/+/P92kLSDsOQL/l02hxplAiBpByTucH9NP77JhA2MIC0kmoP+Zdlpo/g3sxSrUyJYlxZBgi3DThtFWlBZYipEUj86grp5hiJHlwoq8MJWTW58S7l9S7ndTZwaNmxYIMc6HW8P1/Sms8l+oufWGLPAWnvmc6bIESd6bz7b13FRfU0W9tw5OTm0atWKSZMmUbdu3SPL8+b25f89/5XeK3xLuX2rsOW21jJnwz7em7mB31btIjjAjz6tq3Fjxxhqljv2kp2Cyn6q9+YSeQaW4EhoezMbD9WlRv4nOD3ZXcgeKWq3YxJ3EJK0nZCknVRMXEqLlJ2QkwWBR3fLwY8De8uwfXcZti+OZJONYo4tQ2JAOQJLVyGiQnXKV65JTJVK1K0YQfnwgi9sRURERPJbsWIFl112Gb169TqmeBUROZWs7BymLNvJezM2sHTbQcqGBXL3hfW4rn0NosICT38ALymZBeypBIVDUF0od4r/4HNyIGV3nkJ3O35JO4hK3EFU0g4aHNyOTVxHQMZB9/YHcm9rIMUGuc/i+kWRFlwBW6oSwVFViaxQg0pVYyhVoTpEVARXwMkfX0RERMRDjRo1OjIvrIjI6SSnZ/HFPHdjpm0HUqlVLoznejWld6sqBAc4fwmCCtiz4ecHEdHuGy2OW33kSc04lFvk7sQmbid5zxYSd23Gb99WyifvJCRtBWUSZhK4KwvyDBfPwZDiX4aM0GhcpSoRUrYaQVFVIcJ9vW5Y8lY4tA9CyoDO4oqIiIiIyH+UkNuY6ZPcxkxtapbh8csbcWHD6ELVxFYFrDcFhkLZ2lC2NgaIyL3lZXNySEjYxpbNG9mzfSPJu7eQeWAbASk7idq/j4oH1hO9ZR5BJunIPm0A5t+F9Q/GRFSCUpXdZ22PfF/pSLFLRCXwD0JERERERCS/NQlJjJmxgW8XbSM7x9KtSUVu6lSLVtXLOB3thFTAOsz4+RFdqRrRlaoB5x1Zbq1l24FU1iYkMzMhifU79rFv578c2ruVMtl7qWj2EZ21n5o5B6l+6CAVdm6iVOYe/HPSj3+Q0LIQkVvklqrk/v7w14iK7qI3tKzO5oqIiIiIlADWWmav38uYmRuIX72b4AA/BrStzo0dY6hRtnDPpa4CtpAyxlC1TChVy4RyfoMKQG2gDTk5li+n/k5Uzcas2ZXElJ1JrElIZt3uZDKysokkhWizn8bhKTQtlUKdkCSqug5Qzu4jPHkXfjsWu6/fJV/3aVfg0bO4ec/k5j+7GxDiwLMhIiIiIiL/VWZ2DlOW7mDMjA0s355IufBA7r2oHteeU4MyDjZmOhMqYIsYPz9DhVA/4hpFc2Gj6CPLs3Msm/cdYk1CEmt2JrFmVzJfJCSxYWMKGdk5gPsEa/WoUBrUDKFFmTQahR8iJugglfz2E5Cy8+hUQgnLYO3PkJlyfIDg0nmK2spHhynnXRZW3n2dsIgUSXFxcTz44IN07dr1yLLXX3+dNWvWMHLkyJPu8/LLLxMbG3vc8h07dhAS4v7wq06dOnz55ZfeCy8AGGO6AW8ALuB9a+0L+daXAcbi/nQ0DbjBWrvMk32LioJ8HQPs3r2bypUr8/bbb3PLLbd4LbeIiDckp2cxce5mxs3a5G7MVD6MF3o3pWfLwtGY6UyogC0mXH6GmHJhxJQLo2vjikeWZ2XnsGlvbmGbkMTahGTWJCTx65pDZOVYoBR+phQ1yzZyz19bOYK60RHUrxBOTEQ2gam7IHH7kW7Lh5tSkbgddq2E5ASwOceG8fOH8MPDlY8WusGplX37pIjIWRkwYAATJ0485g//iRMn8tJLL53V8T755JMTFgSHZWVl4e/vf9L7p9pPjmeMcQHvABcBW4F5xpjvrLUr8mz2ELDIWtvLGNMgd/suHu5bJBT063jSpEmcc845fPbZZ14tYD19/YuIeGLnwdzGTH//S1JaFm1joniyR2MuaFChUDVmOhP6H7KY83f5UadCOHUqhNO9aaUjyzOycti0N4XVO5NYm+AehrxmVxI/r0ggJ3d0sb+foWa5MOpFl6JuhSrUi46gfoNwapQNI8CVe4Y1OwtSduWZNzdvobsDdq+BDX9AeiItgipA3MXu7skiUmhdddVVPPLII6SnpxMUFMSmTZvYvn07HTt25NZbb2XevHmkpqZy1VVX8eSTT57VYwwaNIioqCgWLlxIq1at2Lt37zH3r7vuOoYOHcqhQ4eoXbs2Y8eOpUyZMsTFxXHuuecya9YsunbtykMPPVTAP32x0BZYZ63dAGCMmQhcAeQtQhsBzwNYa1cZY2oaY6KBWh7sWyQU9Ov4s88+45VXXuHqq69m27ZtVKlSBYAPP/yQl19+GWstLVq04KOPPiIhIYGhQ4cembpm1KhRVK5cmcsuu4xly5YB8PLLL5OcnMwTTzxxzOu6R48e1KtXj2eeeYaMjAzKli3LJ598QnR0NMnJydxxxx3Mnz8fYwyPP/44Bw4cYNmyZbz22msAvPfee6xcuZJXX33VS8+siBQFq3Ym8t6MjXy32N2Y6ZKmlbi5Uy1aVCvtdLT/TAVsCRXo70e96AjqRR/bFzktM5sNu1NYuysp96xtMiu2J/LTsp3Y3MI2wGWoVS7cfcY29xj1outTo34rXCf7JGfLPALHdoVvh0G/j9UwSsRTP42AnUsL9pgVm8IlJx8VWrZsWdq2bcvUqVO54oormDhxIv369cMYw7PPPktUVBTZ2dl06dKFJUuW0KxZs1M+3DXXXHNkCPFFF1105AzYmjVr+OWXX3C5XAwaNOiY+82aNeOtt96ic+fOPPbYYzz55JO8/vrrABw4cIA//viDpKSkkz1kSVcF2JLn/lagXb5tFgO9gT+NMW2BGkBVD/c9c2fwOg7JzgKXB3+e+PB1vGXLFnbu3Enbtm3p27cvn3/+Offccw/Lly/n2WefZdasWQQFBZGZmQnAnXfeSefOnZk8eTLZ2dkkJyezf//+U/44h1/XAPv372fOnDkYY3j//fd58cUXeeWVV3j66aeJjIxk6dKlR7YLDAykWbNmvPjiiwQEBDBu3Djefffd0z9/IlLsWGv5a/1e3p2xgRlrdhMS4OKadjW4oUMM1cuGOh2vwKiAlWMEB7hoVLkUjSqXOmZ5akY263cnHylq1yYksWjLAX5YsuPINoH+ftQuH069YwrbcKqVCcWvWhs21BpInVVjYe570G6Ir380ETkDh4dfHv7Df+zYsQB88cUXjBkzhqysLHbs2MGKFStOW8CebAhxnz59cLlcx90/ePAgBw4coHPnzgAMHDiQPn36HNmuX79+BfEjFmcn+oQwX+c+XgDeMMYsApYCC4EsD/d1P4gxQ4AhANHR0cTHxx+zPjIy8siHDEGZGfhlezjk20KWB9vmZGaQfpoPMXr27MlHH33EBRdcwKeffso777xDUlISH374IePHjycrK4udO3eyYMECYmJiyM7OJiUl5bgPRyZMmEDPnj1JSkri8ssv5/bbb+fmm29mypQp9OjRg6CgILKzswkICCApKYlff/31yGMB+Pn5kZycTE5OzpFl6enppKenk5SURHZ2NpdffvmRdatXr+ahhx4iISGBjIwMatSoQVJSEtOnT2fs2LFHtvP39ycnJ4dOnToxadIk6tevT1paGjVr1vT4A57s7Owj26alpR3371hYJScnF5mseSm3b5WU3Fk5lrk7s5m6MZPNSTmUCjRcWTeA86sFEB64mw1Ld7PBe3GP4YvnXAWseCQk0EWTKpE0qRJ5zPKU9CzW7XIXtmtzv87buI9vF20/sk1wgHsYc4eo7jxYbztMfxiqtYXKLXz8U4gUQac4w+RNPXv25J577uGff/4hNTWVVq1asXHjRl5++WXmzZtHmTJlGDRoEGlpaWf9GGFhYae87+l+cpytQLU896sC2/NuYK1NBAYDGGMMsDH3Fnq6ffMcYwwwBiA2NtbGxcUds37lypVEROSO8unh+XDWpKSko/udxun6ZQ4YMICHH36YtWvXkp6eTqdOndi4cSNvv/32Ma9jYwwRERG4XC7CwsKOe/yvv/6ahIQEJk2aBMD27dvZuXMnQUFBBAUFERERcUzuw8cLCjo6D3vp0qUBjmxjrT2yr8vlonz58kfWjRgxgnvuuYcePXoQHx/PE088QURExJHj5s9366238txzz9GgQQNuuukmj58/OPb5Dg4OpmXLlh7v66T4+Hjyv+aKAuX2reKeOyktk4lztzB29kZ2HEyndvkw/u/iWlzRwrnGTL54zlXAyn8SFuRP82qlaZ5vPH1SWiZrdyUfub521ro9vLcsg85XP825O5fCpEFwywwILnXC44qIs8LDw4mLi+OGG25gwIABACQmJhIWFkZkZCQJCQn89NNPXnmTioyMpEyZMsycOZNOnTrx0UcfHTkbKx6ZB9Q1xsQA24D+wNV5NzDGlAYOWWszgJuAGdbaRGPMafctSgridbx69WpSUlLYtm3bkWWPP/44EydOpHfv3vTq1Yu7776bwMBA9u3bR1RUFF26dGHUqFEMHz78yFnd6Ohodu3axd69ewkPD+eHH36gW7duJ3zMgwcPHrnGdsKECUeWX3zxxbz99ttHhtPv37+fMmXK0K5dO7Zs2cI///zDkiVL/uOzJiKF3Y6DqYyftYlP/95MUnoW7WKieLZXE+LqFd3GTGdCBax4RURwAK2ql6FVdXfDppT0LLq9/DO3fLmRKb3eotq3feD7u+CqsboeVqSQGjBgAL1792bixIkANG/enJYtW9K4cWNq1apFhw4dPDpO3mtgy5Urxy+//HLafSZMmHCkiVOtWrUYN27c2f8gJYy1NssYMwyYhnsqnLHW2uXGmKG560cDDYEPjTHZuBs03XiqfZ34OQrKf30df/bZZ/Tq1euYZVdeeSX9+/fn0Ucf5eGHH6Zz584YY2jdujXjx4/njTfeYMiQIXzwwQe4XC5GjRpF+/bteeyxx2jXrh0xMTE0aNDgpI/5xBNP0KdPH6pUqcI555zDxo0bAXjkkUe4/fbbadKkCS6Xi8cff5zevXsD0LdvXxYtWkSZMmqUKFJcrdyRyHszNvDd4u3kWEv33MZM+U8kFXcqYMUnwoL8Gd4qiBf+yeHq6YapHUcQNvNZqNUZWg9yOp6InECvXr2w9tjLH8ePH3/CbU92vcvJluc/Tv77LVq0YM6cOR4fT45lrZ0CTMm3bHSe72cDdT3dtyj7r6/jJ5544rhlzZo1Y8UKd2PmgQMHMnDgwGOG4kZHR/Ptt98et9+dd97JnXfeedrHveKKK7jiiiuO2y48PPyYM7J5/fnnn9x9990nXCciRZe1lj/X7WHMjA3MXLuH0EAX17V3N2aqFlV8GjOdCRWw4jNlQ/x4//pW9Bszm4Grz+XzmDhcPz0AVdtAdGOn44mIiBQ5Bw4coG3btjRv3pwuXbo4HUdECkhmdg4/LNnOmBkbWbkjkfIRQdzftT7XtKtO6dDTdQAo3lTAik81r1aaV/u24LZP/uHxJnfydPBKzKRBcPPvEBTudDwREZEipXTp0qxZs8bpGCJSQBLTMvlpYyYPzv6dHQfTqFshnBevasYVLSoT5O9MY6bCRgWs+Fz3ppW4v2t9Xpq2mlZtnqT30lthyv3Qa5TT0UREREREfG77gVTG/+VuzJScnkX7WmV5rldTOtcrXyIaM50JFbDiiNviarNhdwr3zNtK4xa3UX/xOxDTCVoU2WaXIgXKWotRg7MClf86SPE+vY6LDv1+iDhj+faDvD9zI98v3o4FLm1aiVah+xh0xTlORyu0VMCKI4wxPNe7CVv2HeKKZR2YV3UBET/eC1VaQ/n6TscTcVRwcDB79+6lbNmy+uO/gFhr2bt3L8HBwU5HKTH0Oi469Psh4lvWWmaudTdm+nOduzHT9e1rckPHmlQtE6qGhaehAlYcE+TvYvR1rek1chZ9dt/Aj4EP4po0CG7+DQJCnI4n4piqVauydetWdu/e7fXHSktLK7J/tJ5p9uDgYKpWrerFRJLX2b6Oi+prsqjn1u+HiPdlZOXw/eLtvDdzA6t2JlEhIogHujXg6rbViQwNcDpekaECVhwVFRbIBwPb0HvkLB41d/Lcrsdh6gi4/A2no4k4JiAggJiYGJ88Vnx8PC1btvTJYxW0opy9JDjb13FR/XdVbhE5mcS0TD79ezPjZm0kITGdetHhvHRVM65oUYVAfz+n4xU5KmDFcXUqhDPq2tYMHJvNueX6c9mC8VCzEzS9yuloIiIiIiJnZduBVMb9uZGJ87aQnJ5Fhzpl+b8rm9G5XnldWvEfqICVQqFDnXI83bMJw7/OpFnZ5VT/fjhUbgllazsdTURERETEY8u2HeT9mRv4fskOAC5rVombO9WiSZVIh5MVDypgpdAY0LY6G3Yn02/mEOIjHiFo0iC46RfwD3I6moiIiIjISVlr+WPNbt6buYFZ6/YSFuhi8Lk1Gdwxhiql1dulIKmAlUJlxCUN2bjnEMPW3Mx7mS/D9Eeh+4tOxxIREREROU5GVg7fLd7OezM2sDohiehSQYy4pAED2lYnMkSNmbxBBawUKi4/wxv9W9BndCof7lvJ9XPfhZodoVEPp6OJiIiIiABwMNXdmGn8X+7GTA0qRvBKn+Zc3ryyGjN5mQpYKXTCgvz5YFAsV751HbHZq2nw7e34VWoGZWo6HU1ERERESrCt+w8x9s9NfD5vMykZ2XSsU46XrmpOp7rl1JjJR1TASqFUKTKE0YPac8e7d/IdDxIyaTB+N0wD/0Cno4mIiIhICbNs20HGzNjAj0t3YIDLm1fmpk4xNK6sxky+pgJWCq1mVUtzf7+Lue/T9Yza/gb216cwXZ9xOpaIiIiIlADWWuLX7GbMHxuYvWEv4UH+3NgxhkHn1qSyGjM5RgWsFGrdmlRiw8XX8+EvK7h+9lsQ0wnqdXU6loiIiIgUU+lZ2Xy7aDvvz9zAmoRkKpYK5qHuDejftjqlgtWYyWkqYKXQu7VzbR5M+B/Ll6+h7qSbCRw2GyKrOB1LRERERIqRg4cy+WTuv4yftYldSek0rFSK1/o159KmasxUmKiAlULPGMNTV8Zy/55HeXbXMNI/HUjEkKng0stXRERERP6bLfsOMXbWRj6ft4VDGdl0qluOV/o2p2MdNWYqjFQBSJEQ6O/HE4Ou4LU3l/Nowmsk/vQkpS572ulYIiIiIlJELdl6gDEzNjBl6Q78jKFH88rc1KkWjSqXcjqanIIKWCkyyoQFcvVN9/HVO4vpNf8tDtXuRGjDi52OJSIiIiJFRE6OJX7NLsbM2MCcDfuICPLn5k61GNShJpUi1ZipKFABK0VK7fLh7O7/Jus+7Ub0pJvJunM2/qUrOx1LRERERAqx9Kxsvlm4jfdmbmTdrmQqRwbzyKUN6demGhFqzFSkqICVIuecBtWY0vltqs3oy+b3r6XWPT+Dn8vpWCIiIiJSyBw4lMEnf29m3KxN7ElOp1GlUrzerwWXNqtEgEuNmYoiFbBSJHXvcj4/bP0fl218hoWfPEzL615wOpKIiIiIFBK7k9L5ZGU6t/32G4cysulcrzxDzqvFubXLqjFTEacCVoqsS669l9mv/U3bdaNZNKMDLc673OlIIiIiIuKwX1Yk8MBXSzhwKIueLaty83kxNKioxkzFhc6bS5HlcvnR7Jb32eGqTOVf72Ddxk1ORxIRERERhxzKyOKhyUu56cP5RJcK5qkOIbzSt7mK12JGBawUaWERpQm6+kMiTTJ7PhrE7sRUpyOJiIiIiI8t2nKAS9/8k8/mbmZo59p8c3sHqoSr1CmO9K8qRV75OrHs6fAk5+Qs5Kd3HyQtM9vpSCIiIiLiA1nZObz561quHPUXGVk5fHbzOYy4pAGB/ipziiv9y0qxUOXC29hR9RKuTp7AyI8+xVrrdCQRERER8aJ/96bQ993ZvPrzGi5vVokpd3XinFplnY4lXqYCVooHY6h07bukhFSm37+PM+qn+U4nEhFxjDGmmzFmtTFmnTFmxAnWRxpjvjfGLDbGLDfGDM6zbpMxZqkxZpExRv+ZikihY63li/lb6P7GTNbuSuaN/i14vX9LIkM0n2tJoAJWio/gSEpd9xHRfgepO/sBvl241elEIiI+Z4xxAe8AlwCNgAHGmEb5NrsdWGGtbQ7EAa8YYwLzrD/fWtvCWhvri8wiIp7an5LBrR//w/++XELTqpFMHX4eV7So4nQs8SEVsFKsmCqt4KJnuMi1gGVf/x8L/t3ndCQREV9rC6yz1m6w1mYAE4Er8m1jgQjjngwxHNgHZPk2pojImfljzW66vj6DX1cl8FD3Bnx60zlUKR3idCzxMc0DK8WOf/uhZGz4g/+t+5QbJjTiuWEDqRYV6nQsERFfqQJsyXN/K9Au3zZvA98B24EIoJ+1Nid3nQWmG2Ms8K61dsyJHsQYMwQYAhAdHU18fHyBhE9OTi6wY/mScvuWcvuW07kzsi2T1mTw879ZVAk3PNouiOo5W5gxY8sp93M699kqqrnBN9lVwErxYwyBvUeSObIjzye/yrBx1fnw9ospFazrIkSkRDAnWJa/s11XYBFwAVAb+NkYM9Namwh0sNZuN8ZUyF2+ylo747gDugvbMQCxsbE2Li6uQMLHx8dTUMfyJeX2LeX2LSdzL99+kOETF7F2VxaDO9TkgW4NCA5webSvnm/f80V2DSGW4ik0ioB+E6hs9nHLwTe4/eMFZGXnnH4/EZGibytQLc/9qrjPtOY1GPjauq0DNgINAKy123O/7gIm4x6SLCLiU9k5lnf/WE/Pd2ZxMDWTD29oy+OXN/a4eJXiSwWsFF/V2uB34WNc4vc3NTZO5KkfVjidSETEF+YBdY0xMbmNmfrjHi6c12agC4AxJhqoD2wwxoQZYyJyl4cBFwPLfJZcRATYdiCVa96fw/M/raJLg2imDT+P8+qVdzqWFBIaQizFW/s7YONMnlj/CT3m1GV8uTAGdYhxOpWIiNdYa7OMMcOAaYALGGutXW6MGZq7fjTwNDDeGLMU95DjB6y1e4wxtYDJ7t5O+AOfWmunOvKDiEiJ9O2ibTzyzTJyciwvXdWMq1pXJff/JBFABawUd35+0Gs0rtEdGef/Dhf+EE2NsmGc36CC08lERLzGWjsFmJJv2eg832/HfXY1/34bgOZeDygiks/B1Ewe/WYZ3y3eTusaZXitbwuql1UTTjmeV4cQn24i9dxt4nInS19ujPnDm3mkhAorh7nyAypk7eCtiA+547N/WLUz0elUIiIiIgLMXr+XS16fwZSlO7jv4np8PuQcFa9yUl4rYD2ZSN0YUxoYCfSw1jYG+ngrj5RwNTtg4h4iLuMP+vv/wY3j57M7Kd3pVCIiIiIlVnpWNs9PWcnV788hOMDFV7eey7AL6uLvUpseOTlvvjo8mUj9atxdEDfDkY6HIt7R6R6I6cxDjCUqZT03fziftMxsp1OJiIiIlDhrEpLo+c5fvDtjA1e3rc4Pd3akebXSTseSIsCbBeyJJlKvkm+bekAZY0y8MWaBMeZ6L+aRks7PBb3fwy+4FJ+VGc2arTu5b9JicnLyT48oIiIiIt6Qk2MZN2sjl731J7sS03j/+lie7dWU0EC15hHPePOV4slE6v5Aa9yt/EOA2caYOdbaNcccyJghwBCA6Oho4uPjCyRgcnJygR3Ll5T7vylT+3aaLXmC8VEf0XfJzfil7KF33cCTbl9Ycp8p5fYt5fa9opxdRKQkSkhM475Ji5m5dg9dGlTghSubUT4iyOlYUsR4s4D1ZCL1rcAea20KkGKMmYG7++ExBay1dgwwBiA2NtbGxcUVSMD4+HgK6li+pNz/VRyUTqbtjJd4vk4HHlzXiAtiG9OzZf4BAm6FJ/eZUW7fUm7fK8rZRURKmqnLdjDi66WkZWbzbK8mXN22uqbHkbPizSHEnkyk/i3QyRjjb4wJBdoBK72YScSt8wio0YH+Ca/Ru/oh/vflEuZv2ud0KhEREZFiJTk9i/snLWbox/9QPSqUH+/sxDXtaqh4lbPmtQLWWpsFHJ5IfSXwxeGJ1PNMpr4SmAosAeYC71trl3krk8gRLn+48n2MfxAv2deoVdqPIR8tYPPeQ04nExERESkWFvy7j+5vzOSrf7ZyxwV1+OrWc6ldPtzpWFLEebVHtbV2irW2nrW2trX22dxlo/NNpv6StbaRtbaJtfZ1b+YROUapytDrXVy7l/NFzI9k51humDCPxLRMp5OJiIiIFFmZ2Tm8On01fUbPxmL54pb23HtxfQI0PY4UAL2KpGSrdzGceyellk1gUsed/Ls3hds/+Yes7Bynk4mIiIgUORt2J3PVqL9487d19G5VlSl3diK2ZpTTsaQYUQEr0uUxqNqGenMf5vWLI5m5dg9PfL8cazW9joiIiIgnrLV8+vdmLn3zT/7dd4iR17Ti5T7NiQgOcDqaFDMqYEVcAXDVWDCGS1c9xO2dqvHxnM2Mm7XJ6WQiIiIihd6e5HRu/nA+D01eSmzNMky96zy6N63kdCwppjRjsAhA6epwxUj4/Bruq/4J6xr34ZkfV1CzXKg+5RERERE5id9WJfC/L5eQmJbFY5c1YtC5NfHzU4dh8Z7T/m1ujBlmjCnjizAijmp4GbS7FfP3aN5ssY1GlUtxx6cL2ZKk62FFRERE8krNyOaRb5Zyw/j5lAsP4vthHbmhY4yKV/E6T04uVQTmGWO+MMZ0M5q0SYqzi56ESi0I+vEOxvWqSERwAK8tSGNXUprTyUREREQKhSVbD3DpmzP55O/NDDmvFt8O60D9ihFOx5IS4rQFrLX2EaAu8AEwCFhrjHnOGFPby9lEfM8/CPqMg5wcyk+9jfeva05ypuXmDxeQlpntdDoRERERx2TnWN7+bS29R/5FamY2n9zYjoe6NyTI3+V0NClBPLq8z7rbse7MvWUBZYAvjTEvejGbiDOiakGPN2HrXJqsepOhzYJYsvUA936xmJwcdSYWERGRkmfLvkP0e3c2L09fwyVNKzH1rvM4t045p2NJCXTaJk7GmDuBgcAe4H3gfmttpjHGD1gL/M+7EUUc0KQ3bJoJs97gwqaRhF/Sk+emrKJW+TDuvbi+0+lEREREfMJay5/bMhn2+0wM8Eb/FlzRoorTsaQE86QLcTmgt7X237wLrbU5xpjLvBNLpBDo+hxsmUuDVa/T9ML+bNhdjbd+W0dMuTB6t6rqdDoRERERr9qfksHD3yxlytIM2sZE8Wrf5lQtE+p0LCnhPLkG9jGgrDHmTmPMHcaYVnnWrfRqOhEnBYRAn/G4sjMwX9/M0z0acG7tsoz4ainzNu1zOp2IiIiI18xcu5tub8zg5xUJ9K0XwGc3n6PiVQoFT6bReRSYAJTFfTZ2nDHmEW8HEykUytVlTb1b4d9ZBMx8iVHXtKZqmRBu+WgBm/cecjqdiIiISIFKy8zmqe9XcN0Hc4kIDmDybR3oXisQl6bHkULCkyZOVwNtrLWPW2sfB84BrvFuLJHCI6FiHLS4Fma8ROTOWYwd1IYcaxk8fi4HUzOdjiciIiJSIFZsT6TH238ydtZGBravwQ93dKRJlUinY4kcw5MCdhMQnOd+ELDeK2lECqvuL0K5evDVzdQMTmH0ta3ZvO8Qt3/yD5nZOU6nExERETlrOTmW92ZsoOc7s9h/KJPxg9vw5BVNCA7Q9DhS+HhSwKYDy40x440x44BlQLIx5k1jzJvejSdSSASGQZ/xkJ4EX9/MOTVL81yvpvy5bg+Pf7cc90xTIiIiIkXL9gOpXPP+3zw7ZSVx9cszbfh5xNWv4HQskZPypAvx5NzbYfHeiSJSyEU3cp+J/e4O+PNV+px3Pxv2pDAqfj21y4dzY8cYpxOKiIiIeOz7xdt5ePJSsnIsL17ZjD6xVTFG17pK4XbaAtZaO8EYEwjUy1202lqrC/+kZGp5HWycAb8/BzU6cP/F7dm0J4VnflxBzbKhdGkY7XRCERERkVNKTMvk8W+XM3nhNlpWL83r/VpQo2yY07FEPOJJF+I4YC3wDjASWGOMOc+7sUQKKWPgstegTAx8eSN+qft4tW8LmlSO5I7PFrJie6LTCUVEREROas6GvVzy+ky+W7yduy+sx6Rb2qt4lSLFk2tgXwEuttZ2ttaeB3QFXvNuLJFCLCjCfT3sob0w+RZC/A3vD4wlMiSAmybMY1dimtMJRaSEM8Z0M8asNsasM8aMOMH6SGPM98aYxcaY5caYwZ7uKyJFU0ZWDi/8tIoB780hwGX4cmh77rqwLv4uT8oBkcLDk1dsgLV29eE71to1QID3IokUAZWaQddnYd3PMPttoksF8/7AWA6kZnLzh/NJzch2OqGIlFDGGBfuUVOXAI2AAcaYRvk2ux1YYa1tDsQBrxhjAj3cV0SKmHW7kug1chaj/1hP/zbV+PHOTrSsXsbpWCJnxZMCdoEx5gNjTFzu7T1ggbeDiRR6bW6Chj3g1ydhyzwaV47kzf4tWbLtIPdOWkROjjoTi4gj2gLrrLUbrLUZwETginzbWCDCuLu1hAP7gCwP9xWRIsJay4ezN3Hpm3+y42AaY65rzfO9mxEW5EkfV5HCyZMCdiiwHLgTuAtYkbtMpGQzBnq8BaWqwJc3QOp+LmwUzcPdGzJl6U5e+Xn16Y8hIlLwqgBb8tzfmrssr7eBhsB2YClwl7U2x8N9RaQI2JWYxqBx83js2+W0r12WqcM7cXHjik7HEvnPTvnxizHGD1hgrW0CvOqbSCJFSEhp6DMOPugK3w6Dfh9zY8cY1u9O5p3f11OrXDhXtq7qdEoRKVlONAdG/iEhXYFFwAVAbeBnY8xMD/d1P4gxQ4AhANHR0cTHx59l3GMlJycX2LF8Sbl9S7lPbUFCFuOWpZOeDdc1CuSCaimsWDCHFWd5PD3fvlVUc4Nvsp+ygLXW5uQ2eKhurd3s1SQiRVWV1nDRkzDtIZg7BtPuFp66ogmb9x1ixNdLqBYVStuYKKdTikjJsRWolud+VdxnWvMaDLxgrbXAOmPMRqCBh/sCYK0dA4wBiI2NtXFxcQUSPj4+noI6li8pt28p94mlpGfx1Pcr+HzhFppUKcXr/VpQp0LEfz5ukXq+szIgPRHSDvL337Np16kruIpW+54i9Xzn44vsngyArwQsN8bMBVIOL7TW9vBaKpGi5pzbYONMmP4IVGtLQOWWjLy6Nb1GzeKWj+Yz+bYO1CynFvUi4hPzgLrGmBhgG9AfuDrfNpuBLsBMY0w0UB/YABzwYF8RKYT+2byfuz9fxOZ9h7gtrjbDL6xHoH8R6zCckwMZyZB28EgRSlpinu8PHr8u//2s1COHawew4G4oXx+im0J0Y6jYBKKbQFg5x35M+W88KWCf9HoKkaLOGOg5EkZ3gkmD4JYZRIZGMnZgG3qOnMUNE+Yx+dYORIYWrU8ARaTosdZmGWOGAdMAFzDWWrvcGDM0d/1o4GlgvDFmKe5hww9Ya/cAnGhfJ34OEfFMVnYOb/22jrd/X0fFUsF8PqS9cyO/stLzFJUHT15knvB+7vcnvmrhKFcQBEdCcCn316BSEFk1z/3II+tXrlxBwygLCcth/a+w+NOjxwmPdhey0Y2hYm5xW65ekTtbWxJ5UsB2t9Y+kHeBMeb/gD+8E0mkiAqNgqs+gHHd4fu74Kpx1CwXxrvXtubaD/7mtk8XMH5wWwI035qIeJm1dgowJd+y0Xm+3w5c7Om+IlI4bdqTwvDPF7FoywF6t6rCEz0aUyr4LAuwnBzISDphkVll6wKYMe/0BWlW2mkexLgLzTxFJqWrQVDj44vSY+7n2d4/yOMfKWF/PA3zDmdN3g27lsPOZe6iNmEp/D0TsjPc6/0CoHyDPGdqG7vP3IaXP+OnU7zHkwL2IuCBfMsuOcEyEal+DlzwiHtqnZjOEDuYdrXK8kLvZtw7aTGPfbuc53o1wT1zhYiIiMiZs9by+bwtPPXDCgJcfrx9dUsuaxgF6fthz+Gi8oAHZz3zDdM9ydnPugDrAP+QfEVmaShdPc/93GXHFaC5XwPDwc/BD/LDy0N4HNSKO7osOxP2rsstanNvG/+AJROPbhNWIU9BmzsEuVw98A/09U8gnKKANcbcCtwG1DLGLMmzKgL4y9vBRIqsDsNh058wdQRUbQMVm3Bl66ps2OPuTFy7fBg3darldEoREREpLHJyjhaTJy0y3bf0lAOs27KdBin7+SUwg+jANFzfJsHX6ad+DOOXp8jMPatZusYpznoevh/JrAXL6HDBJcWzYHMFQIWG7ht9ji5P2Xu0oE1Y7v769xjIzn2e/QJyr61tfOxQ5PAKjvwYJcmpzsB+CvwEPA+MyLM8yVq7z6upRIoyPz/o9S6M7ui+HnZIPASFc+9F9dm4J4Vnp6ykZtkwLmwU7XRSkaIpJxtWfo9fdojTSUREPLfpTxqsfA22jzq+QE1PPP3+AaGk+4ezLTWQjJwQypWvSKWKFTHHFZ2lT1yUBoa7e3achczALcWzeD2VsLJQq7P7dlh2lvts7eHCducydxPPJZ/n2a/8sWdqKx4+W+v50Gc5tZMWsNbag8BBYIAxxgVE524fbowJ17Q6IqcQXh6ufB8+7AFT7oNeo/HzM7zSpwXb9s/mzokLmTS0PY0rRzqdVKToyEqHxZ/BrDdg3wYq1L8D93SmIiKFXOp++Pw6ymZmgolxF5VRMccXmSc8C1qaVL8wnp++jg9n/0uDihG81q8F1SqVcvqnKnlc/lChgfvW9Kqjy1P2uq+tTVh+dCjy3PfynK31h3KHz9bm6YQcHn3WHyqUZKe9Bja3G+ETQAKQk7vYAs28F0ukGIjpBJ0fgPjnoWYnaHkNIYEu3rs+livemcVNE+bz7e0dqFAq2OmkIoVbWiIsGAezR0LyTqjUAvp+yM6EcBo4nU1ExBN/vAhpB1jU+lXaXDb4jHZdtu0gd02cw/rdKdzUMYb7utYnOMDlpaByVsLKQsx57tth2Vmwbz3sXJo7BHk5/DsLln5xdJvQcsd2QY5u4h6WLKfkSROn4UB9a+1eL2cRKX7Ou999PeyU+6BKa6jQgAqlgvlgYBuuGv0XN304n8+HtCckUG9EIsdJ3g1/j4K577unV4jpDL3fdX81BnbFO51QROT0dq+BuWOg1fWkhMd4vFt2jmX0H+t57ec1lAsP4pOb2tGhjuYuLTJc/u5itHz9Y8/WHtp3tKBNyC1u571/tIOzcdEmpArsbXe0C3J0Y4ioqLO1uTwpYLfgHkosImfKz+UeSjyqA3w5GG76FQJDaVS5FG/2b8nNH83nni8W8c7VrfDz039KIgDs3wR/vQULP3YPG254OXQc7v4QSESkqJn2EASEwQWPwrxlHu2yZd8h7vliEfM27efSppV4tlcTSoeWsGtQi6vQKPcovZhOR5dlZ8G+DUeurU1dMYOwf2fD0kl59it77LW10Y3dU/4ElLyRfJ4UsBuAeGPMj8CR9mbW2le9lkqkOImoCL3HwMdXwtQHoMdbAFzYKJqHuzfkmR9X8vL01fyvmwZDSgmXsBz+fB2WfeXultm8P3S4C8rVdTqZiMjZWTMd1v0MFz8LYac/e2qtZfLCbTz27XIAXu3bnF4tq2j6veLO5Q/l67lvTXqzzBVPXFyc+9rphBXHNo2aPw6yUt37GZf7PTJvF+ToxhBRqVifrfWkgN2cewvMvYnImarTBTrdAzNfgZrnQTN3m/YbO8awYU8KI+PXE1MujD6x1RwOKuKAf2fDn6/B2mnusxTn3Artb4dSlZ1OJiJy9rIz3Wdfy9aBtkNOu/mBQxk8/M0yflyygzY1y/Bq3xZUiwr1QVAptELKQM0O7tthOdlHz9buzJ3iZ8vfsOzLPPtFHT1bWzHv2dri0b3/tAWstfZJAGNMmLU2xfuRRIqpuIdg0yz4YThUaQVla2OM4ckejdm89xAPTV5K9ahQ2tUq63RSEe+zFtZOh5mvwpY57jfb8x+GNje5h1eJiBR1c9+DvWvh6i9OOwXNrHV7uPeLxexJTud/3epzy3m1cenSIjkRv9yzruXqQuNeR5enHoBdK452QU5YBgvG5zlb6wdl6x7bBTm6ifvD4iJ2ttaTLsTtgQ+AcKC6MaY5cIu19jZvhxMpVlz+cNUHufPDDoQbf4GAYAJcfrxzTSt6j5zFLR8v4JvbOlCzXJjTaUW8IzsLln/tHiq8azlEVoNLXoSW10KgXvciUkyk7IH4F6B2F6h78Uk3S8vM5uVpq3n/z43UKh/G5Os70LSqptiTsxBSGmqc674dlpMN+zbmFrTL3V+3zXe/Dx/Zr8zRIciHz9pWaFioz9Z6MoT4ddwT7X0HYK1dbIw575R7iMiJRVaFnqPhs34w/RG49GX34pAAxg5qQ893ZnHD+HlMvq0DkaEBDocVKUCZqe6mTH+9CQc2u4cy9XoXmlwJLr3WRaSY+f1ZyEiGrs+d9OzWqp2JDJ+4iFU7k7junBo81L2hZiWQguXngnJ13LfGPY8uTzt47LW1Ccvhn48gM3ewrfFzD33P3zQqsmqhOFvrSQGLtXZLvovHs70TR6QEqN8N2g+D2W+7O9A1ugKAGmXDGHN9LNe89ze3frKACTe0JcDl53BYkf8o9YB7eoA5o+DQHqjaBrr9H9TrBn56fYtIMbQzd+hm2yFQ4fgGjTk5lrGzNvLi1NWUCvFn3KA2nN+ggu9zSskVHAk12rtvh+XkwP48Z2t3LoNt/8Dyycful7egrdgEyjeEQN9eq+3RNDrGmHMBa4wJBO4EVno3lkgx1+Vx2Dwbvr0DKjWHMjUBaFMziud7N+XeSYt59JtlPN+7qToPStGUuAPmjHR3S8xIgjoXQce73UOb9JoWkeLKWpg6wv2HfucHjlu9Ly2H68b+zax1e7mwYTQvXNmUcuFBDgQVycfPD8rWdt9yT64AkJbovrY2b9OohR8fe7Y2qvaRs7Uhh6p6PaonBexQ4A2gCrAVmA7c7s1QIsWefyBcNRZGnweTBsMN0440eLiydVU27knh7d/XUbt8ODefV8vhsCJnYO96mPUGLP4McrKgcW/3VDiVmjmdTETE+1b9AJtmQveXj2tIF796F4/OSiWHDJ7v3ZT+barpQ2op/IJLQfVz3LfDcnLgwKajBW3CMtixCFZ8Q3Czx70eyZMuxHuAa7yeRKSkKVMTrngbvrgOfn0Suj57ZNU9F9Vj454UnvtpJTXKhnJx44rO5RTxxPZFMOt1WPEt+AW4mzKdewdE6QMYESkhstLd/S3KN4TWg49ZtWXfIe74dCFRwX58eEsnYtSsUYoyPz/3+3tULWjU4+jy9CQOzJrj/Yc/3QbGmBeNMaWMMQHGmF+NMXuMMdd6PZlISdCoh/samdlvw+qfjiz28zO83Kc5zapEctfERSzbdtDBkCInYS1snAEf9YIxnWHdr+6zrcOXwmWvqXgVkZJlzkjYvwm6Pe+eeSBXdo7l3i8WY4E7WwapeJXiKygC6+f9xoyedNC42FqbCFyGewhxPeB+r6YSKUkuehoqNoNvboWDW48sDgl08d7AWMqEBnDThPkkJKY5GFIkj5wcWPkDvN8FJlzuHkJ04RNwd+7XiGinE4qI+FbSTpjxMtTvDrXPP2bV6D/WM3fTPp66ojHlQ9W8TuS/8uS36HAZ3R34zFq7z4t5REqegGDoMx6yM+HLG91fc1WICOaDQW1ISsvkpgnzOZSR5VxOkawMWPgJjGwHn18Dh/bCpa/C8CXuBk3BmrtQREqoX592DyG++JljFi/ecoDXfl7D5c0r06tlFYfCiRQvnhSw3xtjVgGxwK/GmPKATgWJFKSyteHyN2DLHPj9uWNWNaxUireubsny7Qe55/PF5ORYh0JKiZWeDLNHwpst4NvbwBUEV34AwxZAmxsL9WTnIiJet+0fWPQJnHOr+/08V0p6FsM/X0SFiCCe6dlEDZtECshpC1hr7QigPRBrrc0EUoArTr2XiJyxpldBq4Hw56uw7pdjVl3QIJqHL23E1OU7eWn6aocCSolzaB/8/jy83gSmPehuPHbNVzB0pvv16vJoKnERkeLLWpj6IISVg/OOvcLumR9XsGlvCq/2a0FkiPevCxQpKU7714cxpg8w1VqbbYx5BGgFPAPs9HY4kRKn2wuwdR58fQsM/RNKVTqy6oYONdmwO5lR8euJKRdG39hqDgaVYu3gVpj9DiwYD5mH3Nd0dRgO1ds5nUxEpHBZ9pV79FSPt9zTjeSaumwnn83dwq1xtTmnVlkHA4oUP54MIX7UWptkjOkIdAUmAKO8G0ukhAoMdV8Pm3kIvr4ZcrKPrDLG8ESPxnSqW46HJy9lzoa9zuWU4mn3avjmNnijOfz9rnsi89vmwIDPVLyKiOSXcQh+ftzdiLHF0RknExLTePDrJTSpUoq7L6znYECR4smTAvbwX9CXAqOstd8Cgd6LJFLCla8Pl77ingh9xkvHrApw+fH21a2oUTaMoR8vYOOeFIdCSrGydT5MvAbeaQfLvoY2N8Fdi6DXaKjQ0Ol0IiKF019vQuJWuOT/wM8FQE6O5b5Ji0nNzOb1fi0J9FfXYZGC5slv1TZjzLtAX2CKMSbIw/1E5Gy1uBqaD4D4F9zzbOYRGRLA2IFt8DOGG8fP48ChDIdCSpFmLaz7leaLHnFPh7PpT/f1W3cvc/8xVrq60wlFRAqvg1vhz9ehcS+oce6RxeP/2sTMtXt45NJG1KkQ7lw+kWLMk0K0LzAN6GatPQBEoXlgRbyv+8tQri58dTMk7z5mVfWyoYy5rjVb96dy68f/kJGV41BIKXJyst1nWd89Dz7uTeihbXDxs+7C9YKH3Y1IRETk1H55ArBw0VNHFq3amcgLU1dxYcMKXNNOHwKKeIsnXYgPAeuBrsaYYUAFa+10rycTKemCwuGqcZB2ACYPgZxji9TYmlH831VNmb1hL49+swxrNb2OnEJWOswfB2/HwpeD3ddZ93ibOeeMgXOHQVCE0wlFRIqGzX/D0klw7h1HRqukZWZz12eLKBUcwP9d2UxT5oh40WkLWGPMXcAnQIXc28fGmDu8HUxEgIpN3J2J1/8Gs14/bnWvllW544I6fD5/C2NmbPB9Pin80hJh1hvwejP4YTgElYK+H8Ltc6HVdVg/Te0gIuKxnByY+gBEVIaOdx9Z/OLU1axOSOKlPs0oGx7kYECR4s+TSfxuBNpZa1MAjDH/B8wG3jrdjsaYbsAbgAt431r7Qr71ccC3wMbcRV9ba59CRI5qPch9Hexvz0D19lCj/TGr776wHhv2pPDC1FXULBdG18YVnckphUvybvh7FMx9H9IPQq046P0uxHQGnRko9jx4/70fONw21R9oCJS31u4zxmwCknA3ccyy1sb6LLhIYbdkImxfCL3GQGAYADPW7GbsrI0MbF+D8+tXcDigSPHnSQFrONqJmNzvT/vXjzHGBbwDXARsBeYZY76z1q7It+lMa+1lHuYVKXmMgcvfcL9hfnWje37Y0Kgjq/38DK/0ac62/akMn7iISUPb06RKpIOBxVH7N8Ffb8HCj93Dhhte7j5LUKWV08nERzx5/7XWvgS8lLv95cDd1tp9eQ5zvrV2jw9jixR+6Unua1+rxELTPgDsS8ng3kmLqVshnAe7q2u7iC940sRpLPC3MeYJY8wTwBzgAw/2awuss9ZusNZmABOBK846qUhJFlzKPT9sym745lZ3B9m8qwNcjLm+NVFhgdw4YR47D6Y5k1Ock7Dc3fDrzVawYIL7j6th86DfRypeS54zff8dAHzmk2QiRdnMVyE5IXfaHD+stYz4agkHD2XyRv+WBAe4nE4oUiKc8gysMcYP+Bv4A+iI+8zrYGvtQg+OXQXYkuf+VqDdCbZrb4xZDGwH7rPWLj9BjiHAEIDo6Gji4+M9ePjTS05OLrBj+ZJy+1Zhyl0lZiB117zHuo/vYWu14/8eHdoYnp2TTr93fufOxtmFJveZKEzP95lwKnfkgRVU3/wVZffNJ9svmO1VLmdLtR5kBJWFZduAbafcv6g+31C0s3uZp++/GGNCgW7AsDyLLTDdGGOBd621Y7wVVKTI2LcRZr8DzfpDVfeo+s/nbWH6igQe7t6QRpVLORxQpOQwp+tcaoyZba1tf8qNTrxfH6Crtfam3PvXAW2ttXfk2aYUkGOtTTbGdAfesNbWPdVxY2Nj7fz58880zgnFx8cTFxdXIMfyJeX2rUKV21r4/FpYMw1umAZVWx+3ye+rdnHjhHm0KO9i0vCuuPyK1vWOher5PgM+zW0trJ3uPhuwZQ6ERME5t0Kbm44ZXu6Jovp8Q8FlN8YsKE7XeXry/ptn237Atdbay/Msq2yt3W6MqQD8DNxhrZ1xgn3zfrjceuLEiQWSPzk5mfDwojd/pnL7lq9zN172AlH7/uHvdqPICCrLzpQcHvsrlTql/bgvNhg/D3sL6Pn2LeX2vYLKfv7555/0vdmTa2CnG2OuxN1g6Uzm6dgKVMtzvyrus6xHWGsT83w/xRgz0hhTTtfdiJyEMXDF2zD6PPhyENwyE0JKH7PJ+Q0q8NhljXji+xU8/cMKHr+8kdr5FxfZWbD8a/jzddi1HCKrwSUvQstrjzQTEcGD9988+pNv+LC1dnvu113GmMm4hyQfV8DmnpkdA+4Plwvqg5Ci+qGKcvuWT3NvnAnxs+GCRzj3vCvJzM7hqlF/ERKYxdgh51ExMtjjQ+n59i3l9j1fZPfkGth7gElAujEm0RiTZIxJPN1OwDygrjEmxhgTiPtN8ru8GxhjKprcv6yNMW1z8+w9o59ApKQJKQNXjYXE7fDdHcddDwswqEMMXWv6M/6vTXzw58YTHESKlMxUmPsevNUSvr4ZbDb0ehfuXAjtblHxKvmd9v0XwBgTCXTGPRvA4WVhxpiIw98DFwPLfJJapDDKyYapIyCyOrR3j7R/45e1LN56kBd6Nz2j4lVECsZpz8Baa89qdntrbZYxZhgwDXcb/7HW2uXGmKG560cDVwG3GmOygFSg/xme5RUpmaq1gS6Pw8+Pwrz3oe3Nx23Sr34g/hHleebHlVSKDOHSZpUcCCr/SeoB97/vnFFwaA9Ubes+41q3K/h58vmjlEQevv8C9AKmH54mL1c0MDn3s2V/4FNr7VTfpRcpZP6ZAAnL3I0UA0KYu3EfI+PX0ad1VS5pqvdVESectIA1xnQFIqy1X+ZbfjWw21r78+kObq2dAkzJt2x0nu/fBt4+09AigvuT4E1/wrSHoFpbqNT8mNV+xvBK3+YkJKZx9xeLqFAqiDY1z+z6SHFI4g6YMxLmj4OMJKhzkXsqnBrnag7XEsYYcxkwxVqbcyb7ne79N/f+eGB8vmUbgGP/MxEpqVIPuOdgr9EBGvUkMS2Tuz9fRLWoUB7v0djpdCIl1qk+wn8Sd/fh/H4DnvJOHBHxmJ8f9BwFoeVg0iD3/HT5BAe4eO/6WKqWCeGmCfNZtyvZ9znFc3vXw3d3whvNYPbbUK+re97fa7+Emh1UvJZM/YG1xpgXjTGaZFLEl2a8BIf2QbfnwRge+2YZOxPTeL1fC8KDPGkjIyLecKoCNtRauzv/QmvtTkAXXIkUBmFl4aoPYP+/8P3wE14PWyYskAmD2xLgMgwaN5ddSZojttDZvsj9IcTbsbB4IrS8Du5Y4P63rdjU6XTiIGvttUBLYD0wzhgz2xgz5PB1qiLiJXvWwt+jodV1UKk53y7axjeLtnPnBXVpWb2M0+lESrRTFbDBxpjjPl4yxgQAId6LJCJnpMa5cP5DsOxL+OfDE25SLSqUsYPasDc5gxvHz+dQRpaPQ8pxrIWNM+CjXjCmM6z7FTrcBcOXwmWvQlQtpxNKIZHbsf8rYCJQCfe1q/8YY46bFkdECsi0hyEgFC54lK37D/HIN8toXaMMt59f2+lkIiXeqQrYr4H3crsQAkc6Eo7OXScihUXHe6DW+fDT/yBhxQk3aVa1NG9f3ZLl2w8y7NOFZGWf0SV1UlBycmDl9/B+F5hwOexcBhc+AXfnfo2IdjqhFCLGmMtzp7L5DQjAPZ/rJbivU73P0XAixdXaX2DtNDjvfrJDy3PP54uxFl7r2wJ/lxroiTjtVL+FjwAJwL/GmAXGmAXAJmB37joRKSz8/KD3GAgq5R6KmpFyws26NIzm6Z5N+G3VLh77bjlq+u1DWRmw8BMY2Q4+vxYO7YXLXnOfce14NwRHOp1QCqc+wGvW2mbW2pestbsArLWHgBucjSZSDGVnwrQH3aNg2g1l9B/rmbtpH0/2aEz1sqFOpxMRTtGF2FqbBYwwxjwJ1MldvM5am+qTZCJyZsIrwJXvwYc9Ycr9ULrvCTe7pl0Ntu1PZWT8eqqUDuH28+uccDspIOnJ7qHds9+GxG0Q3RSu/AAa9QSXmoDIaT0O7Dh8xxgTAkRbazdZa391LpZIMTXvA9izBgZMZMnOQ7z28xoubVaJ3q2qOJ1MRHJ5Mg9sKrDUB1lE5L+qFQed/wd//B81aubAqkPgCgT/QPfX3Nv9rQNJ3WWYMG0OMSFpdG9Z4+h6dbotGIf2wd/vwtx3IXU/1OgIl78JdbroOZYzMQk4N8/97NxlbZyJI1KMpeyF+Oeg1vkcqnkhw9+aRfmIIJ7r2RSj/7dFCg19/C9S3HR+ADbPJmbjZ7DpsxNuYnCf1nk8GJiaezvMLwD8g8AVAK6gExbAx64/vH3e9Ye/P/P1oSmbYd+GE6/3c3n/+fuvDm6F2e/AgvGQeQjqd3cPEa7W1ulkUjT5W2szDt+x1mYYYwKdDCRSbMU/5x410+15nv5xFRv3pvDJTe2IDA1wOpmI5KECVqS48XPBtZOZO/VT2rZs5r6eJzsdsjPc12FmH70dSj3E2D9Wk5qayqB2VSgfQu62mZCVfsy27vuZR9enJeZbf/j7PPvb7DOO3xZg3klWGtcpCmBPC27vrA9N2QLf3AZLPndnbdrH3VW4gqbulP9ktzGmh7X2OwBjzBXAHocziRQ/CStg/lhocxPTd5fhs7kLuKVzLc6tXc7pZCKSz0kLWGNMq1PtaK39p+DjiEiBcPlzKKw6VG5xys1CgV4NU+k9chZfLzZMvq0DFSODCy5HTvapC9wTFNfLly6kcf26JyigPduf7AzITIXUA6cs3snOOG38M9EWwD8E2twE7W+H0tUL9PhSYg0FPjHGvI178MQW4HpnI4kUM9bC1BEQVIrdre9mxJilNK5cinsvqu90MhE5gVOdgX3lFOsscEEBZxERB1QpHcLYQW3oO3o2g8fP44tbziEiuICGS/m5wC8EAjyfOnp3Qjg0jyuYxz8Va489o3zKM84nKIDzrV/373bq9H4YwvRpvRQca+164BxjTDhgrLVJTmcSKXZWT4GNf5DT7f+498etHMrI4o3+LQj015Q5IoXRqboQn+/LICLinMaVIxl1bWtuGD+P2z75h7GD2hBQ3Oe6M8Y9FNi/YC4n3BofTx0Vr+IFxphLgcZA8OFGMtbapxwNJVJcZKXDtIehfAM+zLyAGWvW8nTPJtSpEOF0MhE5CY/+QjXGNDHG9DXGXH/45u1gIuJb59Urz/O9mzJz7R4e/Hqp5ogVKQSMMaOBfsAduIcQ9wFqOBpKpDj5ezTs38iWto/y3LT1dGlQgWvb6RIQkcLstE2cjDGPA3FAI2AKcAnwJ/ChV5OJiM/1ia3GtgOpvP7LWqqUDuHui+o5HUmkpDvXWtvMGLPEWvukMeYV4GunQ4kUC8m74I+XyK7TlZtnlaJUcDr/d1UzTZkjUsh5cgb2KqALsNNaOxhoDgR5NZWIOOauLnXp07oqb/y6li/mbXE6jkhJl5b79ZAxpjKQCcQ4mEek+Pj1KchKY3TwDazamcRLVzWnXLj+xBUp7DyZRifVWptjjMkyxpQCdgG1vJxLRBxijOG53k3ZmZjGg5OXEh0ZTOd65Z2OJVJSfW+MKQ28BPyDu4nie44mEikOti+ChR+zteENvDQ/m+vb1+D8BhWcTiUiHvDkDOz83DfP94AFuN9A53ozlIg4K8Dlx8hrWlEvOoLbPl7A8u0HnY4kUuIYY/yAX621B6y1X+G+9rWBtfYxh6OJFG250+bkhJblurWdqVMhnIe6a85ukaLitAWstfa23DfP0cBFwMDcocQiUoxFBAcwfnAbIkMCGDxuHtsOpDodSaREsdbmkGdKO2tturVWnyaJ/FfLJ8Pm2XwSdj1bUwN4o38LggNcTqcSEQ+dtoA1xvQyxkQCWGs3AZuNMT29nEtECoHoUsGMv6EtqZnZDB43l4OpmU5HEilpphtjrjTqKiNSMDJT4efH2F+qPo9vacX9XevTuHKk06lE5Ax4MoT48byf+FprDwCPey2RiBQq9aIjePe61mzck8ItH80nPSvb6UgiJck9wCQg3RiTaIxJMsYkOh1KpMj66y04uIW7DvTnnNrluamj2rqIFDWeFLAn2saT5k8iUkycW7scL/dpzpwN+/jfl0vIydEcsSK+YK2NsNb6WWsDrbWlcu+XcjqXSJGUuB3752vMCuzIYlcTXunbHD8/DW4QKWo8KUTnG2NeBd7B3f3wDtzNnESkBLmiRRW27k/lpWmrqVw6hAe6NXA6kkixZ4w570TLrbUzfJ1FpMj75Qmys7J4IK0Pzw1oSqXIEKcTichZ8KSAvQN4FPgcMMB04HZvhhKRwum2uNpsO5DKqPj1VCkdwrXn1HA6kkhxd3+e74OBtrg/RL7AmTgiRdSWebDkc97NuoJzWrXk0maVnE4kImfptAWstTYFGOGDLCJSyBljeKpHYxIOpvHYt8uoFBlMl4bRTscSKbastZfnvW+MqQa86FAckaIpJ4fsKf9jP2X4LqI/X/Vo7HQiEfkPTnoNrDHm9dyv3xtjvst/81lCESlU/F1+vHV1S5pUiWTYpwtZvOWA05FESpKtQBOnQ4gUKUu/wLXjH17I6s9z/dsTHqRWLiJF2al+gz/K/fqyL4KISNERGujPBwPb0HvULG6cMI+vb+1A9bKhTscSKXaMMW/h7j8B7g+dWwCLHQskUtSkJ5P20yOsyqlN1c6DaF2jjNOJROQ/OukZWGvtAmOMC7jZWvtH/psPM4pIIVQ+Iojxg9uSlWMZNG4u+1MynI4kUhzNx33N6wJgNvCAtfZaZyOJFB2Jv75EcNpuJpa9jWEX1HM6jogUgFNOo2OtzQbKG2MCfZRHRIqQ2uXDee/6WLYeSOXmD+eTlqk5YkUK2JfAx9baCdbaT4A5xhgNdxDxQPa+TQTPfYfvbUduu/Zq/F2ezB4pIoWdJ7/Jm4BZxphHjTH3HL55OZeIFBFtakbxWt8WLNi8n3u+WKQ5YkUK1q9A3rk+QoBfTreTMaabMWa1MWadMea4RozGmPuNMYtyb8uMMdnGmChP9hUpKjZ9di9Z1g9z4RO6zEWkGPGkgN0O/JC7bUSem4gIAJc2q8TD3RsyZelOnp2y0uk4IsVJsLU2+fCd3O9P+Zd47uU/7wCXAI2AAcaYRnm3sda+ZK1tYa1tATwI/GGt3efJviJFwYZ506i9+xd+LXs1l3aMdTqOiBQgT6bReRLAGBPhvnv0jVRE5LAbO8awdX8qH/y5kSqlQ7ihY4zTkUSKgxRjTCtr7T8AxpjWQOpp9mkLrLPWbsjdZyJwBbDiJNsPAD47y31FCp3UtAyyf3qAHZSj08AnMcY4HUlECtBpC1hjTBPcHYkPDy3aA1xvrV3u5WwiUoQYY3j0skbsOJjK0z+uoHLpYLo10UTxIv/RcGCSMWZ77v1KQL/T7FMF2JLn/lag3Yk2zL2ethsw7Cz2HQIMAYiOjiY+Pv40sTyTnJxcYMfyJeX2rVPl3jj/RwbnbGRatXsJWrjQt8FOozg+34WZcvueL7J7MhHWGOAea+3vAMaYOOA94FzvxRKRosjlZ3ijf0uufm8Od01cxKc3B9G6RpTTsUSKLGvtPGNMA6A+YIBV1trM0+x2otNNJ7s4/XJglrV235nua60dg/tvBGJjY21cXNxpYnkmPj6egjqWLym3b50s9++L1nF50kQ2l2pB1xsehUJ29rW4Pd+FnXL7ni+ye3INbNjh4hXAWhsPhHktkYgUacEBLt4f2IbKpUO4acJ8NuzWVQciZ8sYczvu9+Fl1tqlQLgx5rbT7LYVqJbnflXc/SxOpD9Hhw+f6b4ihcqupDS2fPskUSaJin1fK3TFq4gUDE8K2A25HYhr5t4eATZ6O5iIFF1RYYGMH9wGP2MYNG4ee5LTnY4kUlTdbK09cPiOtXY/cPNp9pkH1DXGxOROg9cf+C7/RsaYSKAz8O2Z7itS2FhrefnTKfTP+ZGkhv0IrNbK6Ugi4iWeFLA3AOWBr4HJud8P9mYoESn6apQN4/2BsexKSuPGCfM5lJHldCSRosjP5OlAk9sl+JRzs1trs3Bf0zoNWAl8Ya1dbowZaowZmmfTXsB0a23K6fYtsJ9GxEs+nP0vF219C/yDibz0aafjiIgXedKFeD9wpw+yiEgx07J6Gd7s35KhHy/gzs8W8e51rXH5aUiXyBmYBnxhjBmN+1rUocBPp9vJWjsFmJJv2eh898cD4z3ZV6QwW5OQRPxPExnn+gd7/pMQXsHpSCLiRZ50If6e4xs4HATmA+9aa9O8EUxEioeLG1fkiR6Neezb5Tzx3XKeuqKxpjQQ8dwDuDv93oq7wdJC3J2IRQRIz8pm+Kfzecv1Edmla+I651anI4mIl3nShXgD7mHDh5s89AMSgHq4uxFf551oIlJcXN++Jtv2p/LujA1ULRPCLZ1rOx1JpEiw1uYYY+YAtXC//0YBXzmbSqTweHnaamL3TKZ2wFbo9in4BzkdSUS8zJMCtqW19rw89783xsyw1p5njNF1MSLikQe6NWD7wTSe/2kVlUqH0KN5ZacjiRRaxph6uBsoDQD2Ap8DWGvPdzKXSGHy59o9TJq5hL/CvobqnaF+d6cjiYgPeFLAljfGVLfWbgYwxlQHyuWuy/BaMhEpVvz8DC/3aUZCYhr3fbGYChFBnFOrrNOxRAqrVcBM4HJr7ToAY8zdzkYSKTySMyxPT1rE4xHfEZKVAt1e0LQ5IiWEJ12I7wX+NMb8boyJx/2Ger8xJgyY4M1wIlK8BPm7eO+6WKqXDWXIh/NZm5DkdCSRwupKYCfwuzHmPWNMF9zXwIqUeNZaxi9PJyplPT2zpmJib4DoRk7HEhEfOW0Bm9uNsC4wPPdW31r7o7U2xVr7ulfTiUixExkawPjBbQgKcDFo3Dx2JaoPnEh+1trJ1tp+QAMgHrgbiDbGjDLGXOxoOBGHTVqwlfkJWYyp8DUmKBziHnI6koj40GkLWGNMKHA/MMxauwioZoy5zNvBRKT4qlomlHGD2rD/UAaDx88jOV1zxIqcSO6HxZ9Yay8DqgKLgBHOphJxzqY9KTzx3XIGllpEtf1z3MVrmC5HESlJPBlCPA73ta7tc+9vBZ7xWiIRKRGaVInknWtasWpnErd/8g9Z2TlORxIp1Ky1+6y171prL3A6i4gTMrNzGP75IoL9srnP72MoVx/a3Oh0LBHxMU8K2NrW2heBTABrbSq6DkdECsD59SvwbM8m/LFmN498swxr8085LSIi4vbWb+tYtOUAHzddRETaDuj6HLgCnI4lIj7mSRfiDGNMCGABjDG1gXSvphKREqN/2+psO5DKW7+to0rpEJq6nE4kIiKFzYJ/9/H2b2u5vlkojdaMZm9ULGXrXuh0LBFxgCdnYJ8ApuK+9vUT4FfgAW+GEpGS5Z6L6tG7VRVe+XkNs7ZlOh1HREQKkaS0TO6auIgqZUJ4JOQryDzEujqDnY4lIg457RlYa+10Y8wC4BzcQ4fvstbu8XoyESkxjDG80LsZuxLTGbtsD53X7qFj3XKn31FERIq9x79bzvYDqfzQJ5LA7z6Gc24jNbiq07FExCGedCH+1Vq7N3fqnB+stXuMMb/6IpyIlByB/n6MvLYVlcIMQz9ewModiU5HEhERh/2wZDtf/7ONYefXodHi5yA0Cjr/z+lYIuKgkxawxphgY0wUUM4YU8YYE5V7qwlU9llCESkxSgUHcE9sMOFB/gweN48dB1OdjiQiIg7ZfiCVh75eSotqpbmr0gr4dxZc8AiElHY6mog46FRnYG8BFuCeRH1Bntu3wDvejyYiJVFUsB/jBrchJT2LwePmkZima2JFREqa7BzLPV8sIjvH8uZV9XH9+hhEN4FWA52OJiIOO2kBa619w1obA9xnra1lrY3JvTW31r7tw4wiUsI0rFSK0de1Zt2uZG79eAEZWZojVkSkJHlv5gbmbNjH4z0aU331ODiwGbo9D35qVS9S0p32Glhr7VvGmCbGmL7GmOsP33wRTkRKrg51yvF/VzZj1rq9jPh6ieaIFREpIZZtO8gr01dzSZOK9KnngpmvQcPLIeY8p6OJSCHgSROnx4G3cm/nAy8CPTw5uDGmmzFmtTFmnTFmxCm2a2OMyTbGXOVhbhEpAa5sXZV7L6rH1/9s49Wf1zgdR0REvCw1I5s7Jy4kKiyQ53o1xfz6FORkwkVPOx1NRAoJT+aBvQroAuy01g4GmgNBp9vJGOPCfa3sJUAjYIAxptFJtvs/YNoZ5BaREmLYBXXo36Yab/22js/mbnY6joiIeNGzU1awYXcKr/ZtQZn9S2DxZ9B+GETFOB1NRAoJTwrYVGttDpBljCkF7AJqebBfW2CdtXaDtTYDmAhccYLt7gC+yj2uiMgxjDE807MJneuV55FvlvH7av1XISJSHP26MoGP52zm5k4xdKgVBT89AOHR0Okep6OJSCHi78E2840xpYH3cHchTgbmerBfFWBLnvtbgXZ5NzDGVAF6ARcAbU52IGPMEGAIQHR0NPHx8R48/OklJycX2LF8Sbl9S7l962S5+1e3bNppGPrhPB5sG0zNyMLVyKO4Pd9FQVHOLiLH2p2Uzv++XELDSqW4r2t9WDoJts2HK0ZCUITT8USkEDltAWutvS3329HGmKlAKWvtEg+ObU50uHz3XwcesNZmG3OizY9kGAOMAYiNjbVxcXEePPzpxcfHU1DH8iXl9i3l9q1T5W7dNo1eI//inWU5fH1rW6pFhfo23CkUx+e7sCvK2UXkKGst//tyMcnpWXzWvwVBOWnwyxNQuSU0H+B0PBEpZE46hNgY0zV/UyVr7SagqTHmIg+OvRWolud+VWB7vm1igYnGmE24r7UdaYzp6cGxRaQEqlAqmAk3tCE9M5vB4+dx8JDmiBURKeo+mvMvv6/ezUPdG1IvOgL+fB2StkO3/wM/T652E5GS5FT/KzwJ/HGC5b8CT3lw7HlAXWNMjDEmEOgPfJd3g9x5ZWtaa2sCXwK3WWu/8SS4iJRMdSpE8N71sWzee4ibP5pPela205FEROQsrU1I4tkfVxJXvzzXt6/hnu/1rzehyVVQvd3pDyAiJc6pCthQa+3u/AuttTuBsNMd2FqbBQzD3V14JfCFtXa5MWaoMWbo2QYWEWlXqywv923O3I37uPeLxeTkaI5YEZGiJj0rm7smLiIsyJ8Xr2qGMQZ+fgwwcNGTTscTkULqVNfABhtj/HML0SOMMQFAiCcHt9ZOAabkWzb6JNsO8uSYIiIAPZpXZseBVJ7/aRVVSofwYPeGTkcSEZEz8Mr0NazYkcj718dSISIY/v0Llk+GuAchsqrT8USkkDrVGdivgfeMMUfOtuZ+Pzp3nYiIo4acV4vr29fg3Rkb+HD2JqfjiIiIh/5at4f3Zm7gmnbVubBRNORku6fNKVUVzr3T6XgiUoidqoB9BEgA/jXGLDDGLAA2Abtz14mIOMoYw+OXN+bChtE88d1ypi/f6XQkERE5jQOHMrjni8XElAvjkUsbuRcu+gR2LnEPHQ4sPB3mRaTwOWkBa63NstaOwN1JeFDurbq1doS1Vq0/RaRQcPkZ3hrQkqZVS3PnxIUs3Lzf6UgijjPGdDPGrDbGrDPGjDjJNnHGmEXGmOXGmD/yLN9kjFmau26+71JLSWCt5aHJS9mTnM4b/VoSEuiCtET49Smodg40udLpiCJSyJ22N7m1NtVauzT3luqLUCIiZyIk0MUHA93XUN00YT7/7k1xOpKIY4wxLuAd4BKgETDAGNMo3zalgZFAD2ttY6BPvsOcb61tYa2N9UFkKUG+XLCVKUt3cu/F9WlaNdK9cMZLkLIbuj0PxjgbUEQKPU2uJSLFQrnwICbc0JYcaxk0bh77UjKcjiTilLbAOmvtBmttBjARuCLfNlcDX1trNwNYa3f5OKOUQP/uTeGJ75bTLiaKIefVci/cux7mjIIW10KVVs4GFJEi4VRdiEVEipSYcmG8P7ANV783h5smzOPTm88hOMDldCwRX6sCbMlzfyuQf0LNekCAMSYeiADesNZ+mLvOAtONMRZ411o75kQPYowZAgwBiI6OJj4+vkDCJycnF9ixfEm5Ty07x/Lc32nk5OTQt3oqM2e4R603WfocpY2LuSEXknEGOfR8+5Zy+1ZRzQ2+yX7aAtYYY4BrgFrW2qeMMdWBitbauV5NJiJyFlrXKMMb/Vty6ycLuGviQkZe0xqXn4akSYlyohd8/smS/YHWQBfcU+PNNsbMsdauATpYa7cbYyoAPxtjVllrZxx3QHdhOwYgNjbWxsXFFUj4+Ph4CupYvqTcp/baz2tYf3Atbw5oSY/mld0L1/8O8X9Dl8c5t1OvMzqenm/fUm7fKqq5wTfZPRlCPBJoDwzIvZ+E+9oaEZFCqVuTijx2WSOmLU/g6R9WYG3+v91FirWtuBswHlYV2H6CbaZaa1OstXuAGUBzAGvt9tyvu4DJuIcki5y1Bf/u563f1tK7ZZWjxWt2Fkx9EMrUhHNuczSfiBQtnhSw7ay1twNpANba/UCgV1OJiPxHgzvEcGPHGMb/tYkP/tzodBwRX5oH1DXGxBhjAoH+wHf5tvkW6GSM8TfGhOIeYrzSGBNmjImAI3O/Xwws82F2KWaS07O4+/NFVC4dwpNXND66YsE42L0SLn4GAoKdCygiRY4n18Bm5nY0tADGmPJAjldTiYgUgIe7N2THwVSe+XEllSJDuLRZJacjiXidtTbLGDMMmAa4gLHW2uXGmKG560dba1caY6YCS3C/p79vrV1mjKkFTHZfPYQ/8Km1dqozP4kUB098t5yt+w/xxS3tiQgOcC88tA9+fxZqdoIGlzkbUESKHE8K2DdxDyGqYIx5FrgKeMSrqURECoCfn+HVvi3Ylfg3d3+xiAqlgmhTM8rpWCJeZ62dAkzJt2x0vvsvAS/lW7aB3KHEIv/Vj0t28OWCrdx5QR1i8/7f+8f/QdpB6PaCps0RkTPmyTywnwD/A54HdgA9rbWTvB1MRKQgBAe4eO/6WKqWCeHmD+ezfney05FERIq9HQdTeWjyUppXK80dXeoeXbFrFcx9D1oPgopNHMsnIkXXaQtYY0xtYKO19h3c18FclDsBuohIkVAmLJAJg9vi72cYNG4uu5PSnY4kIlJs5eRY7v1iMZnZObzRrwUBrtw/N62FaQ9BYDic/7CzIUWkyPKkidNXQLYxpg7wPhADfOrVVCIiBaxaVChjB7VhT1IGN06Yx6GMLKcjiYgUS+//uYG/1u/l8csbUbNc2NEVa6fD+l8hbgSElXMuoIgUaZ4UsDnW2iygN+6Jzu8G1AlFRIqcZlVL8/bVLVm27SDDPl1IVrb60YmIFKRl2w7y0rTVdGtckb6xeWZzyspwn30tWxfa3uxcQBEp8jwpYDONMQOA64EfcpcFeC+SiIj3dGkYzVNXNOG3Vbt47LvlmiNWRKSApGZkM/zzRUSFBfJ876aYvA2a5o6Bveug63Pg0p+RInL2POlCPBgYCjxrrd1ojIkBPvZuLBER77n2nBpsO5DKqPj1VC0Twm1xdZyOJCJS5D3/00rW7UrmoxvbUiYs8OiKlD3wx4tQ5yKod7FzAUWkWDhlAZs7/+tD1tprDy+z1m4EXvB2MBERb7r/4vpsP5DKi1NXU6V0CFe0qOJ0JBGRIuu3VQl8OPtfbuwYQ6e65fOtfAYyU9xnX0VE/qNTFrDW2mxjTHljTKC1NsNXoUREvM3Pz/DiVc1ISEzjvkmLKR8RxLm11VRERORM7UlO539fLqFBxQju71r/2JU7l8I/E6DtLVC+njMBRaRY8eQa2E3ALGPMo8aYew7fvJxLRMTrgvxdvHtdLDHlwrjlowWs3pnkdCQRkSLFWsv/vlxCYloWbw5oSXCAK+9KmPogBJeGuAccyygixYsnBex23M2b/ICIPDcRkSIvMiSAcYPbEhroYvC4uSQkpjkdSUSkyPj47838tmoXD17SgHrR+f48XPk9bJoJFzwMIWWcCSgixc5pmzhZa5/0RRAREadUKR3C2EFt6Dt6NoPGzeOLW84hIlhdMkVETmXdriSe+WEFneuVZ9C5NY9dmZkG0x+GCo2g1SAn4olIMXXaM7C518C+ZIyZYoz57fDNF+FERHylceVIRl7bmjUJSdz2yT9kao5YEZGTysjK4a6JiwgL8uelPs2OnTIHYM47cGAzdHseXJ5MeiEi4hlPhhB/AqwCYoAncV8TO8+LmUREHNG5Xnme792UmWv38NDXSzVHrIjISbzy82qWb0/k/65sRoWI4GNXJu6AGa9Ag8ugVpwj+USk+PKkgC1rrf0AyLTW/mGtvQE4x8u5REQc0Te2Gnd1qcukBVt549e1TscRESl0/lq/hzEzNjCgbXUuahR9/Aa/PgU5mXDx074PJyLFnidjOjJzv+4wxlyKu6lTVe9FEhFx1vAL67L9QCqv/7KWyqVD6BtbzelIIiKFwsFDmdz7xWJiyobx6GUNj99g2wJY/Cl0GA5RtXyeT0SKP08K2GeMMZHAvcBbQCngbq+mEhFxkDGG53o3ZWdiGg99vZSKpYI5r155p2OJiDjKWstD3yxld1I6k2/rQGigf/4N4KcREFYBzrvPmZAiUuyddgixtfYHa+1Ba+0ya+351trW1trvfBFORMQpAS4/Rl7TirrREdz68QKWbz/odCQREUd9/c82flyyg7svqkfTqpHHb7D0S9g6F7o8BkGacVFEvMOTLsS1jDHfG2P2GGN2GWO+NcZoTIiIFHsRwQGMH9yGyJAABo+bx7YDqU5HEhFxxOa9h3js22W0jYliaOfax2+QkQK/PA6VWkCLa3yeT0RKDk+aOH0KfAFUBCoDk4DPvBlKRKSwiC4VzLjBbUnNzGbwuLkcTM08/U4iIsVIVnYOwz9fiJ+f4dW+zXH5meM3mvUmJG6Dbi+Anyd/XoqInB1P/ocx1tqPrLVZubePAc0tISIlRv2KEbx7XWs27knhlo/mk56V7XQkERGfeef39fyz+QDP9GxC1TKhx29wYAvMeh0a94Ya7X2eT0RKFk8K2N+NMSOMMTWNMTWMMf8DfjTGRBljorwdUESkMDi3djleuqo5czbs44Evl2iOWBEpEf7ZvJ83f1tLzxaVuaJFlRNv9Mvj7q8XPeW7YCJSYnnShbhf7tdb8i2/AfeZWF0PKyIlQs+WVdh2IJWXpq2mcukQ/tetgdORRES8Jjk9i+ETF1GxVDBP9Wxy4o3+nQ3LvoLOD0BpTTkmIt532gLWWhvjiyAiIkXBbXG12XYglZHx66lSJoRr2tVwOpKIiFc8+d1ytu4/xMQh7SkVHHD8Bjk5MHUERFSGDnf5PqCIlEgnHUJsjGljjKmY5/71uR2I39TQYREpqYwxPNWjMV0aVODRb5bx68oEpyOJiBS4n5buYNKCrdwWV4e2MSf5s2/xp7BjkXvocGCYT/OJSMl1qmtg3wUyAIwx5wEvAB8CB4Ex3o8mIlI4+bv8eOvqljSuHMmwTxeyeMsBpyOJiBSYHQdTGfH1UppXjeSuC+ueeKO0RPjlSajaFppe5duAIlKinaqAdVlr9+V+3w8YY639ylr7KFDH+9FERAqv0EB/PhgUS9nwQG6cMI9dh3KcjiQi8p/l5Fjum7SYjKwcXu/fkgDXSf5UnPkKpOyCS14Ac4JpdUREvOSUBawx5vA1sl2A3/Ks86T5k4hIsVYhIpjxg9uSmW15ZX4a63cnOx1JROQ/+eDPjcxat5fHL29ETLmTDAvetwHmjITmV0OV1r4NKCIl3qkK2M+AP4wx3wKpwEwAY0wd3MOIRURKvDoVwhk7KJaUTMtlb/7JF/O3aIodcZwxppsxZrUxZp0xZsRJtokzxiwyxiw3xvxxJvtK8bR8+0FemraaixtF06/NKToKT38U/AKgy2O+CycikuukBay19lngXmA80NEe/YvMD7jD+9FERIqG1jWieLpDCC2qleZ/Xy7hzomLSEzLdDqWlFDGGBfwDnAJ0AgYYIxplG+b0sBIoIe1tjHQx9N9pXhKy8zmromLKB0awAtXNsOcbFjwhj9g1Q/Q6R4oVcm3IUVEOPUZWKy1c6y1k621KXmWrbHW/uP9aCIiRUeZYD8+vqkd93etz5SlO+j+xkz+2bzf6VhSMrUF1llrN1hrM4CJwBX5trka+NpauxnAWrvrDPaVYuj5KStZtyuZl/s0Jyos8MQbZWfB1AehdHVoP8y3AUVEcp2ygBUREc+5/Ay3n1+HL25pD0Cf0bN55/d1ZOdoSLH4VBVgS577W3OX5VUPKGOMiTfGLDDGXH8G+0ox8/vqXUyY/S83dIjhvHrlT77hPxNg13K4+BkICPZdQBGRPNSMSUSkgLWuUYYpd3Xioa+X8tK01cxat4fX+rUgupT+4BOfONHYz/yfovgDrXE3aQwBZhtj5ni4r/tBjBkCDAGIjo4mPj7+bPMeIzk5ucCO5UtFNfeOfck8/9t8qoYbzglNID5+1wm3889Mpt3fj5MS2YRFCaVgV7xvg+ZTVJ9v5fYt5fY9X2RXASsi4gWlggN4a0BLzqtbnse/W06312fwcp/mdGkY7XQ0Kf62Ank78FQFtp9gmz25lwilGGNmAM093BcAa+0YcueFj42NtXFxcQUSPj4+noI6li8VxdzWWnq+Oo20HMsXN3WgQcVSJ9946oOQnULp/qOIq9TMdyFPoig+36DcvqbcvueL7BpCLCLiJcYY+rapxg93dqRSZAg3TpjPE98tJy0z2+loUrzNA+oaY2KMMYFAf+C7fNt8C3QyxvgbY0KBdsBKD/eVYuLjvzezeHc2I7o1OHXxunsNzB0Dra6HQlC8ikjJpjOwIiJeVrt8OJNvP5cXflrFuFmb+HvjPt4a0II6FSKcjibFkLU2yxgzDJgGuICx1trlxpihuetHW2tXGmOmAkuAHOB9a+0ygBPt68gPIl6TmJbJCz+t4tO/N9OknItB59Y89Q7THoKAUDj/EZ/kExE5FRWwIiI+EOTv4vHLG9Opbjnum7SEy9+axRM9GtE3ttrJp6sQOUvW2inAlHzLRue7/xLwkif7SvHxy4oEHvlmGbuS0ri5UwyxwQn4+Z3i/6C1P8O6n+HiZyH8FA2eRER8REOIRUR86IIG0Uy9qxOtapTmga+WMuzThRxM1ZyxIuJde5LTGfbpP9z04XxKhwYw+bYOPHxpI4JcpyheszPd176WrQNth/gurIjIKegMrIiIj1UoFcxHN7Tj3RkbeGX6ahZtOcCbA1rQukaU09FEpJix1jJ54Tae+mEFh9KzufeietzSuTaB/h6cw5j7HuxdCwM+B/+TzA0rIuJjOgMrIuIAPz/DrXG1mTS0PX5+0PfdObz161rNGSsiBWbr/kMMHDePe75YTO3y4Uy5qyN3dKnrWfGashf+eAFqd4F6Xb0fVkTEQzoDKyLioJbVy/DjnZ14ZPIyXvl5DX+u28Pr/VtQKTLE6WgiUkRl51g+mr2JF6etxgBP9mjMdefUOPW1rvn9/iykJ0PX50DX6YtIIaIzsCIiDisVHMAb/Vvwcp/mLN12kEvemMn05TudjiUiRdDahCT6jP6LJ75fQduYKKbf05mB59Y8s+J15zJYMA7a3AQVGngvrIjIWdAZWBGRQsAYw1Wtq9Kqemnu+GwhQz5awPXta/BQ94YEB7icjicihVxGVg6j4tfzzu/rCAty8Vq/5vRsUeXMu5xbC9MehOBIiBvhnbAiIv+BClgRkUKkVvlwvr7tXF6aupr3/9zI3I37eGtAS+pGa85YETmxRVsO8MCXS1idkESP5pV57PJGlAsPOruDrfoRNs6A7i9DqBrLiUjh49UhxMaYbsaY1caYdcaY4z7GM8ZcYYxZYoxZZIyZb4zp6M08IiJFQZC/i0cua8S4wW3YnZTO5W//yad/b8ZaNXgSkaMOZWTx9A8r6D1yFgdTM/lgYCxvDmh59sVrVjpMfxjKN4TWgws2rIhIAfHaGVhjjAt4B7gI2ArMM8Z8Z61dkWezX4HvrLXWGNMM+ALQxRYiIsD59Svw0/BO3PvFYh6avJSZa3fzQu9mRIYGOB1NRBz259o9PDh5CVv2pXLtOdV5oFsDIoL/4/8Nc0bC/k1w3Tfg0iA9ESmcvHkGti2wzlq7wVqbAUwErsi7gbU22R49pRAG6PSCiEgeFSKCmTC4LQ9e0oCfVyRwyRszmLdpn9OxRMQhBw9lcv+kxVz7wd8E+Pnx+ZBzeKZn0/9evCYlwIyXoX53qH1+wYQVEfECb368VgXYkuf+VqBd/o2MMb2A54EKwKUnOpAxZggwBCA6Opr4+PgCCZicnFxgx/Il5fYt5fYt5T6x+sBD7YIYvTidvqNn07NOAJfXDsDvP05vUVSfbyja2UXOxk9Ld/Dot8vZfyiD2+Jqc2eXugXX5O3Xp9xDiC9+pmCOJyLiJd4sYE/0V9VxZ1ittZOBycaY84CngQtPsM0YYAxAbGysjYuLK5CA8fHxFNSxfEm5fUu5fUu5Ty4O6Nsti0e/WcbkhdvYlh3B6/1aULn02c8ZW1Sfbyja2UXOxK7ENB79dhnTlifQpEopJtzQhsaVIwvuAbYvhEWfwLl3QNnaBXdcEREv8OYQ4q1AtTz3qwLbT7axtXYGUNsYU86LmUREirTwIH9e69eCV/s2Z3nunLFTl2nOWJHiyFrLxLmb6fLqH8Sv3s2ISxrwzW0dCrZ4tRZ+GgFh5eC8+wvuuCIiXuLNAnYeUNcYE2OMCQT6A9/l3cAYU8fkTlBmjGkFBAJ7vZhJRKRY6N2qKj/c2YnqUaEM/XgBj3yzlLTMbKdjiUgB+XdvCte8/zcjvl5Ko0qlmDr8PIZ2ro2/q2D/dKuwayZsmQMXPArBpQr02CIi3uC1IcTW2ixjzDBgGuACxlprlxtjhuauHw1cCVxvjMkEUoF+VvNEiIh4JKZcGF/dei4vT1/NmBkbcueMbUX9ipozVqSoysrOYeysjbz68xoC/Px4rldT+rephp/ff7ve/YQyDlFrwwSo2AxaXlvwxxcR8QKv9ki31k4BpuRbNjrP9/8H/J83M4iIFGeB/n481L0hHeqU494vFtPj7T955LJGXNuuOuY/NngSEd9asT2REV8vYcnWg1zYMJpnejahYmSwdx4sMw3inyM4fQ9c8hH4FVAzKBERL9MkXyIixUDneuX56a5O3DtpMY9+s4yZa3bz4lXNKB0a6HQ0ETmNtMxs3v5tHaP/WE/p0ADevrollzatVPAfQiVuh7XTYc002BAPmYdIqHAe0TXOLdjHERHxIhWwIiLFRPmIIMYPasPYWRv5v6mruOSNmbzerwXtapV1OpqInMS8TfsY8dUS1u9O4cpWVXnk0oaUCSugD55yctwdhtdMdd92LnEvj6wOLa6Bet1YtQWiC+bRRER8QgWsiEgx4udnuKlTLdrFlOWOz/5hwHtzGHZBXe68oE6BN38RkbOXnJ7Fi1NX8eHsf6lSOoQJN7Slc73y//3AaYmw4Xf3Wda10yFlNxg/qNYOLnwC6nWD8g0g9+yu3Rb/3x9TRMSHVMCKiBRDTatG8sOdnXj82+W8+eta/lq3h9f7t6BqmVCno4mUeL+v2sXDk5eyIzGNwR1qct/F9QkL+g9/ku1dn1uwToNNsyAnE4Ijoc5F7oK1ThcIjSq4H0BExEEqYEVEiqnwIH9e6ducTnXL8cg3y+j+xkxeuLIZ3ZtWcjqaSIm0LyWDp75fzjeLtlO3QjhfDj2X1jXKnPmBsjNh82x30bpmGuxd615evgG0v81dtFZtCy79mScixY/+ZxMRKeZ6tqxCy+qlufOzhdz2yT8MaFudxy5rREiguo6K+IK1lu8Wb+fJ71eQlJbJXV3qctv5tQnyP4PfwZS9sO5n97Ws636D9IPgCoSanaDtzVD3YoiK8d4PISJSSKiAFREpAWqUDWPS0HN59ec1jP5jPfM27eOtAS2djiVS7G0/kMoj3yzjt1W7aF6tNC9e2cyzuZqthYTluQ2YpsHWeYCF8Gho1MN9lrVWHASFe/tHEBEpVFTAioiUEIH+foy4pAEd6pTlni8Wc8U7s+hb15/O1mrOWJEClpNj+eTvf/m/qavJzrE8elkjBp1bE5ffKX7XMlNh44zconU6JG51L6/cEuJGQL2uULE5+Kkhm4iUXCpgRURKmE513XPG3j9pMR+v3M3ODxfw0lXNCm7qDpESbv3uZEZ8tYR5m/bTsU45nv//9u48vIr63uP4+5sQ9k0IRCBsQhDZd9lEtKKIVFyw4lqtt1b7oGBvrUsXreVarU9bQVSk1vtobxVbBQuKKKJhVUTZF4UQUREUAogGEUjyvX+co8aYkAMmM3PC5/U852HOzJzxc75BfvmemTO/C7rSslEZN1Dbu/WbOwbnzoeC/ZBWB9qdFmtas4ZBveODfQMiIhGmBlZE5BiUXrcGj13Vl9sff4VnNu7g7IkL+evFPRjQTnPGihytQ4VFTF2Qy8R5m6iVlsp9o7sxunfmt69wKCqEj97+5gZMn6yJrW/YGnr/OHaWtfUgqFYjnDchIhJxamBFRI5RZsZZbdK4bFg/bnxqBZc++gZjT2vPuB9kac5YkSO0ZW8h905ezIbtn3FO12bccW4nmtarGdv45V7Y/Oo3Z1q/2AWWCq0GwLC7Yt9nTe/w9dysIiJSNjWwIiLHuC4tGjDrhsHcOXMdD7yaw+KcPCaO6Vn2JY8i8rX9Bwu5/5WNTH39S5rUcx65ojdndT4e8nJgzZzY91k/eB2KCqDWcfG5Wc+Kzc1a6yim0BEROcapgRUREerUqMZ9F3VncFY6v5mxlhGTFvLHC7oyslvzsKPJUTCz4cBEIBV41N3vKbF9KPAf4L34qunufld82xbgc6AQKHD3PsGkTj5LNudx2/Q1vL/rC05vAZPOMOq+PxHmzYHdubGdmnaCgTfE52btCymavkpE5PtQAysiIl8b1aMFvVodx43TVjD2yRUs3JjHHed2onZ1DRfJwsxSgQeBYcBWYJmZzXT39SV2XejuI8s4zGnunleZOZPZ3v2HuOfFDbz85lpG11/PtR020eCj+VR7ej+k1oC2Q6D/z2NnWhu2CjuuiEiVot9IRETkW1o2qs2/fjaA+1/ZyEPZm1n2fmzO2M7NG4QdTRLTD8hx91wAM5sGjAJKNrBypNxZsvg1Vr/6ND8qeIu7a27GDjrsaca2pkNoPvTqWPNavU7YSUVEqiw1sCIi8h1pqSncfFZHBrVLZ/zTKzn/wSXcNqIjVw1sozljo68F8GGx51uBk0vZb4CZrQK2Ab9093Xx9Q68bGYOPOLuU0v7j5jZtcC1ABkZGWRnZ1dI+Pz8/Ao7VkVIKfyS4/asou6Ot6i/8y0G+m76Y+TVbc+Wppewq3Ff8uu2JX/fPjZurwXbl4Ud+YhErd6JUu5gKXewkjU3BJNdDayIiJRpYPt05owfws3/XsXvZ61n0aY8/jS6G43raoqPCCvtEwYv8Xw50Nrd881sBPAckBXfNsjdt5lZU2Cumb3j7gu+c8BYYzsVoE+fPj506NAKCZ+dnU1FHeuoffrB19Pc+HsLsMID5FOLhUXdqH7ScIaMuJSmDWJzs7aNvyQSuY+CcgdLuYOl3MELIrsaWBEROaxGdarz6I/78PiSLdw9+x3OnriQ+y/uwcD26WFHk9JtBVoWe55J7Czr19z9s2LLs83sITNLd/c8d98WX7/DzGYQuyT5Ow1slVJUCFuXxe4YvPEl2BG72vpQg7bMqzWCJ3afhLfszx8u7E37pnVDDisicmxTAysiIuUyM64a1Ja+bRtx41MruOzvS7n+1HbcNKwDaZozNmqWAVlm1hb4CBgDXFp8BzM7HvjE3d3M+gEpwC4zqwOkuPvn8eUzgbuCjR+Q/XsgZ16sYc2ZG3ueUg1aDaBo2ASeye/CHYsOkGJw6w87ctnJrUlJ0eXzIiJhUwMrIiIJ69w8NmfsXbPW81D2ZpZs3sUDl2jO2Chx9wIzGwu8RGwancfcfZ2ZXRffPgUYDVxvZgXAfmBMvJnNAGbEv+dcDXjS3eeE8kYqmjvkbYyfZX05NjerF0LtxrEpbjqcBe1O591PU7jl2dWs/PBTTjuxCRPO70qLhrXCTi8iInFqYEVE5IjUrl6Ney7sxuCsdG6bvoYRExcy4fwujOrRIuxoEufus4HZJdZNKbY8GZhcyutyge6VHjAoBQdgyyLY9HKscd2zJbY+oysMvinWuLboBSmpHCgo5MHXNvNwdg71aqYxcUwPzu3eXDctExGJGDWwIiJyVEZ2a073zIaMm7aCcdNWsmhTHnee25k6NTS0SIg+/+SbhnXza3BoH1SrCScMhUHjIOtMaJD5rZcs/2APtzyzmk078jmvR3N+O7KTblQmIhJR+i1DRESO2ldzxk6ct4nJr+Xw9vt7mHRJT7q00JyxEpCiIvh4VfyuwXNg24rY+vqZ0P3i2FnWNqdA9e9e5r7vQAH3vfQuj7++hWb1a/K/V/XltI5NA34DIiJyJNTAiojI91ItNYX/PvNEBrZLZ/zTKzj/ocXcMrwj1wxuq8svpXIcyIfc7FjDumku5H8MGGT2hdN/G2taMzrDYf7+Ldi4k9umr+GjT/dz5YDW/Gp4R+rq6gERkcjTv9QiIlIhBrRrzIvjhvCrZ1Yz4YUNLM7J476LupOuSzGlIux+75tLg7csgsKDUKM+tP9BrGFtfwbUKX9qpz37DvKHF9YzfflHnNCkDv++bgB92zQK4A2IiEhFUAMrIiIVplGd6vztyt784433mfDCBs6euJC//Kg7p2Q1CTuaJJvCAvhwafws68uw853Y+sZZ0O/aWNPaqj+kpiV0OHfnhTXbuXPmOj794hBjT2vP2NPbUzMttRLfhIiIVDQ1sCIiUqHMjCsHtKFvm0bc8NQKrvj7m/zs1BP45Zknas5YObwvdtP0k2x45h+xuVm/3AspadBmEPS+KnYDpsbtjviwH+/9kt88t5ZXNnxC1xYNeOInJ9Opef0Kjy8iIpVPDayIiFSKk5rVZ9bYwdz1/HoemZ/LG5t3MemSnrRuXCfsaBJFOzbAwwPp5EVQpwl0HBmbm/WE06Dm0TWbRUXOtGUf8sfZGzhUVMTtIzryk0FtqaYPUkREkpYaWBERqTS1qqfyxwu6ckpWOrc+u5pzJi1iwnldOK+n5oyVEtJPhKG38/beBvQe+V+Q8v2azPfy9nHrs6tZ+t5uBpzQmHsu7KoPT0REqgA1sCIiUulGdG1G95YNGT9tBeOfXsmCTTu5a1QX3fVVvpGSAqfezOfZ2d+reS0oLOLRRe/x17kbqV4thXsu6MrFfVvqjtgiIlWEfnMQEZFAtGhYi6d+2p8HXs3hgVc3sfz9PTxwSS+6ZmrOWKkY67bt5ZZnV7P2o884s1MGfzivCxn1a4YdS0REKpC+BCIiIoGplprCTcM68NRP+3OgoIgLHl7M3xbkUlTkYUeTJPbloULunfMO505ezMd7D/DQZb145Ireal5FRKognYEVEZHAnXxCY14cdwq3PLua/5m9gYU5efz5ou40qac5Y+XILM3dxW3T15Cbt4+Lemfy63NOomHt6mHHEhGRSqIzsCIiEoqGtasz5fLeTDivC0tzd3H2xAXM37gz7FiSJD7/8hC/nrGGi6e+wcHCIv5xTT/uu6i7mlcRkSpODayIiITGzLi8f2tmjh1MozrV+fFjb3L37A0cLCgKO5pE2LwNn3DmXxfw5JsfcM3gtrx80xBOyWoSdiwREQmALiEWEZHQnXh8PWaOHcyEF9YzdUEur8fnjG2brmlP5Bt5+Qf4/az1zFq1jQ4ZdXnosoH0bHVc2LFERCRAOgMrIiKRUDMtlQnndWXK5b35YPcXjJy0kOnLt4YdSyLA3Zm+fCvD/jKfOWu3c9MZHXj+hlPUvIqIHIN0BlZERCJleJfj6ZbZgPHTVvKLf61i4aY87hrVmXo108KOJiHYuucLfj1jLfM37qRnq4bce2E3OmTUCzuWiIiERA2siIhETvOGtXjq2v5MfjWHifM2svyDPUwa05PuLRuGHU0CUlTkPPH6Fv700rsA3PHDTlw5oA2pKRZyMhERCZMuIRYRkUhKTTHGnZHF0z8bwKGCIi58eAlT5m/WnLHHgE2ffM7oKUu4c9Z6erc+jpfGD+HqQW3VvIqIiM7AiohItPVt04gXxw3h1umruefFd1gcnzNWqp6DBUX8J+cgL8xdRO0aqfz5ou5c0KsFZmpcRUQkRmdgRUQk8hrUTuOhy3px9/ldWbZlN2dPXMiGXYVhx5IKtCVvH+dOXsSMnEOc2TmDuTedyoW9M9W8iojIt6iBFRGRpGBmXHpyK2aNHUzLRrVpUEONTVWSXq8GdWpUY1yvGky+tBdN6tUIO5KIiESQGlgREUkqWRn1mPHzgTSvqyGsKqlboxrPXDeAnk317SYRESmbRn8REUk6uqy0atLPVUREyqMGVkRERERERJKCGlgRERERERFJCmpgRUREREREJCmogRUREREREZGkoAZWRESkijGz4Wb2rpnlmNmtpWwfamZ7zWxl/PG7RF8rIiISJt2rXkREpAoxs1TgQWAYsBVYZmYz3X19iV0XuvvIo3ytiIhIKHQGVkREpGrpB+S4e667HwSmAaMCeK2IiEil0xlYERGRqqUF8GGx51uBk0vZb4CZrQK2Ab9093VH8FrM7FrgWoCMjAyys7O/f3IgPz+/wo4VJOUOlnIHS7mDlay5IZjsamBFRESqFitlnZd4vhxo7e75ZjYCeA7ISvC1sZXuU4GpAH369PGhQ4cebd5vyc7OpqKOFSTlDpZyB0u5g5WsuSGY7LqEWEREpGrZCrQs9jyT2FnWr7n7Z+6eH1+eDaSZWXoirxUREQmTGlgREZGqZRmQZWZtzaw6MAaYWXwHMzvezCy+3I/Y7wO7EnmtiIhImHQJsYiISBXi7gVmNhZ4CUgFHnP3dWZ2XXz7FGA0cL2ZFQD7gTHu7kCprw3ljYiIiJTCYuNV8jCzncD7FXS4dCCvgo4VJOUOlnIHS7mDlay5oeKyt3b3JhVwnGOWxmZAuYOm3MFS7mAla24IYGxOuga2IpnZW+7eJ+wcR0q5g6XcwVLuYCVrbkju7FK2ZP25KnewlDtYyh2sZM0NwWTXd2BFREREREQkKaiBFRERERERkaRwrDewU8MOcJSUO1jKHSzlDlay5obkzi5lS9afq3IHS7mDpdzBStbcEED2Y/o7sCIiIiIiIpI8jvUzsCIiIiIiIpIkqnwDa2bDzexdM8sxs1tL2W5mNim+fbWZ9QojZ0kJ5B5qZnvNbGX88bswcpZkZo+Z2Q4zW1vG9qjWu7zcUa13SzN7zcw2mNk6MxtXyj6Rq3mCuSNXczOraWZvmtmqeO7fl7JPFOudSO7I1fsrZpZqZivM7PlStkWu3lI+jc3B0tgcLI3NwdLYHI5Qx2Z3r7IPYpOwbwZOAKoDq4BOJfYZAbwIGNAfWJokuYcCz4edtZTsQ4BewNoytkeu3gnmjmq9mwG94sv1gI1J8nc8kdyRq3m8hnXjy2nAUqB/EtQ7kdyRq3exbL8AniwtXxTrrUe5P0+NzcFn19gcbG6NzcHm1tgcTv7Qxuaqfga2H5Dj7rnufhCYBowqsc8o4AmPeQNoaGbNgg5aQiK5I8ndFwC7D7NLFOudSO5Icvft7r48vvw5sAFoUWK3yNU8wdyRE69hfvxpWvxR8kYCUax3IrkjycwygXOAR8vYJXL1lnJpbA6YxuZgaWwOlsbm4IU9Nlf1BrYF8GGx51v57v+IiewTtEQzDYhfdvCimXUOJtr3FsV6JyrS9TazNkBPYp/gFRfpmh8mN0Sw5vFLZlYCO4C57p4U9U4gN0Sw3sD9wK+AojK2R7Leclgam6MnivVOVKTrrbE5GBqbA3c/IY7NVb2BtVLWlfxkI5F9gpZIpuVAa3fvDjwAPFfZoSpIFOudiEjX28zqAs8C4939s5KbS3lJJGpeTu5I1tzdC929B5AJ9DOzLiV2iWS9E8gduXqb2Uhgh7u/fbjdSlkXer3lsDQ2R08U652ISNdbY3NwNDYHJwpjc1VvYLcCLYs9zwS2HcU+QSs3k7t/9tVlB+4+G0gzs/TgIh61KNa7XFGut5mlERto/unu00vZJZI1Ly93lGsO4O6fAtnA8BKbIlnvr5SVO6L1HgSca2ZbiF2uebqZ/V+JfSJdbymVxuboiWK9yxXlemtsDofG5kCEPjZX9QZ2GZBlZm3NrDowBphZYp+ZwJXxu2X1B/a6+/agg5ZQbm4zO97MLL7cj9jPclfgSY9cFOtdrqjWO57p78AGd/9LGbtFruaJ5I5izc2siZk1jC/XAs4A3imxWxTrXW7uKNbb3W9z90x3b0Ps38FX3f3yErtFrt5SLo3N0RPFepcrqvXW2Bwsjc3BisLYXK2iDhRF7l5gZmOBl4jdPfAxd19nZtfFt08BZhO7U1YO8AVwdVh5v5Jg7tHA9WZWAOwHxrh76JdCmNlTxO6Ylm5mW4E7iH0pPbL1hoRyR7LexD4FuwJYY7HvUADcDrSCSNc8kdxRrHkz4HEzSyU2iPzL3Z+P+r8pJJY7ivUuVRLUWw5DY3PwNDYHTmNzsDQ2R0CQ9baI1kBERERERETkW6r6JcQiIiIiIiJSRaiBFRERERERkaSgBlZERERERESSghpYERERERERSQpqYEVERERERCQpqIEViTgzKzSzlcUet1bgsduY2dqKOp6IiMixQGOzSHiq9DywIlXEfnfvEXYIERER+ZrGZpGQ6AysSJIysy1mdq+ZvRl/tI+vb21m88xsdfzPVvH1GWY2w8xWxR8D44dKNbO/mdk6M3vZzGqF9qZERESSmMZmkcqnBlYk+mqVuEzp4mLbPnP3fsBk4P74usnAE+7eDfgnMCm+fhIw3927A72AdfH1WcCD7t4Z+BS4sFLfjYiISPLT2CwSEnP3sDOIyGGYWb671y1l/RbgdHfPNbM04GN3b2xmeUAzdz8UX7/d3dPNbCeQ6e4Hih2jDTDX3bPiz28B0tx9QgBvTUREJClpbBYJj87AiiQ3L2O5rH1Kc6DYciH6bryIiMj3obFZpBKpgRVJbhcX+/P1+PISYEx8+TJgUXx5HnA9gJmlmln9oEKKiIgcQzQ2i1QifZojEn21zGxlsedz3P2r2/XXMLOlxD6MuiS+7kbgMTO7GdgJXB1fPw6YambXEPs093pge2WHFxERqYI0NouERN+BFUlS8e/Z9HH3vLCziIiIiMZmkSDoEmIRERERERFJCjoDKyIiIiIiIklBZ2BFREREREQkKaiBFRERERERkaSgBlZERERERESSghpYERERERERSQpqYEVERERERCQpqIEVERERERGRpPD/4Twf0uV8F/kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 66s 84ms/step - loss: 0.5543 - accuracy: 0.7650\n",
      "Test Loss: 0.5543357133865356\n",
      "Test Accuracy: 0.7650399804115295\n"
     ]
    }
   ],
   "source": [
    "show_loss_accuracy_evolution(history)\n",
    "results = model.evaluate(x_test_seq, test_labels, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : 1, real : 0, lenght: 270\n",
      "<START> black <UNK> did this plot so much better which is why it is <UNK> and the man with two lives is just a forgotten <UNK> <UNK> no tears was it's working title and it would have been a better one as he was a thoroughly evil character for most of the film br br <UNK> <UNK> is <UNK> <UNK> when he is involved in a <UNK> accident dr <UNK> <UNK> <UNK> has been involved in some <UNK> <UNK> on animals <UNK> them back from the dead his <UNK> <UNK> him to try his <UNK> on <UNK> who has died as he is <UNK> a dangerous criminal <UNK> is going to the <UNK> <UNK> and <UNK> <UNK> of the soul <UNK> when <UNK> <UNK> from the <UNK> he has the soul of he is a changed person he is <UNK> to his family and starts to <UNK> around old <UNK> he takes over <UNK> old gang going by the name of <UNK> <UNK> he also <UNK> <UNK> former girlfriend who <UNK> a <UNK> <UNK> as <UNK> is <UNK> to even up <UNK> and starts to <UNK> his <UNK> <UNK> <UNK> up including the girlfriend and a <UNK> then his own family begins to fall victim br br but i hate those bad dream movies you always feel let down this film would have been better if he had <UNK> in character as and had a final shoot out <UNK> his <UNK> would have ended up <UNK> but <UNK> with his brother br br <UNK> <UNK> the star had a big career mostly in b movies br br not really recommended\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 322\n",
      "<START> in order to enjoy an <UNK> <UNK> of <UNK> <UNK> ' stephen needs the viewer to <UNK> all reality and <UNK> knowledge of the american <UNK> <UNK> <UNK> <UNK> it's the very use of <UNK> name and knowledge to her life and work that sets this film up to fail on a grand <UNK> br br what becomes apparent quite early on with the casting of the beautiful <UNK> and <UNK> <UNK> <UNK> as the anti <UNK> <UNK> <UNK> <UNK> is that didn't get <UNK> or what her work was about <UNK> realism and seems only <UNK> to <UNK> on a <UNK> level through her <UNK> of <UNK> <UNK> br br what follows is a kind of pretty and <UNK> beauty the <UNK> fantasy <UNK> with robert <UNK> jr as <UNK> <UNK> <UNK> love interest however it's not the <UNK> of the story that is the main <UNK> in this film but the <UNK> <UNK> <UNK> that <UNK> <UNK> one of the art <UNK> most <UNK> and original woman <UNK> was <UNK> of <UNK> her own ideas about her work while his previous film was a <UNK> of female <UNK> his <UNK> portrayal of the female as <UNK> <UNK> this film completely and <UNK> in the face of the real life <UNK> <UNK> <UNK> and <UNK> in single <UNK> <UNK> the often <UNK> world of <UNK> br br imagine an <UNK> <UNK> on pop star <UNK> life with guy <UNK> as her <UNK> the man behind her career and you'll get a feel of how seriously <UNK> and <UNK> this film is it can only work if you have absolutely no knowledge of the subject or just <UNK> to <UNK> all the <UNK> br br it's a shame because once you <UNK> all <UNK> to <UNK> <UNK> this film could have <UNK> up on its own as an interesting <UNK> on <UNK> and a good <UNK> piece to <UNK> 4 10\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 1005\n",
      "<START> looking back on jim <UNK> works years after his death is like taking a look back into another time for unlike most so called creative <UNK> <UNK> to <UNK> to or worse yet <UNK> <UNK> children <UNK> jim never seemed to really forget what it was like to be a child and if there ever was a moment in which he <UNK> this <UNK> aside it is <UNK> <UNK> movie filmed as an <UNK> story about how <UNK> came to work in <UNK> television as a <UNK> and ended up with a half hour show of his own on <UNK> television the <UNK> movie ends up an <UNK> of everything more <UNK> understanding <UNK> would say to children who did not quite meet the expected <UNK> during the <UNK> and as we enjoy the <UNK> of an era in which we are <UNK> and <UNK> from speaking about anything <UNK> someone might get <UNK> the open <UNK> of difference or <UNK> that <UNK> a large part of the <UNK> show is on offer here i have said it in other comments but i must say it here a great light in the world went out the day jim <UNK> died br br the <UNK> movie begins with its cast sitting down to see the <UNK> of what were about to see for the next <UNK> or so minutes in short <UNK> <UNK> we are introduced to the major players as well as some of the <UNK> and when the story <UNK> begins boy are we given a great song to bring us into the moment the <UNK> <UNK> <UNK> both a beautiful and sad image of what the <UNK> especially <UNK> were these were not just a bunch of felt <UNK> with <UNK> <UNK> who <UNK> to put on a show they were living things based upon a part of all of us only <UNK> so much more <UNK> than we are used to as each <UNK> was introduced to us in turn we saw another <UNK> of part of <UNK> and of course the children in the audience would <UNK> <UNK> to each character <UNK> everyone had a favourite when animal appeared behind a <UNK> <UNK> and <UNK> to eat a <UNK> i knew i had found one of mine <UNK> i am more of a <UNK> <UNK> fan but what the hey br br <UNK> the characters was a <UNK> of musical numbers that further developed their <UNK> and <UNK> can you picture that <UNK> an <UNK> into dr <UNK> and his band as well as the creative soul of <UNK> but the most <UNK> song to me was <UNK> number <UNK> what he is and where he came from many of us would spend a <UNK> <UNK> into the stars and like <UNK> saying we knew we would be going back there <UNK> not that all the songs were so <UNK> serious of course and <UNK> share a number after they decide to <UNK> their talent or lack <UNK> and hit the road if any <UNK> were <UNK> that present day <UNK> have lost the ability to use the pop <UNK> to create something <UNK> this number would be it never before and never again would the group <UNK> of a cast and the music so perfectly <UNK> one another with the and voice actors so perfectly on top of their game the human cast had a lot to live up to br br which makes it all the more amazing that the human element also lived up to their end of the deal <UNK> literally <UNK> the film with everyone from steve martin to <UNK> <UNK> <UNK> in to offer their support even richard <UNK> the last man one would expect to see in a film about the <UNK> appears to set up a hilarious moment <UNK> <UNK> <UNK> is just as disturbing to me as an adult as it was when i was a small boy but i suspect that is because <UNK> knew why i would find it disturbing now the big acting <UNK> though comes from charles <UNK> who as <UNK> <UNK> <UNK> everything both <UNK> and his audience <UNK> to <UNK> at every <UNK> <UNK> comes to either offer <UNK> the chance to <UNK> out and <UNK> his own kind or perhaps offer <UNK> being the right word when <UNK> attempts to <UNK> <UNK> <UNK> become <UNK> more <UNK> and violent the whole thing is one big <UNK> for how every artist has his heart broken by the world br br of course animal also shows up to <UNK> us that just because our friends are not sweet and <UNK> does not make them any less of a friend in point of fact animal turns out to be the best friend that <UNK> has in that moment and that has been the <UNK> message of every good show or film <UNK> has been involved in ever since that <UNK> or <UNK> others simply because of <UNK> or <UNK> <UNK> could literally be the worst mistake one ever makes there can be little doubt that in today's world where a <UNK> in a <UNK> suit can tell my <UNK> they are not good if they do not have good feelings for <UNK> <UNK> and still not come under serious <UNK> by child <UNK> <UNK> <UNK> creature <UNK> could never have got off the ground to <UNK> the <UNK> title <UNK> to be stupid is one thing but <UNK> the choice upon others is another matter the <UNK> movie <UNK> how <UNK> <UNK> to ask us all to think both inside and outside of the <UNK> box there will never be another entirely like him but he never would want us to stop trying br br therefore the <UNK> movie is the <UNK> of a ten out of ten film if we were to <UNK> a film out into the <UNK> to prove to intelligent life that we are worth more than being <UNK> this would be it\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 99\n",
      "<START> wow i've never seen nor heard of this film it just came on tv 2 <UNK> am and i am in complete <UNK> <UNK> a bunch of rich fat <UNK> are out <UNK> one <UNK> a ball into the <UNK> it <UNK> by a <UNK> a <UNK> man <UNK> over to pick the ball up the <UNK> <UNK> it <UNK> it in his hand man <UNK> gun <UNK> <UNK> <UNK> <UNK> <UNK> into gun <UNK> gun <UNK> this is just the beginning of the <UNK> people everyone must see this movie 10 big <UNK> fat stars from <UNK>\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 111\n",
      "<START> this film is about the <UNK> of 7 <UNK> on <UNK> in one <UNK> <UNK> <UNK> br br it shows 7 different <UNK> of <UNK> married <UNK> <UNK> up a relationship <UNK> <UNK> <UNK> date and <UNK> <UNK> they are not <UNK> to each other apart from the <UNK> location so that is a disappointment the film is a <UNK> of <UNK> without any <UNK> plot the film <UNK> from a <UNK> to another without any <UNK> i find this film boring and <UNK> the only redeeming feature is the great <UNK> throughout the film it is sad that talents like <UNK> <UNK> and <UNK> get wasted by this film\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 56\n",
      "<START> jim first real movie is quite a <UNK> but don't come in expecting to see <UNK> p any time soon i felt the wide <UNK> of characters <UNK> <UNK> were great but without being said the rest of the movie should be put into a or something a rather odd beginning for a movie <UNK>\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 597\n",
      "<START> there's something strange about the <UNK> <UNK> you can find in some <UNK> and <UNK> material one of the songs in up in <UNK> well i often wish more songs these days began that way but in this excuse for a video the <UNK> <UNK> are showing us the <UNK> for four songs from their <UNK> of the moment also <UNK> get out of my room you hear a voice over during the opening credits in which some <UNK> producer <UNK> the record as being a <UNK> <UNK> that will just take up room on the <UNK> unfortunately this opening voice over hits the <UNK> right on the head br br most music <UNK> <UNK> by the seem to keep to a <UNK> of putting the best material early in the <UNK> often when one gets past that first song the <UNK> <UNK> <UNK> that the <UNK> has little if anything to hold their attention <UNK> that <UNK> <UNK> <UNK> on the other hand often saved their best material for last or at least <UNK> it <UNK> throughout the <UNK> in this case <UNK> and <UNK> appear to have decided to <UNK> their <UNK> the opening piece get out of my room is a <UNK> <UNK> song with an incredibly bad video many a viewer of a <UNK> music video will find the <UNK> direction somewhat <UNK> <UNK> <UNK> of british <UNK> is also incredibly funny br br where it all goes <UNK> is the second number i'm not home right now nothing kills interest in a song quite like <UNK> and it's tough to get more <UNK> than this <UNK> <UNK> honestly one feels the <UNK> to <UNK> <UNK> in the face and tell him that we get the idea he isn't home right now so please move on the next song along the theme of love being a strange thing is the absolute rock bottom not only for this collection but for <UNK> and <UNK> in general it's almost as if this song was made for the <UNK> reason of <UNK> out the <UNK> running time br br <UNK> the <UNK> <UNK> saved the best for last but it is also curious to note that <UNK> is completely <UNK> from this cut born in <UNK> <UNK> a is a simple number based upon the old bruce <UNK> number that <UNK> <UNK> view of <UNK> as one is by <UNK> tale one has to wonder how many poor <UNK> who couldn't speak a word of spanish were <UNK> to <UNK> simply because their <UNK> wasn't <UNK> white <UNK> was an <UNK> part of <UNK> culture in <UNK> and it remains so today if anything it has gotten worse so one has to wonder what born in <UNK> <UNK> a would be like if it were written in the <UNK> era br br unfortunately two cuts does not an <UNK> make especially when there is so much boring <UNK> between them the <UNK> before get out of my room for example are quite funny not side <UNK> like much of up in <UNK> but funny enough to <UNK> their <UNK> unfortunately the two middle songs are <UNK> in their making of footage boring song makes boring <UNK> if you cut out the middle half hour of material from this video you'd have something <UNK> better br br i gave get out of my room a three out of ten they are <UNK> by the first and last video i'm pretty certain that the stars look at material like this today and wonder what they were thinking\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 825\n",
      "<START> <UNK> <UNK> is <UNK> a <UNK> at the moment and fair play to him i always liked his image and his acting ability in such <UNK> as <UNK> heart and johnny <UNK> you know what you are going to get with <UNK> mean <UNK> dirty but this film gives you much more and you don't want most of it br br first and <UNK> this whole thing just doesn't make sense <UNK> is a <UNK> <UNK> killer who after killing a <UNK> <UNK> of <UNK> <UNK> <UNK> for london he is on the run from the cops and from his own army <UNK> he has also <UNK> to never kill again it looks like the <UNK> full of kids finally did it for him br br however when he gets to london he is <UNK> down by a local <UNK> <UNK> looking like his <UNK> and hair came straight off a <UNK> <UNK> to kill his main <UNK> in turn for <UNK> 000 and a <UNK> trip to the us <UNK> <UNK> <UNK> to do it but is seen by a <UNK> <UNK> and <UNK> the crime to him in the <UNK> in order to keep the <UNK> mouth <UNK> he <UNK> it is better than killing him br br a <UNK> of things <UNK> here which just don't add up 1 why pick <UNK> to off your <UNK> as is <UNK> by a scene <UNK> an <UNK> is <UNK> to a wall by a couple of <UNK> with what look like these london guys are tough enough anyway to do their own killing 2 not only that but the <UNK> gets a guy to follow <UNK> and <UNK> the killing with his own eyes why didn't that guy simply kill the <UNK> and save all the <UNK> of dealing with <UNK> 3 <UNK> sees the murder take place and the police let him go off without <UNK> i may add to take <UNK> no way 4 <UNK> <UNK> around the church right next to where he <UNK> out the murder immediately after the crime takes place to go to <UNK> why aren't the cops <UNK> the place out 5 <UNK> <UNK> around the church and <UNK> <UNK> in particular for days <UNK> without anybody <UNK> him what he's on the run and he <UNK> put by the very place where he <UNK> another murder stupid 6 the cops actually meet <UNK> in the church <UNK> the <UNK> and have no idea who he is do they not know he is on the run for the school <UNK> <UNK> they don't even check up on him 7 why get <UNK> to kill for you and then tell him to wait around for a few days to get on the <UNK> you'd think you'd want to get <UNK> of him immediately or kill him one or the other 8 why does <UNK> brother suddenly decide to rape the <UNK> <UNK> in the <UNK> of all the waiting could he not <UNK> himself for a few days at least until <UNK> has been <UNK> <UNK> to the states ridiculous 9 <UNK> suddenly has <UNK> <UNK> after all his years of killing and <UNK> over the <UNK> <UNK> immediately even after she knows he is a killer she still loves him again utterly <UNK> and besides she falls in love with him in record time a few days 10 the whole <UNK> thing at the end is just plain silly from <UNK> point of view 11 things happen in parts of this film that just do not make sense or are simply in there to help the storyline and i say that in <UNK> along <UNK> <UNK> <UNK> in a <UNK> until the <UNK> is ready to <UNK> and <UNK> suddenly <UNK> a moral high ground to respect the <UNK> in the house but yet will bed a <UNK> girl 12 <UNK> asks a <UNK> on the <UNK> where <UNK> is and the <UNK> <UNK> <UNK> out the entire <UNK> of his boss in less than 10 seconds it was <UNK> the guy was telling <UNK> far more than he even asked <UNK> <UNK> is an ex army guy and we see him beat up three <UNK> behind a <UNK> totally <UNK> for and yet another <UNK> worthy scene br br i'm <UNK> stop there at <UNK> <UNK> without <UNK> <UNK> hair so <UNK> red it is laughable his accent which to be fair is not too bad sometimes but <UNK> to a barely heard <UNK> at other times his clothes walk looks to the <UNK> etc nor will i mention the music and the <UNK> editing style br br i have just mentioned them br br overall a disaster of a film with some obvious religious <UNK> thrown in <UNK> on the cross <UNK> from a <UNK> which would <UNK> a first year film student never mind a top star and director br br 4 10\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 2315\n",
      "<START> there's a sign on the lost <UNK> that says br br major spoilers ahead br br but you already knew that didn't you br br since there's a great deal of people that apparently did not get the point of this movie i'd like to <UNK> my <UNK> of why the plot makes perfect sense as others have <UNK> out one single viewing of this movie is not <UNK> if you have the dvd of <UNK> you can <UNK> by looking at david <UNK> top 10 <UNK> to <UNK> <UNK> but only upon second or third viewing please br br first of all <UNK> drive is <UNK> brilliant a masterpiece this is the kind of movie that <UNK> to leave your head not often are the comments on the <UNK> very accurate but it gets inside your head and <UNK> there really hit the mark br br david <UNK> deserves <UNK> for creating a movie that not only has a beautifully <UNK> look to it cinematography wise has great acting <UNK> <UNK> <UNK> a <UNK> soundtrack by <UNK> and a very dream like quality to it but on top of it all it also manages to <UNK> the viewer in such a way that few movies have before after all when is the last time you saw a movie that just wouldn't leave your mind and that everyone felt <UNK> to talk and write about <UNK> of whether they liked it or hated it br br <UNK> enough about all that it's time to <UNK> those <UNK> br br most people that have gone through some effort to try to piece the plot together will have come to the conclusion that the first half of the picture is an <UNK> a dream sequence br br of course that's too bad for all those trying to make sense of the movie by expecting <UNK> <UNK> in which the story is <UNK> out in a <UNK> <UNK> and <UNK> manner for the viewer but for those expecting that i <UNK> you to check the name of the director and come back again br br <UNK> is the story of the sad <UNK> of <UNK> <UNK> a <UNK> actor who is <UNK> in love with another actor <UNK> due to <UNK> lack of talent she is constantly <UNK> to <UNK> her career and feels she failed to deliver on her own and her <UNK> expectations upon <UNK> that <UNK> will never be <UNK> c becomes <UNK> with adam the director she <UNK> a <UNK> to get <UNK> of her and <UNK> has to deal with the <UNK> that it <UNK> br br the movie first starts off with what may seem as a strange opening for this kind of thriller which is some <UNK> dance <UNK> <UNK> in which we can see the main character <UNK> giving a great performance we also see an <UNK> couple which we will see twice more throughout the movie together with her and <UNK> her br br no wait this is what most people see the first time they view it there's actually another very <UNK> fact that is given before the credits the camera moving into an <UNK> although <UNK> and the scene quickly <UNK> out if you look <UNK> the <UNK> is actually a <UNK> <UNK> that what follows is a dream br br the main characters seen in the first half of the movie br br <UNK> <UNK> <UNK> self used in the first half of the movie that <UNK> the dream sequence a positive portrayal of a successful <UNK> young actor the complete opposite of <UNK> was <UNK> as the name as that is the real name of the <UNK> at notice that in the dream version the name is br br <UNK> the fantasy version of <UNK> <UNK> that through <UNK> dream and with the help of an <UNK> car accident is turned into an <UNK> this makes her <UNK> and <UNK> on <UNK> love she is then <UNK> <UNK> in <UNK> <UNK> <UNK> <UNK> home which <UNK> has been allowed to stay in br br <UNK> in real life <UNK> mother in the dream part the woman in <UNK> of the apartment complex that <UNK> <UNK> in she's mainly a strong <UNK> figure as can be <UNK> in both parts of the film br br adam the director we know from the second half that he gets <UNK> with <UNK> his <UNK> purpose for being in the first half of the movie is only to <UNK> as a <UNK> <UNK> for <UNK> <UNK> since she <UNK> such <UNK> towards him br br <UNK> <UNK> <UNK> real <UNK> but instead of being out of town she is actually dead <UNK> <UNK> the money left by her <UNK> and used that to pay for murder br br mr <UNK> a typical <UNK> character not real appears only in <UNK> dream sequence he's a mysterious <UNK> person that <UNK> the <UNK> of events in the dream from his <UNK> he <UNK> much of the same <UNK> as the <UNK> talking <UNK> which he also plays in <UNK> <UNK> br br the <UNK> the person that murders <UNK> this character is basically the same in both parts of the movie although <UNK> in a slightly more <UNK> fashion in the dream sequence more on that below br br now having <UNK> the various <UNK> of the characters in the movie we can begin to <UNK> into the plot of course i will not go into every little detail neither will i <UNK> it out <UNK> but i will try to explain some of the important scenes in <UNK> to <UNK> <UNK> br br as i mentioned above <UNK> was re produced as an <UNK> through her <UNK> <UNK> of a car accident in the first 10 minutes of the movie which left her completely <UNK> what i found very intriguing with <UNK> is that <UNK> constantly gives <UNK> on what is real and what isn't i've already mentioned the camera moving into the <UNK> but notice how there's two cars <UNK> in each <UNK> <UNK> the <UNK> br br only one of the cars actually hit the <UNK> what about the other even if they <UNK> clear of the accident themselves wouldn't they try to help the others or at least call for help my <UNK> is that since this is a dream the presence of the other car is just set aside and forgotten about since as <UNK> so <UNK> puts it like real dreams it does not explain does not complete its sequences <UNK> over what it finds fascinating <UNK> <UNK> <UNK> br br <UNK> after <UNK> <UNK> down from the <UNK> <UNK> at <UNK> dr and makes her way down the <UNK> and <UNK> into <UNK> <UNK> apartment <UNK> <UNK> and we see this creepy old couple driving away <UNK> <UNK> at each other and <UNK> at themselves and the camera this is the first <UNK> that what we're seeing is a nightmare br br although the old couple seem to be <UNK> to <UNK> i think they're actually her parents since they were <UNK> her at the <UNK> <UNK> perhaps she didn't know them all that well and didn't really have as good a relationship with them as she wanted so the couple is shown as very <UNK> and <UNK> to her in the dream they also <UNK> her feelings of <UNK> from the murder and <UNK> sense of <UNK> <UNK> her <UNK> <UNK> in her life br br a rather long and hilarious scene is the one involving the <UNK> <UNK> apparently sees him as the major force behind the <UNK> trying to <UNK> the director to accept part in the movie from <UNK> party in the second half of the movie and he therefore <UNK> a major part of her dream because of her feelings of <UNK> and <UNK> towards the murder of <UNK> a part of her wants him to miss so she turns him into a dumb criminal br br this scene i think is also <UNK> attempt at totally <UNK> his audience over since they're given a <UNK> <UNK> in which to view the movie br br <UNK> love that <UNK> just bit me <UNK> line though br br the next interesting scene is the one with the two <UNK> at <UNK> who are having a <UNK> about how one of them keep having this <UNK> nightmare involving a man which is seen by him through a wall outside of the <UNK> that they're sitting in after a little talk they head outside and keep walking toward the <UNK> of a <UNK> <UNK> of course by excellent music <UNK> the mood of the scene br br when <UNK> the <UNK> a <UNK> like character with a <UNK> face appears out from behind the <UNK> <UNK> the living crap out of the man having the nightmare this nightmare <UNK> only in <UNK> mind she saw that guy in the <UNK> when <UNK> for the murder so in short her <UNK> into that poor <UNK> <UNK> the <UNK> also <UNK> <UNK> evil side as can be <UNK> later in the movie br br the <UNK> <UNK> along with the <UNK> one of the strange characters that are always present in the <UNK> <UNK> <UNK> only saw him for a short while at <UNK> party but just like our own dreams can award <UNK> <UNK> that we hardly know a major part in our dreams so can he be <UNK> an important part in her dream we are also given further <UNK> during his scenes that what we're seeing is not real his <UNK> <UNK> etc br br the <UNK> is also used as a <UNK> to <UNK> the director when he meets up with him at the odd location the <UNK> here give a clear <UNK> that this is part of a dream also notice how he says that he will appear one more time if he adam does good or two more times if he does bad throughout the movie he appears two more times <UNK> to <UNK> that she did bad he is also the one to <UNK> her up to reality that scene is probably an <UNK> made to fit into her <UNK> of him <UNK> twice and <UNK> <UNK> she <UNK> suicide br br the <UNK> scene with the brothers where we can see <UNK> the <UNK> as <UNK> is probably a result of the fact that <UNK> was having an <UNK> just before <UNK> and adam made their <UNK> at <UNK> party in the second half it could at the same time also be a <UNK> from <UNK> br br during the scene in which they <UNK> <UNK> apartment the body <UNK> in the bed is <UNK> but notice how she's <UNK> <UNK> <UNK> <UNK> <UNK> is seeing herself in her own dream but the face is not <UNK> although it had the same <UNK> on the face as <UNK> would have after shooting herself this scene is also filled with some <UNK> <UNK> <UNK> since <UNK> did not know where or when the <UNK> would get to <UNK> and finish her off she just put her into her own home br br in real life <UNK> <UNK> for the movie part was bad in her dream she delivers a perfect <UNK> leaving the whole crew <UNK> about her performance br br also interesting is the fact that the money that in real life was used to pay for murder now appears in <UNK> <UNK> this is part of <UNK> <UNK> of her terrible act by <UNK> being given the money back as the murder now hasn't taken place br br when her <UNK> <UNK> to get her <UNK> <UNK> <UNK> another <UNK> is given she takes the <UNK> from her <UNK> and leaves yet later when <UNK> and <UNK> have their <UNK> on the <UNK> we see the <UNK> appear again when the camera <UNK> over the <UNK> <UNK> that <UNK> <UNK> with the <UNK> was a fantasy br br the catch <UNK> of the movie adam is <UNK> actresses for is she is the girl which are the <UNK> same words that <UNK> uses when giving the <UNK> <UNK> <UNK> br br the blue box and the key <UNK> the major turning point in the movie and is where the true <UNK> of the characters are <UNK> there's much <UNK> going on here the box may <UNK> <UNK> future it's empty or it may be a sort of a <UNK> box the <UNK> laughs when she asks him what the key will open either way it is <UNK> to the murder by means of the blue key which is <UNK> next to her after the murder has taken place the box is also seen at the end of the movie in the hands of the <UNK> <UNK> br br club is a <UNK> little addition to further <UNK> the viewer that what s he is viewing is not real it also <UNK> that <UNK> is about to <UNK> up to her reality her reality being a nightmare that she is <UNK> to escape from even in her dreams br br during the <UNK> scene at the end where the creepy old couple <UNK> <UNK> is <UNK> in such a way that she sees suicide as the only way out in order to escape the <UNK> and to avoid being <UNK> by her <UNK> br br anyway that is my <UNK> <UNK> hope this could help people from <UNK> out at this movie and <UNK> it 'the worst movie <UNK> or something to that effect without <UNK> the plot br br as usual <UNK> is all about creating <UNK> <UNK> and he certainly <UNK> that with this picture as well br br 10 out of 10\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 196\n",
      "<START> for all <UNK> and <UNK> <UNK> might seem like just another <UNK> <UNK> musical to some <UNK> this might even be true especially because the producers had to be sure that the film <UNK> with the <UNK> but somewhere behind the scenes either <UNK> who had the <UNK> for this story or who directed the film decided that there would be a twist to the usual <UNK> and <UNK> perhaps beyond even their own expectations br br this is not simply about a <UNK> man <UNK> with 3 women <UNK> on whom to <UNK> as his <UNK> partner <UNK> <UNK> character was really in love with each of the 3 women at various times and they with him despite being aware of the other two <UNK> <UNK> relationship with <UNK> and is particularly interesting in that each of the women comes to <UNK> on him <UNK> there are quite a lot of <UNK> <UNK> in the <UNK> body language that <UNK> themselves to imagination <UNK> on the <UNK> <UNK> the theme is surprisingly adult and after all that it was <UNK> that the ending was <UNK> obviously <UNK> to please the <UNK> and <UNK> <UNK>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_errors(x_test, model, labels, int2word, n_samples=10):\n",
    "    preds = 1.0 * (model.predict(x_test).flatten() > 0.5)\n",
    "    bad_pred_inds = np.where(preds != labels)[0]\n",
    "    n_samples = min(len(bad_pred_inds), n_samples)\n",
    "    samples_inds = np.random.choice(bad_pred_inds, n_samples)\n",
    "    for ind in samples_inds:\n",
    "        print('Predicted : {0}, real : {1}, lenght: {2}'.format(\n",
    "            int(preds[ind]), labels[ind], len(test_data[ind])))\n",
    "        print(get_words(test_data[ind], int2word))\n",
    "        print()\n",
    "    return\n",
    "\n",
    "show_errors(x_test_seq, model, test_labels, int2word, n_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictioins with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0362],\n",
       "       [0.9702],\n",
       "       [0.9599],\n",
       "       [0.9103],\n",
       "       [0.0244],\n",
       "       [0.0533]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = ['the film was really bad and i am very disappointed',\n",
    "           'The film was very funny entertaining and good we had a great time . brilliant film',\n",
    "           'this film was just brilliant',\n",
    "           'the film is not good',\n",
    "           'the film is not bad',\n",
    "          'the movie is not bad I like it']\n",
    "sequences = [vectorize_text_sentence(review.lower(), word2int)\n",
    "             for review in reviews]\n",
    "\n",
    "## Padding the sequences\n",
    "x_pred  = sequence.pad_sequences(sequences, maxlen=max_len, truncating='post', padding='post')# ...\n",
    "\n",
    "np.round(model.predict(x_pred), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0*(model.predict(x_pred) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU model\n",
    "Use `keras.layers.GRU`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(max_len,), name='input'))\n",
    "## one-hot encoding\n",
    "model.add(layers.Embedding(input_dim=num_words, output_dim=num_words,\n",
    "                           input_length=max_len, embeddings_initializer='identity',\n",
    "                           trainable=False))\n",
    "\n",
    "## complete the model with recurrent layers\n",
    "model.add(layers.GRU(64, return_sequences=False))\n",
    "## add binary classification output\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "88/88 [==============================] - 120s 1s/step - loss: 0.6858 - accuracy: 0.5392 - val_loss: 0.4927 - val_accuracy: 0.7700\n",
      "Epoch 2/5\n",
      "88/88 [==============================] - 143s 2s/step - loss: 0.4447 - accuracy: 0.7963 - val_loss: 0.4134 - val_accuracy: 0.8176\n",
      "Epoch 3/5\n",
      "88/88 [==============================] - 176s 2s/step - loss: 0.3699 - accuracy: 0.8373 - val_loss: 0.4056 - val_accuracy: 0.8188\n",
      "Epoch 4/5\n",
      "88/88 [==============================] - 150s 2s/step - loss: 0.3543 - accuracy: 0.8443 - val_loss: 0.4053 - val_accuracy: 0.8144\n",
      "Epoch 5/5\n",
      "88/88 [==============================] - 171s 2s/step - loss: 0.3400 - accuracy: 0.8526 - val_loss: 0.4419 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "## set the loss and see the results\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "epochs = 5\n",
    "history = model.fit(x_train_seq, train_labels,\n",
    "                    validation_split=0.1, epochs=epochs,\n",
    "                    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 95s 121ms/step - loss: 0.4489 - accuracy: 0.7922\n",
      "Test Loss: 0.4488656520843506\n",
      "Test Accuracy: 0.7922000288963318\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test_seq, test_labels, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model\n",
    "Use `keras.layers.LSTM` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(max_len,), name='input'))\n",
    "## one-hot encoding\n",
    "model.add(layers.Embedding(input_dim=num_words, output_dim=num_words,\n",
    "                           input_length=max_len, embeddings_initializer='identity',\n",
    "                           trainable=False))\n",
    "\n",
    "## complete the model with recurrent layers\n",
    "model.add(layers.LSTM(64, return_sequences=False))\n",
    "## add binary classification output\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "88/88 [==============================] - 216s 2s/step - loss: 0.6599 - accuracy: 0.5767 - val_loss: 0.4748 - val_accuracy: 0.8012\n",
      "Epoch 2/5\n",
      "88/88 [==============================] - 185s 2s/step - loss: 0.4313 - accuracy: 0.8116 - val_loss: 0.4212 - val_accuracy: 0.8040\n",
      "Epoch 3/5\n",
      "88/88 [==============================] - 88s 1s/step - loss: 0.3778 - accuracy: 0.8341 - val_loss: 0.4187 - val_accuracy: 0.8096\n",
      "Epoch 4/5\n",
      "88/88 [==============================] - 82s 935ms/step - loss: 0.3621 - accuracy: 0.8424 - val_loss: 0.4038 - val_accuracy: 0.8116\n",
      "Epoch 5/5\n",
      "88/88 [==============================] - 81s 917ms/step - loss: 0.3493 - accuracy: 0.8460 - val_loss: 0.4193 - val_accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "## set the loss and see the results\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "epochs = 5\n",
    "history = model.fit(x_train_seq, train_labels,\n",
    "                    validation_split=0.1, epochs=epochs,\n",
    "                    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 59s 75ms/step - loss: 0.4325 - accuracy: 0.8034\n",
      "Test Loss: 0.4325280785560608\n",
      "Test Accuracy: 0.8034399747848511\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test_seq, test_labels, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep model\n",
    "Use `keras.layers.SimpleRNN`,  `keras.layers.GRU`,  `keras.layers.LSTM` or `keras.layers.Bidirectional`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(max_len,), name='input'))\n",
    "## one-hot encoding\n",
    "model.add(layers.Embedding(input_dim=num_words, output_dim=num_words,\n",
    "                           input_length=max_len, embeddings_initializer='identity',\n",
    "                           trainable=False))\n",
    "\n",
    "## complete the model with recurrent layers\n",
    "model.add(layers.GRU(64, return_sequences=True))\n",
    "model.add(layers.GRU(64, return_sequences=False))\n",
    "## add binary classification output\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "88/88 [==============================] - 85s 928ms/step - loss: 0.6782 - accuracy: 0.5493 - val_loss: 0.4938 - val_accuracy: 0.7564\n",
      "Epoch 2/5\n",
      "88/88 [==============================] - 91s 1s/step - loss: 0.4343 - accuracy: 0.8010 - val_loss: 0.4194 - val_accuracy: 0.8108\n",
      "Epoch 3/5\n",
      "88/88 [==============================] - 103s 1s/step - loss: 0.3785 - accuracy: 0.8344 - val_loss: 0.4170 - val_accuracy: 0.8136\n",
      "Epoch 4/5\n",
      "88/88 [==============================] - 114s 1s/step - loss: 0.3590 - accuracy: 0.8448 - val_loss: 0.4158 - val_accuracy: 0.8132\n",
      "Epoch 5/5\n",
      "88/88 [==============================] - 164s 2s/step - loss: 0.3470 - accuracy: 0.8491 - val_loss: 0.4234 - val_accuracy: 0.8152\n"
     ]
    }
   ],
   "source": [
    "## set the loss and see the results\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "epochs = 5\n",
    "history = model.fit(x_train_seq, train_labels,\n",
    "                    validation_split=0.1, epochs=epochs,\n",
    "                    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 114s 146ms/step - loss: 0.4352 - accuracy: 0.8050\n",
      "Test Loss: 0.4352430999279022\n",
      "Test Accuracy: 0.8049600124359131\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test_seq, test_labels, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional model\n",
    "Use `keras.layers.SimpleRNN`,  `keras.layers.GRU`,  `keras.layers.LSTM` with `keras.layers.Bidirectional`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(max_len,), name='input'))\n",
    "## one-hot encoding\n",
    "model.add(layers.Embedding(input_dim=num_words, output_dim=num_words,\n",
    "                           input_length=max_len, embeddings_initializer='identity',\n",
    "                           trainable=False))\n",
    "\n",
    "## complete the model with recurrent layers\n",
    "model.add(layers.Bidirectional(layers.GRU(64, return_sequences=False)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "88/88 [==============================] - 386s 4s/step - loss: 0.6766 - accuracy: 0.5540 - val_loss: 0.4971 - val_accuracy: 0.7696\n",
      "Epoch 2/5\n",
      "88/88 [==============================] - 172s 2s/step - loss: 0.4369 - accuracy: 0.8002 - val_loss: 0.4155 - val_accuracy: 0.8108\n",
      "Epoch 3/5\n",
      "88/88 [==============================] - 153s 2s/step - loss: 0.3608 - accuracy: 0.8414 - val_loss: 0.4223 - val_accuracy: 0.8060\n",
      "Epoch 4/5\n",
      "88/88 [==============================] - 183s 2s/step - loss: 0.3441 - accuracy: 0.8553 - val_loss: 0.4239 - val_accuracy: 0.8140\n",
      "Epoch 5/5\n",
      "88/88 [==============================] - 188s 2s/step - loss: 0.3139 - accuracy: 0.8677 - val_loss: 0.4388 - val_accuracy: 0.8072\n"
     ]
    }
   ],
   "source": [
    "## set the loss and see the results\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "epochs = 5\n",
    "history = model.fit(x_train_seq, train_labels,\n",
    "                    validation_split=0.1, epochs=epochs,\n",
    "                    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 120s 154ms/step - loss: 0.4523 - accuracy: 0.7944\n",
      "Test Loss: 0.4523336589336395\n",
      "Test Accuracy: 0.794439971446991\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test_seq, test_labels, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictioins with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2854],\n",
       "       [0.9668],\n",
       "       [0.8511],\n",
       "       [0.7447],\n",
       "       [0.5015],\n",
       "       [0.5001]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = ['the film was really bad and i am very disappointed',\n",
    "           'The film was very funny entertaining and good we had a great time . brilliant film',\n",
    "           'this film was just brilliant',\n",
    "           'the film is not good',\n",
    "           'the film is not bad',\n",
    "           'the movie is not bad I like it']\n",
    "sequences = [vectorize_text_sentence(review.lower(), word2int)\n",
    "             for review in reviews]\n",
    "\n",
    "## Padding the sequences\n",
    "x_pred  = sequence.pad_sequences(sequences, maxlen=max_len, truncating='post', padding='post')# ...\n",
    "\n",
    "np.round(model.predict(x_pred), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : 1, real : 0, lenght: 166\n",
      "<START> i just <UNK> watching <UNK> <UNK> that i <UNK> from my <UNK> i <UNK> it <UNK> from years ago and wanted to watch it with my son anyway the movie was less than 2 hours running time and i thought it was much longer when i first saw it the back of the vhs box states that the <UNK> a <UNK> <UNK> whose <UNK> could <UNK> the free world forever the <UNK> were supposedly on a <UNK> mission to <UNK> the <UNK> <UNK> there was nothing even <UNK> about <UNK> this <UNK> also the box says that the <UNK> <UNK> <UNK> <UNK> <UNK> on human blood that would make this a horror movie and there was also nothing <UNK> in the movie about this i can't remember the details when i watched this years ago on tv but could the back of this box actually be true maybe the 3 hour movie <UNK> more details br br just wondering if anyone knows anything about this\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 176\n",
      "<START> my mother forced me to watch this movie with her she apparently will watch anything with a vampire <UNK> in it i was bored throughout br br at different points <UNK> <UNK> of the is <UNK> of <UNK> battle for the planet of the <UNK> the passion of the <UNK> and <UNK> what it reminds me most of are those italian <UNK> and <UNK> pictures of the <UNK> <UNK> not the good ones that spend an <UNK> amount of time showing <UNK> or <UNK> <UNK> in <UNK> talking and <UNK> <UNK> while you wait <UNK> for the <UNK> man hero and his lover usually the <UNK> daughter to do something br br this film was in desperate need of some color and suspense the characters were pretty two <UNK> br br the sets looked as if they were <UNK> entirely of <UNK> i wonder how many <UNK> war <UNK> sets were <UNK> down to make this movie br br all those wearing <UNK> <UNK> on your <UNK> and black <UNK> feel free to <UNK> no\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 131\n",
      "<START> just an hour ago i finished watching this my friend as a fans of <UNK> we think that this movie is so bad that is good we will say one thing without a <UNK> <UNK> there is now way you can <UNK> through this movie this movie should be watched with a many <UNK> fans to laugh their ass off the best character in the movie is the lord <UNK> his <UNK> his laugh and <UNK> <UNK> the <UNK> experience what we liked in this movie was the fact that the island of <UNK> man was the same as in cartoon version we believe that the only character similar to the one in the cartoon is the <UNK> man he is also a sex <UNK> and kind of <UNK> too\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 244\n",
      "<START> i saw this at the london film festival last night apparently the <UNK> version james <UNK> of the content of the film is very good very <UNK> <UNK> his <UNK> of the <UNK> business into <UNK> <UNK> about <UNK> the effect of the <UNK> media the power of <UNK> and the need for <UNK> br br the film is shot on hand held <UNK> which some might find <UNK> but which does <UNK> to catch people off <UNK> on a number of <UNK> which probably would not have been possible using more <UNK> <UNK> br br despite the <UNK> feel of the film the editing is very <UNK> not only giving us a <UNK> of the <UNK> <UNK> but also <UNK> a number of comments with somewhat <UNK> visual images and giving others <UNK> <UNK> to <UNK> themselves to a <UNK> this <UNK> michael <UNK> recent work although <UNK> in a more subtle way but probably the <UNK> of the film go back to <UNK> <UNK> the <UNK> and the <UNK> both in the way the film is <UNK> and in the <UNK> of of the <UNK> french <UNK> as the stars de <UNK> <UNK> <UNK> were present at the <UNK> and <UNK> questions <UNK> we do indeed all need a little <UNK> <UNK> <UNK> br br overall an excellent film with <UNK> that go way beyond the world of <UNK> into the way we <UNK> <UNK> as people and <UNK> our world\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 176\n",
      "<START> this <UNK> <UNK> short wasn't really much not one of his <UNK> <UNK> of course i never see <UNK> kids as anything hilarious that's what the <UNK> of this story is <UNK> and his wife <UNK> davis <UNK> his in <UNK> two young kids one is a baby who is constantly <UNK> and the other is a four year old <UNK> who does everything but <UNK> the house <UNK> the kid create <UNK> over and over was not entertaining to me br br the best part was the last four or five minutes when the couple thinks that this big <UNK> <UNK> young is <UNK> their house half the time it's the <UNK> cat <UNK> the couple but overall that <UNK> is fun with some good sight gags <UNK> me of another <UNK> short <UNK> <UNK> br br however the good ending doesn't save the whole picture which i probably wouldn't watch again <UNK> has done too many other good things to waste even <UNK> minutes on this one again it just isn't that funny\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 829\n",
      "<START> for those of you who have never heard of the movie until now of which i <UNK> there are many <UNK> people who haven't i'll <UNK> it for you <UNK> <UNK> plays the <UNK> character of <UNK> who also <UNK> as the film's <UNK> a la kevin <UNK> in american beauty but without the intelligent <UNK> on life <UNK> goes to <UNK> for <UNK> a <UNK> kid to death and the movie attempts to figure out why he did it he seems to be a nice boy if not <UNK> <UNK> and is portrayed by <UNK> with a complete lack of violence <UNK> or <UNK> and if you're waiting for him to <UNK> his <UNK> side later in the movie don't waste your time it's not that kind of movie once in <UNK> prison <UNK> goes to <UNK> <UNK> by <UNK> <UNK> <UNK> portrayed by don <UNK> who is <UNK> of anything but quality even when in bad movies <UNK> attempts to <UNK> the mystery of <UNK> in an attempt to figure out how such a kid could do such a thing and so he could write a book about it later along with being a <UNK> prison teacher <UNK> is also an <UNK> <UNK> br br the relationship between <UNK> and <UNK> is the driving narrative behind the film as their <UNK> <UNK> past to the audience however to call it the central focus would <UNK> that this <UNK> film had one it does not the <UNK> states of <UNK> <UNK> an impressive cast which seems to be to the <UNK> of the film it seems as though writer director <UNK> <UNK> <UNK> don't <UNK> that you haven't heard of him he's never done anything had to give every character a personal story <UNK> and personality <UNK> in order to get the actors to play them most of these <UNK> and stories are <UNK> and most go <UNK> and <UNK> br br i'll try and break them down here martin <UNK> and ann are the parents of the <UNK> <UNK> boy i love how the movie kept <UNK> the kid <UNK> never <UNK> <UNK> that part made me laugh inside they apparently have a cold relationship because all <UNK> <UNK> in <UNK> cinema must be cold their other two kids are <UNK> williams who is apparently an <UNK> actress about to <UNK> college and <UNK> <UNK> who plays the same <UNK> teen <UNK> she always plays this time with a heroine <UNK> <UNK> was also the girlfriend of <UNK> which gives him his <UNK> to his victim <UNK> boyfriend who was <UNK> and came to live with the family and is a <UNK> player looking to go to the same college as his girlfriend is played by chris <UNK> he ends up doing more with his character than any of the other bit players <UNK> to <UNK> the movie at times <UNK> <UNK> is mother who seems to be <UNK> sad for some reason kevin <UNK> also the <UNK> producer is cold and <UNK> father who is a <UNK> <UNK> eventually <UNK> will show up to put a <UNK> in story if you even care at that point oh yeah and there's a drug dealing ex boyfriend a couple of fellow and a co <UNK> of <UNK> with whom he has an affair on his long <UNK> girlfriend with played by <UNK> <UNK> br br sorry if all that <UNK> and character <UNK> took so long if it seemed <UNK> and boring then you've just <UNK> a bit of what i did during the <UNK> minutes i spent watching the movie but the <UNK> supporting cast of over <UNK> clichés is the least of this film's <UNK> the biggest one is that the whole <UNK> is entirely pointless we aren't given a fascinating look into a <UNK> mind we aren't given an effective explanation we aren't given much of anything given that it <UNK> so much i'm <UNK> go ahead and <UNK> the ending for you so that you never have to see it <UNK> <UNK> the <UNK> because all <UNK> could see in the world was <UNK> and wanted to <UNK> <UNK> or whatever the <UNK> name was the <UNK> in his eyes it's like the worst <UNK> band in the world made an <UNK> and <UNK> it the world is sad so i killed a <UNK> oh and <UNK> dies in the end in a sequence so <UNK> of unbelievable <UNK> that it would have <UNK> the movie if the movie didn't already <UNK> of course he dies in the end because that made the movie so deep br br i'm giving the movie 2 stars because the actors themselves all did a pretty good job with the <UNK> they were given the scenes with <UNK> and <UNK> together were even interesting on some <UNK> but to <UNK> the film itself you have to believe that movies are more than the <UNK> of their parts\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 327\n",
      "<START> minor spoilers br br if there's something in the world of silent <UNK> that <UNK> me it is that <UNK> chase never got his well deserved break through in the movies oh well maybe it isn't that strange really <UNK> as he never <UNK> in any full length features but when i think of it such an explanation makes it all only more mysterious because why the <UNK> didn't chase get any offers to play the leading lead in features one explanation is that his character no matter how amusing was simply too realistic to suit a longer story without the <UNK> elements that <UNK> <UNK> <UNK> <UNK> and other <UNK> <UNK> it can be <UNK> that the comedy he made and which worked so well for twenty minutes would get <UNK> after a few more <UNK> i don't quite buy this though as <UNK> <UNK> <UNK> is <UNK> and could i believe at its best <UNK> the interest of viewers alone for a longer period at least i am <UNK> to think so when <UNK> like a <UNK> runs the show br br mr <UNK> isn't <UNK> <UNK> and <UNK> <UNK> is hardly a classic beauty he <UNK> the truly biggest front <UNK> of any human being on the planet and she has a <UNK> large <UNK> both of them takes <UNK> <UNK> without the <UNK> knowledge and when they meet by accident just a little later he doesn't <UNK> his wife and she doesn't <UNK> her husband a number of hilarious <UNK> begin with many clever gags all the way through i don't think i'll <UNK> anything further to make the viewing more enjoyable for you because if you're a fan of silent comedies or even if you aren't <UNK> like a <UNK> offers so many memorable moments within such a short time that i would look upon it as a <UNK> shame not to see it silly indeed but no less extremely funny\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 178\n",
      "<START> if you don't have anything better to do then go ahead and rent this movie it's intelligent funny it will sure have your attention <UNK> for a while br br i discover it by <UNK> <UNK> in a boring <UNK> it was on cable and for the faces i saw i thought it may worth the try it made me laugh and for a movie in a <UNK> with nothing else on tv it was ok br br <UNK> <UNK> looks amazing in the movie even though her acting is not what i expected it's kind of poor acting and for the rest of the crew i liked <UNK> in her role as a dr also i found interesting seeing the guy from the <UNK> what i like about you playing an almost gay <UNK> br br as for j <UNK> i found it as always a very good performance michael douglas plays a small role but his <UNK> was hard for me to <UNK> him br br it's also a good movie to watch with company\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 341\n",
      "<START> this is a very strange film with a no name cast and <UNK> nothing known about it on the <UNK> it uses an approach familiar to those who have watched the likes of <UNK> in that it <UNK> a <UNK> of so called horror <UNK> and <UNK> them together into a <UNK> narrative of the people who are involved in the <UNK> getting off a <UNK> there is a <UNK> who <UNK> on about relationships but his talking adds absolutely nothing to the mix at all and just adds to the <UNK> as for the stories themselves well i <UNK> i have not got a <UNK> why this movie got an <UNK> <UNK> in the <UNK> which would bring it into line with the likes of nightmare on <UNK> street and the <UNK> nothing here is even <UNK> scary there is no gore sex nudity or even a <UNK> word to <UNK> things up this is the kind of thing you could put out on <UNK> tv and no one would <UNK> an <UNK> i can only think if it had got the rating it truly deserved a <UNK> no serious horror fan would be seen dead with it so the <UNK> probably <UNK> the <UNK> until they <UNK> anyway here are the 3 <UNK> in <UNK> 1 a man becomes <UNK> <UNK> with his <UNK> car to the point of <UNK> his <UNK> 2 a man who lives in a <UNK> apartment is <UNK> <UNK> out when a living <UNK> <UNK> from his six <UNK> old <UNK> <UNK> 3 a woman thinks she has found the perfect man through a computer <UNK> <UNK> that is until he starts to act weird and there you have it some of them are pretty amusing due to their <UNK> <UNK> my favourite being number 2 but you get the feeling they were meant to be a <UNK> and b <UNK> plays unfortunately they fail <UNK> on both <UNK> to <UNK> up then this flick is an <UNK> <UNK> for very good reasons\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 343\n",
      "<START> let's see what are the <UNK> to watching <UNK> <UNK> well if you've never seen anything to do with <UNK> there's a lot of <UNK> footage of both <UNK> and the <UNK> and <UNK> side and of the various <UNK> <UNK> at work and play as well as plenty of <UNK> <UNK> if you like william smith he plays a bit of a <UNK> as he has always been <UNK> to do br br and that's about it if it wasn't for william smith this could probably pass as a <UNK> <UNK> film for save the children or some other <UNK> that <UNK> the third world the only time you really see the <UNK> of the title is during the opening credits no <UNK> killer <UNK> like in <UNK> <UNK> named <UNK> you'd figure with twice the <UNK> in the title there would be twice as many monster <UNK> <UNK> on the characters but <UNK> this is not the case br br the story starts with a <UNK> and her brother coming to <UNK> to do a story on one of the last <UNK> places on the planet but their <UNK> quickly changes to one of wanting to find <UNK> which are apparently fairly <UNK> there br br there's not a lot of real action or <UNK> in this movie what <UNK> been an exciting <UNK> race is <UNK> by the <UNK> of <UNK> and animal footage that is <UNK> in it to <UNK> out the films running time there's not a whole lot more action until the last <UNK> minutes or so of the movie which is probably about how long the movie would last without all the br br in my view the only ways that a movie can really be a bad movie is to be boring or incredibly stupid <UNK> <UNK> certainly <UNK> for that former <UNK> and is pretty damn close to the second the only reason i won't rate it a 1 is that the added footage is more interesting than the rest of the movie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_errors(x_test_seq, model, test_labels, int2word, n_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Use a convolutional network instead of a RNN\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Conv1D(\n",
    "    filters, kernel_size\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "tf.keras.layers.MaxPool1D(\n",
    "    pool_size=2\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Flatten()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "num_words = 2000\n",
    "((train_data, train_labels), (test_data, test_labels)\n",
    " ) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "#  limit the data for class time\n",
    "# Transform word_id to word and reverse\n",
    "word2int = imdb.get_word_index()\n",
    "word2int = {w: i+3 for w, i in word2int.items()}\n",
    "word2int[\"<PAD>\"] = 0\n",
    "word2int[\"<START>\"] = 1\n",
    "word2int[\"<UNK>\"] = 2\n",
    "word2int[\"<UNUSED>\"] = 3\n",
    "int2word = {i: w for w, i in word2int.items()}\n",
    "num_words = num_words+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 100)\n",
      "test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "max_len = 100\n",
    "x_train_seq = sequence.pad_sequences(train_data, maxlen=max_len, truncating='post', padding='post')\n",
    "x_test_seq = sequence.pad_sequences(test_data, maxlen=max_len, truncating='post', padding='post')\n",
    "\n",
    "print('train shape:', x_train_seq.shape)\n",
    "print('test shape:', x_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(max_len,), name='input'))\n",
    "## one-hot encoding\n",
    "model.add(layers.Embedding(input_dim=num_words, output_dim=num_words,\n",
    "                           input_length=max_len, embeddings_initializer='identity',\n",
    "                           trainable=False))\n",
    "\n",
    "\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "88/88 [==============================] - 74s 831ms/step - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6747 - val_accuracy: 0.6352\n",
      "Epoch 2/5\n",
      "88/88 [==============================] - 70s 793ms/step - loss: 0.6032 - accuracy: 0.6811 - val_loss: 0.4481 - val_accuracy: 0.7912\n",
      "Epoch 3/5\n",
      "88/88 [==============================] - 50s 570ms/step - loss: 0.3984 - accuracy: 0.8220 - val_loss: 0.4070 - val_accuracy: 0.8140\n",
      "Epoch 4/5\n",
      "88/88 [==============================] - 49s 558ms/step - loss: 0.3549 - accuracy: 0.8434 - val_loss: 0.3995 - val_accuracy: 0.8192\n",
      "Epoch 5/5\n",
      "88/88 [==============================] - 50s 571ms/step - loss: 0.3104 - accuracy: 0.8689 - val_loss: 0.4124 - val_accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "epochs = 5\n",
    "history = model.fit(x_train_seq, train_labels,\n",
    "                    validation_split=0.1, epochs=epochs,\n",
    "                    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3799],\n",
       "       [0.9474],\n",
       "       [0.8705],\n",
       "       [0.7794],\n",
       "       [0.6296]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = ['the film was really bad and i am very disappointed',\n",
    "           'The film was very funny entertaining and good we had a great time . brilliant film',\n",
    "           'this film was just brilliant',\n",
    "           'the film is not good',\n",
    "           'the film is not bad']\n",
    "sequences = [vectorize_text_sentence(review.lower(), word2int)\n",
    "             for review in reviews]\n",
    "\n",
    "## Padding the sequences\n",
    "x_pred  = sequence.pad_sequences(sequences, maxlen=max_len, truncating='post', padding='post')# ...\n",
    "\n",
    "np.round(model.predict(x_pred), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : 0, real : 1, lenght: 213\n",
      "<START> <UNK> director david <UNK> <UNK> love of blood and gore and <UNK> heads with the more confusing aspects of a reality <UNK> david <UNK> film and it actually works <UNK> i won't bother trying to give even the <UNK> <UNK> of a plot <UNK> here because <UNK> only cause more <UNK> all you need to know is that the film is about a <UNK> reality computer game that is so incredibly <UNK> that it becomes difficult to tell the difference between reality and <UNK> reality the film almost seems to <UNK> its <UNK> <UNK> point at the end but then it <UNK> in the final twist in the very last line of dialogue br br there's also some very <UNK> sexual <UNK> based around the in the <UNK> <UNK> as well as some very <UNK> acting from <UNK> law he manages to come off as <UNK> and stupid and boring and any other annoying <UNK> you can care to think of jason <UNK> <UNK> comes off much better and everyone else can be called a supporting character including <UNK> <UNK> in a <UNK> if <UNK> role as a money <UNK> <UNK> overall is a very effective sci fi film about the <UNK> <UNK> can present and the possible <UNK> it will <UNK>\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 153\n",
      "<START> man i think people have forgotten how to watch a movie everyone thinks they're a <UNK> they comment on things that the average movie <UNK> doesn't even know or think about br br i enjoyed the film it was what i was expecting therefore was not disappointed <UNK> gets a bad <UNK> for putting his <UNK> into his films but that's also a reason to watch what's even more funny is the people that <UNK> about his films say he's the worst and that we shouldn't watch his films yet watch his movies anyway all so they can comment on how bad they are who's the <UNK> if you don't like his work don't watch it then you won't have to subject yourself to this supposedly painful event br br stop <UNK> movies to other movies and watch a movie on an <UNK> <UNK> and you may begin to enjoy films again\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 226\n",
      "<START> i love <UNK> they are among my favorite <UNK> of film before seeing this film i hadn't seen one that i hadn't liked br br the premise for this film is a great one the <UNK> is well done there were some times early on when i laughed and <UNK> yet as the film went on the more <UNK> and <UNK> it became this could have been something special had the subject not been such an <UNK> <UNK> <UNK> <UNK> i appreciate his passion for film but <UNK> your <UNK> if you're short on <UNK> maybe you shouldn't have so many kids or spend so much money on <UNK> maybe you should have gone to film school or at least <UNK> from high school maybe you should have lived life and gotten perspective and <UNK> that could add to your vision br br there are so many people out there with stories that are interesting funny and <UNK> to see this guy <UNK> over any of them is nothing less than <UNK> if you want to do a documentary on a film <UNK> why not do one on someone from <UNK> or <UNK> a film <UNK> with real problems br br two final questions br br who takes a little kid to see <UNK> now br br how many times did this guy say man\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 330\n",
      "<START> the film <UNK> <UNK> was a good view although still <UNK> at over 4 hours but the film took great <UNK> as usual with hollywood james chris <UNK> and <UNK> were actually married in real life their main <UNK> to the <UNK> <UNK> war was to start it by being <UNK> well by starting it i mean it came at the beginning not the end here's the real <UNK> james and <UNK> <UNK> were <UNK> married because one <UNK> could be given to each family by <UNK> as single <UNK> they could get two <UNK> they <UNK> on crazy woman <UNK> actually <UNK> the water above the land held by a powerful member of the <UNK> he <UNK> to buy them out <UNK> which they <UNK> br br although <UNK> in real life as the <UNK> of a <UNK> <UNK> kate and a <UNK> herself and also in the film there is no real <UNK> that was true it is known that she bought many head of sick <UNK> <UNK> them back to life and was later <UNK> by the <UNK> of <UNK> the <UNK> in <UNK> for <UNK> in the end she was <UNK> of <UNK> an act almost certainly <UNK> so much for this part of the <UNK> of the american west which is a de <UNK> of <UNK> <UNK> a time period of about one <UNK> years br br in real life she and jim were surprised one day by several members of the <UNK> taken in hand and <UNK> <UNK> those <UNK> the <UNK> were never brought to <UNK> but that was the first <UNK> that led to the murder of <UNK> <UNK> and the start of the <UNK> <UNK> war br br quite different from the hollywood version which shows her shot at the end br br other than that i think the main problem with the film was the <UNK> who could have made the action a <UNK> pace by more <UNK> editing\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 135\n",
      "<START> i went into this movie with <UNK> high expectations after loving the cartoon series in my childhood and this nearly <UNK> that love for me jason lee david <UNK> in the film is <UNK> i understand it can't be easy to act with cgi characters who aren't actually there but i really found his performance <UNK> along with all the other non animated characters the <UNK> were <UNK> yet sometimes <UNK> obvious at moving the plot of the story along and therefore did not <UNK> me to stay in the theater for longer than half an hour into the film if you feel you must see this film rent it at the most it is not worth <UNK> <UNK> to see it in <UNK> unless you'd like a good laugh at the horrible acting\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 206\n",
      "<START> an <UNK> <UNK> some <UNK> and a <UNK> of a <UNK> machine a powerful and <UNK> <UNK> fall in a <UNK> in <UNK> the <UNK> company <UNK> a <UNK> <UNK> <UNK> by <UNK> <UNK> <UNK> <UNK> the <UNK> of a huge <UNK> which <UNK> the <UNK> and father of one of the scientist there the group finds the <UNK> of the plane five <UNK> far from the expected location and the machine and the remains of the <UNK> further they realize that a <UNK> a kind of big <UNK> is <UNK> them this movie is so ridiculous that i do not know what i am doing <UNK> my time again in this garbage the direction is awful the actors and the lines are horrible <UNK> parts of the and even the <UNK> witch <UNK> to <UNK> how bad this movie is its best scene is when <UNK> <UNK> the character of <UNK> <UNK> is <UNK> and the <UNK> of the <UNK> says that she needs to have an <UNK> of <UNK> <UNK> <UNK> <UNK> her <UNK> and the <UNK> says <UNK> <UNK> but the shot needs to be in your ridiculous my <UNK> is two br br title <UNK> <UNK> o <UNK> the br br\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 91\n",
      "<START> i had to <UNK> my rating of this movie to a 4 due to the terrible sound track i'm pretty sure it was not a problem with me or the <UNK> because some actors and the sound track <UNK> great but most of the actors <UNK> were <UNK> or <UNK> beyond <UNK> especially for non <UNK> br br there are plenty of cute little twists that would make this an enjoyable movie ending up in <UNK> by mistake is great but much of the humor was lost in the sound\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 337\n",
      "<START> child death and horror movies will always <UNK> a <UNK> <UNK> <UNK> and therefore it is my personal opinion that every movie that shows the <UNK> to <UNK> on this <UNK> should <UNK> some extra attention from horror fans of course like in the case of <UNK> little things <UNK> themes don't always <UNK> a good film despite the <UNK> interesting plot the <UNK> setting and the <UNK> of video nasty director j s <UNK> the <UNK> this is an <UNK> and cliché <UNK> film that couldn't offer a single <UNK> or shock after <UNK> their husband and father the <UNK> women mother <UNK> and her <UNK> <UNK> and <UNK> move to a small and <UNK> <UNK> town where they <UNK> an old <UNK> <UNK> their new home is <UNK> close to the old mine <UNK> where <UNK> of innocent children <UNK> lost their lives in <UNK> strange things start to happen like young <UNK> <UNK> an <UNK> girl who used to live in their house and the <UNK> <UNK> seem to keep <UNK> from <UNK> and her <UNK> quickly turns out that the <UNK> children still leave their mine <UNK> at night to <UNK> <UNK> on the <UNK> of the <UNK> <UNK> mr <UNK> who was responsible for their <UNK> <UNK> little things is rather <UNK> and extremely predictable the script <UNK> <UNK> one <UNK> cliché after the other like car <UNK> stuck in the <UNK> at <UNK> times <UNK> and <UNK> broken <UNK> there's very little suspense even less gore and the make up effects are <UNK> weak the <UNK> children don't look <UNK> at all actually they all look like <UNK> <UNK> of <UNK> <UNK> with their black <UNK> <UNK> faces and dark eyes the <UNK> free finale is stupid and just as <UNK> as the rest of this pointless production <UNK> is thoroughly <UNK> in her leading role as the mother but <UNK> taylor <UNK> <UNK> a big star thanks to the <UNK> remake and young <UNK> are <UNK> as the <UNK>\n",
      "\n",
      "Predicted : 1, real : 0, lenght: 70\n",
      "<START> i know it's not original but what the hey what else can be said about it i feel <UNK> silly just <UNK> any attention at all to from hell it came the movie makes the important political and social issue of <UNK> from <UNK> <UNK> <UNK> seem a matter for <UNK> and <UNK> not the <UNK> and <UNK> being <UNK> by <UNK> all over the world at the time\n",
      "\n",
      "Predicted : 0, real : 1, lenght: 585\n",
      "<START> it would be something to try and tell someone what <UNK> <UNK> is very simply about or maybe it isn't <UNK> goes to the <UNK> <UNK> and <UNK> <UNK> to film <UNK> <UNK> and the <UNK> but this is just the <UNK> <UNK> it's a <UNK> that you either <UNK> yourself to or you don't he gets into the form of the world around him entirely without a story <UNK> only to certain aspects of written <UNK> as his camera shooting on supposedly <UNK> film <UNK> <UNK> like in a pure <UNK> one might even jump to that easy conclusion as he puts up these <UNK> <UNK> then moving to more <UNK> <UNK> culture though not the actual <UNK> culture itself and to a point <UNK> too <UNK> to be able to <UNK> <UNK> here sometimes it takes a while to get along close to a <UNK> through the <UNK> <UNK> but a <UNK> in how parts are <UNK> either by nature or by broken down <UNK> soon the <UNK> <UNK> from the who by the way does the music for most of his films with the <UNK> <UNK> of actually highly <UNK> shots adds a whole different level to it it's a <UNK> film and it's not easy but the <UNK> are what best comes <UNK> to <UNK> idea of <UNK> truth images he's been out for his whole career br br one <UNK> if the images end up by the time the second <UNK> <UNK> leading along the words <UNK> or if it's the other way around you're eyes are moving along with the <UNK> and <UNK> and the <UNK> is close to being religious writing but there's also the music <UNK> how the <UNK> <UNK> singing and low key <UNK> music goes together with <UNK> <UNK> and <UNK> faith i think each side ends up <UNK> the other and it's something that still seems like it shouldn't work perhaps that's the <UNK> to it the <UNK> taken in going through <UNK> <UNK> and the <UNK> run <UNK> of any kind of <UNK> life in this case the <UNK> of the <UNK> that make it so fascinating if only for the <UNK> sense it's a <UNK> too <UNK> for the <UNK> photography fan because of <UNK> of <UNK> and some of the <UNK> images of any <UNK> film there's <UNK> there's long shots there's hand held while driving by the <UNK> there's a <UNK> <UNK> of <UNK> away that <UNK> <UNK> seems only a couple there's full on close ups of fire and a man <UNK> a <UNK> and talking about its <UNK> truly classic <UNK> comedy there's people <UNK> still in fake <UNK> and a man and woman playing <UNK> music but most <UNK> it ends up feeling at least for me natural for the personal nature of the approach br br i'm sure only <UNK> would know for certain why he made this film as <UNK> to the simple <UNK> he was already filming even <UNK> started small and he ended up going through many <UNK> to finish it yet this is what makes <UNK> <UNK> such an amazing <UNK> it will appeal to one <UNK> on what someone brings to it in actually watching it it's definitely <UNK> but there's the <UNK> to want to see it again very soon after just to experience all of the ideas and <UNK> turned <UNK> strange <UNK> yes the word <UNK> here it's one of the truly <UNK> art films ever made\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_errors(x_test_seq, model, test_labels, int2word, n_samples=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
