{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ac4bae",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2360c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e3013",
   "metadata": {},
   "source": [
    "# Abalone Dataset\n",
    "\n",
    "Abalones are marine snails that can be found along coasts of almost every continent. \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/AbaloneInside.jpg/440px-AbaloneInside.jpg\" alt=\"abalone\" border=\"0\" width=\"400\" height=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we are going to Predict the age of abalone from physical measurements. [Link to documentation](https://archive.ics.uci.edu/ml/datasets/abalone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801c6c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0eaeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.522693</td>\n",
       "      <td>0.406575</td>\n",
       "      <td>0.139271</td>\n",
       "      <td>0.824734</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>0.180162</td>\n",
       "      <td>0.237921</td>\n",
       "      <td>9.896988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.121164</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>0.491182</td>\n",
       "      <td>0.222223</td>\n",
       "      <td>0.110182</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>3.205654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.436375</td>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.127375</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.795250</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.170750</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length     Diameter       Height  Whole weight  Shucked weight  \\\n",
       "count  3320.000000  3320.000000  3320.000000   3320.000000     3320.000000   \n",
       "mean      0.522693     0.406575     0.139271      0.824734        0.357705   \n",
       "std       0.121164     0.100120     0.042708      0.491182        0.222223   \n",
       "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
       "25%       0.450000     0.345000     0.115000      0.436375        0.181500   \n",
       "50%       0.540000     0.425000     0.140000      0.795250        0.335500   \n",
       "75%       0.615000     0.480000     0.165000      1.150000        0.504500   \n",
       "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
       "\n",
       "       Viscera weight  Shell weight          Age  \n",
       "count     3320.000000   3320.000000  3320.000000  \n",
       "mean         0.180162      0.237921     9.896988  \n",
       "std          0.110182      0.140261     3.205654  \n",
       "min          0.000500      0.001500     1.000000  \n",
       "25%          0.092000      0.127375     8.000000  \n",
       "50%          0.170750      0.230000     9.000000  \n",
       "75%          0.253125      0.325000    11.000000  \n",
       "max          0.760000      1.005000    27.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b179759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('Age')\n",
    "X_train = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fede61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "y_test = df_test.pop('Age')\n",
    "X_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de841977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3320, 7), X_test shape: (850, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bf8de",
   "metadata": {},
   "source": [
    "## Regression Losses\n",
    "\n",
    "- **Mean Squared Error (MSE)**: \n",
    "\n",
    "```python\n",
    "tf.keras.losses.MSE\n",
    "```\n",
    "```python\n",
    "model.compile(loss='mse') or model.compile(loss=tf.keras.losses.MSE)\n",
    "```\n",
    "\n",
    "$$ \\mathrm{MSE} = \\frac{\\sum_{i=1}^n\\left( y_i - \\hat{y_i}\\right)^2}{n}$$\n",
    "\n",
    "\n",
    "- **Mean Absolute Error (MAE)**: \n",
    "\n",
    "```python\n",
    "tf.keras.losses.MAE\n",
    "```\n",
    "```python\n",
    "model.compile(loss='mae') or model.compile(loss=tf.keras.losses.MAE)\n",
    "```\n",
    "\n",
    "$$ \\mathrm{MAE} = \\frac{\\sum_{i=1}^n\\left| y_i - \\hat{y_i}\\right|}{n}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c743b",
   "metadata": {},
   "source": [
    "## Question 1: Create a sequential net with at least 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f142132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, input_shape=(7,), activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26bb1a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 102.7421 - mae: 9.6083 - val_loss: 71.1714 - val_mae: 7.9244\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 0s 568us/step - loss: 58.8385 - mae: 7.1320 - val_loss: 28.1901 - val_mae: 4.6059\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 0s 548us/step - loss: 21.5446 - mae: 3.7431 - val_loss: 9.6292 - val_mae: 2.2495\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 0s 541us/step - loss: 9.5226 - mae: 2.1909 - val_loss: 8.2565 - val_mae: 2.1081\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 0s 547us/step - loss: 7.6318 - mae: 2.0070 - val_loss: 7.9059 - val_mae: 2.0600\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 0s 549us/step - loss: 8.0880 - mae: 2.0715 - val_loss: 7.5765 - val_mae: 2.0009\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 0s 542us/step - loss: 7.2738 - mae: 1.9451 - val_loss: 7.2848 - val_mae: 1.9627\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 0s 548us/step - loss: 7.5317 - mae: 1.9450 - val_loss: 7.0421 - val_mae: 1.9223\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 0s 559us/step - loss: 6.9695 - mae: 1.8691 - val_loss: 6.8207 - val_mae: 1.9381\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 0s 533us/step - loss: 6.6445 - mae: 1.8553 - val_loss: 6.6339 - val_mae: 1.9117\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 0s 533us/step - loss: 6.5167 - mae: 1.8538 - val_loss: 6.5297 - val_mae: 1.8555\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 0s 534us/step - loss: 6.6345 - mae: 1.8361 - val_loss: 6.4012 - val_mae: 1.8598\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - 0s 527us/step - loss: 6.4026 - mae: 1.8050 - val_loss: 6.3084 - val_mae: 1.8706\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - 0s 524us/step - loss: 6.6823 - mae: 1.8651 - val_loss: 6.2365 - val_mae: 1.8689\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - 0s 555us/step - loss: 6.3457 - mae: 1.8345 - val_loss: 6.1898 - val_mae: 1.8269\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - 0s 530us/step - loss: 6.2351 - mae: 1.7808 - val_loss: 6.1110 - val_mae: 1.8277\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - 0s 577us/step - loss: 6.0174 - mae: 1.7949 - val_loss: 6.0409 - val_mae: 1.8321\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - 0s 549us/step - loss: 6.0860 - mae: 1.7856 - val_loss: 5.9743 - val_mae: 1.8035\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 5.7403 - mae: 1.7554 - val_loss: 5.9101 - val_mae: 1.8303\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - 0s 545us/step - loss: 5.3427 - mae: 1.6805 - val_loss: 5.8334 - val_mae: 1.8021\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - 0s 530us/step - loss: 5.5664 - mae: 1.7233 - val_loss: 5.7805 - val_mae: 1.7569\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - 0s 521us/step - loss: 6.1490 - mae: 1.7774 - val_loss: 5.7081 - val_mae: 1.7519\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - 0s 518us/step - loss: 5.2170 - mae: 1.6508 - val_loss: 5.6383 - val_mae: 1.7521\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - 0s 543us/step - loss: 5.8238 - mae: 1.7550 - val_loss: 5.6458 - val_mae: 1.6996\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 5.6040 - mae: 1.7038 - val_loss: 5.5227 - val_mae: 1.7444\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 5.8842 - mae: 1.7727 - val_loss: 5.5757 - val_mae: 1.6705\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - 0s 516us/step - loss: 5.8874 - mae: 1.7271 - val_loss: 5.4816 - val_mae: 1.6705\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - 0s 520us/step - loss: 5.2638 - mae: 1.6172 - val_loss: 5.3699 - val_mae: 1.7038\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - 0s 526us/step - loss: 4.9819 - mae: 1.6233 - val_loss: 5.3317 - val_mae: 1.6771\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - 0s 521us/step - loss: 4.8628 - mae: 1.6227 - val_loss: 5.2967 - val_mae: 1.7246\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - 0s 523us/step - loss: 5.3460 - mae: 1.7121 - val_loss: 5.2447 - val_mae: 1.7014\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - 0s 533us/step - loss: 5.4229 - mae: 1.6595 - val_loss: 5.2024 - val_mae: 1.6812\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - 0s 546us/step - loss: 5.0749 - mae: 1.6472 - val_loss: 5.1949 - val_mae: 1.7041\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - 0s 567us/step - loss: 5.4392 - mae: 1.7199 - val_loss: 5.1489 - val_mae: 1.6467\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - 0s 553us/step - loss: 5.1824 - mae: 1.6219 - val_loss: 5.1277 - val_mae: 1.6826\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - 0s 543us/step - loss: 4.9034 - mae: 1.6249 - val_loss: 5.0926 - val_mae: 1.6456\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - 0s 542us/step - loss: 4.9109 - mae: 1.6000 - val_loss: 5.1313 - val_mae: 1.6096\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - 0s 565us/step - loss: 4.8138 - mae: 1.5765 - val_loss: 5.0546 - val_mae: 1.6305\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - 0s 547us/step - loss: 5.1189 - mae: 1.6494 - val_loss: 5.0971 - val_mae: 1.6033\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - 0s 545us/step - loss: 5.0594 - mae: 1.6164 - val_loss: 5.0234 - val_mae: 1.6275\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - 0s 553us/step - loss: 5.0652 - mae: 1.6259 - val_loss: 5.0298 - val_mae: 1.6076\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - 0s 547us/step - loss: 4.8291 - mae: 1.5930 - val_loss: 5.0017 - val_mae: 1.6486\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - 0s 562us/step - loss: 4.7003 - mae: 1.6023 - val_loss: 4.9859 - val_mae: 1.6284\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - 0s 543us/step - loss: 4.6752 - mae: 1.5850 - val_loss: 4.9802 - val_mae: 1.6373\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - 0s 561us/step - loss: 4.8592 - mae: 1.6282 - val_loss: 4.9640 - val_mae: 1.6272\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - 0s 553us/step - loss: 4.6841 - mae: 1.6035 - val_loss: 5.0139 - val_mae: 1.6763\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - 0s 558us/step - loss: 4.3111 - mae: 1.5296 - val_loss: 4.9547 - val_mae: 1.6265\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - 0s 548us/step - loss: 4.7764 - mae: 1.6037 - val_loss: 4.9793 - val_mae: 1.5891\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - 0s 521us/step - loss: 4.8601 - mae: 1.6215 - val_loss: 4.9736 - val_mae: 1.5885\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - 0s 507us/step - loss: 4.8717 - mae: 1.6155 - val_loss: 4.9433 - val_mae: 1.5968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15d8d2a30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    metrics=['mae']\n",
    ")\n",
    "model.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644f80fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 275us/step - loss: 5.5356 - mae: 1.6244\n",
      "Test Loss: 5.535606384277344\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9a6494",
   "metadata": {},
   "source": [
    "## Question 2: Normalize the inputs and train the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebbfbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train mu, sigma [ 2.77689518e-16  4.65491099e-17  2.50402109e-16 -2.81434849e-16\n",
      "  2.18299274e-16  1.77100637e-16 -1.05404306e-16] [1. 1. 1. 1. 1. 1. 1.]\n",
      "X_test mu, sigma [0.05808422 0.06917445 0.03098307 0.04461505 0.04160742 0.02421514\n",
      " 0.03516632] [0.95187926 0.95135017 0.89294094 0.99223632 0.99454932 0.97495047\n",
      " 0.96304109]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "print('X_train mu, sigma', X_train_norm.mean(0), X_train_norm.std(0))\n",
    "print('X_test mu, sigma', X_test_norm.mean(0), X_test_norm.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5277042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, input_shape=(7,), activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c1690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 99.3273 - mae: 9.4483 - val_loss: 63.5809 - val_mae: 7.2565\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 0s 560us/step - loss: 54.6784 - mae: 6.5652 - val_loss: 35.6929 - val_mae: 4.9783\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 0s 546us/step - loss: 34.9187 - mae: 4.8580 - val_loss: 28.7328 - val_mae: 4.4335\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 0s 555us/step - loss: 27.2311 - mae: 4.2435 - val_loss: 22.0178 - val_mae: 3.8168\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 0s 539us/step - loss: 20.8773 - mae: 3.6213 - val_loss: 14.9012 - val_mae: 3.0194\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 0s 556us/step - loss: 14.0520 - mae: 2.7901 - val_loss: 9.5170 - val_mae: 2.2459\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 0s 551us/step - loss: 9.0380 - mae: 2.1190 - val_loss: 7.1770 - val_mae: 1.8913\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 0s 541us/step - loss: 8.0262 - mae: 1.9333 - val_loss: 6.4097 - val_mae: 1.8344\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 0s 543us/step - loss: 6.9167 - mae: 1.8072 - val_loss: 6.1332 - val_mae: 1.8055\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 0s 532us/step - loss: 6.0816 - mae: 1.7807 - val_loss: 5.9501 - val_mae: 1.7791\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 0s 564us/step - loss: 6.1626 - mae: 1.7656 - val_loss: 5.7869 - val_mae: 1.7544\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 0s 547us/step - loss: 6.0008 - mae: 1.7895 - val_loss: 5.6530 - val_mae: 1.7218\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - 0s 547us/step - loss: 5.5980 - mae: 1.7291 - val_loss: 5.5351 - val_mae: 1.7089\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - 0s 535us/step - loss: 5.6094 - mae: 1.7150 - val_loss: 5.4163 - val_mae: 1.6747\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - 0s 538us/step - loss: 5.0813 - mae: 1.6629 - val_loss: 5.3663 - val_mae: 1.6872\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 5.1053 - mae: 1.6497 - val_loss: 5.2102 - val_mae: 1.6548\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - 0s 525us/step - loss: 5.4225 - mae: 1.7084 - val_loss: 5.1658 - val_mae: 1.6274\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - 0s 525us/step - loss: 4.9035 - mae: 1.6278 - val_loss: 5.0639 - val_mae: 1.6384\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - 0s 523us/step - loss: 4.6665 - mae: 1.5797 - val_loss: 5.0601 - val_mae: 1.6572\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - 0s 524us/step - loss: 4.7316 - mae: 1.6123 - val_loss: 4.9450 - val_mae: 1.6024\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - 0s 550us/step - loss: 4.7200 - mae: 1.5973 - val_loss: 4.9239 - val_mae: 1.6093\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - 0s 535us/step - loss: 4.4870 - mae: 1.5573 - val_loss: 4.8999 - val_mae: 1.5990\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - 0s 539us/step - loss: 4.6979 - mae: 1.5964 - val_loss: 4.8423 - val_mae: 1.5745\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - 0s 540us/step - loss: 4.4942 - mae: 1.5648 - val_loss: 4.8040 - val_mae: 1.5817\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - 0s 524us/step - loss: 4.4783 - mae: 1.5744 - val_loss: 4.7729 - val_mae: 1.5783\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - 0s 555us/step - loss: 4.6603 - mae: 1.5863 - val_loss: 4.7689 - val_mae: 1.5701\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - 0s 523us/step - loss: 4.1257 - mae: 1.4879 - val_loss: 4.7448 - val_mae: 1.5685\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - 0s 517us/step - loss: 4.6798 - mae: 1.5814 - val_loss: 4.7044 - val_mae: 1.5838\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - 0s 540us/step - loss: 4.3803 - mae: 1.5460 - val_loss: 4.6835 - val_mae: 1.5570\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 4.5136 - mae: 1.5588 - val_loss: 4.7204 - val_mae: 1.5724\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - 0s 533us/step - loss: 4.4850 - mae: 1.5340 - val_loss: 4.6778 - val_mae: 1.5377\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - 0s 521us/step - loss: 4.4814 - mae: 1.5592 - val_loss: 4.6375 - val_mae: 1.5596\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - 0s 518us/step - loss: 4.8245 - mae: 1.6177 - val_loss: 4.6289 - val_mae: 1.5616\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - 0s 515us/step - loss: 4.4174 - mae: 1.5386 - val_loss: 4.6172 - val_mae: 1.5822\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - 0s 516us/step - loss: 4.4068 - mae: 1.5544 - val_loss: 4.5980 - val_mae: 1.5386\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - 0s 516us/step - loss: 4.4785 - mae: 1.5406 - val_loss: 4.5863 - val_mae: 1.5404\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - 0s 511us/step - loss: 4.2572 - mae: 1.5046 - val_loss: 4.5884 - val_mae: 1.5484\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - 0s 525us/step - loss: 4.7239 - mae: 1.5570 - val_loss: 4.6060 - val_mae: 1.5176\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - 0s 525us/step - loss: 4.7543 - mae: 1.5769 - val_loss: 4.5552 - val_mae: 1.5271\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - 0s 532us/step - loss: 4.2963 - mae: 1.5044 - val_loss: 4.5539 - val_mae: 1.5234\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - 0s 536us/step - loss: 4.3011 - mae: 1.5110 - val_loss: 4.5527 - val_mae: 1.5226\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - 0s 536us/step - loss: 4.5120 - mae: 1.5395 - val_loss: 4.5330 - val_mae: 1.5390\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - 0s 521us/step - loss: 4.6410 - mae: 1.5574 - val_loss: 4.5126 - val_mae: 1.5330\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - 0s 545us/step - loss: 4.3980 - mae: 1.5160 - val_loss: 4.5244 - val_mae: 1.5127\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - 0s 800us/step - loss: 4.0587 - mae: 1.4778 - val_loss: 4.4927 - val_mae: 1.5291\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - 0s 550us/step - loss: 4.0889 - mae: 1.4912 - val_loss: 4.5455 - val_mae: 1.5417\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - 0s 540us/step - loss: 4.4780 - mae: 1.5402 - val_loss: 4.4742 - val_mae: 1.5134\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - 0s 522us/step - loss: 4.2091 - mae: 1.5023 - val_loss: 4.4758 - val_mae: 1.5257\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - 0s 520us/step - loss: 4.4685 - mae: 1.5430 - val_loss: 4.5651 - val_mae: 1.5511\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - 0s 525us/step - loss: 4.3095 - mae: 1.5203 - val_loss: 4.4487 - val_mae: 1.5387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15d804460>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    metrics=['mae']\n",
    ")\n",
    "model.fit(X_train_norm, y_train, epochs=50, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d2c1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 286us/step - loss: 5.1790 - mae: 1.5792\n",
      "Test Loss: 5.179037570953369\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de862aa9",
   "metadata": {},
   "source": [
    "## Optimizers:\n",
    "\n",
    "- [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD): Gradient descent with momentum\n",
    "```python\n",
    "tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD', **kwargs\n",
    ")\n",
    "```\n",
    "If momentum is 0:\n",
    "```python\n",
    "w = w - learning_rate * gradient\n",
    "```\n",
    "If we have momentum:\n",
    " \n",
    " ```python\n",
    "velocity = momentum * velocity - learning_rate * g\n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "\n",
    "- [RMSprop](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop): Root Mean Square Propagation\n",
    "```python\n",
    "tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop', **kwargs\n",
    ")\n",
    "```\n",
    "- [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam): Adaptive Moment Estimation,  is an update to the RMSProp algorithm\n",
    "```python\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cd71d",
   "metadata": {},
   "source": [
    "## Question 3: Train the same model with different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17c797bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                512       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, input_shape=(7,), activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81ef1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 94.5638 - mae: 9.1701 - val_loss: 57.9521 - val_mae: 6.7915\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 0s 544us/step - loss: 51.7070 - mae: 6.2664 - val_loss: 32.9604 - val_mae: 4.7626\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 0s 536us/step - loss: 34.1236 - mae: 4.7561 - val_loss: 26.7788 - val_mae: 4.2548\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 27.2453 - mae: 4.1790 - val_loss: 20.1501 - val_mae: 3.6177\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 0s 526us/step - loss: 19.7262 - mae: 3.4745 - val_loss: 13.5291 - val_mae: 2.7994\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 0s 519us/step - loss: 12.6845 - mae: 2.6143 - val_loss: 8.9920 - val_mae: 2.1470\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 0s 525us/step - loss: 8.9117 - mae: 2.0725 - val_loss: 7.1503 - val_mae: 1.9085\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 0s 533us/step - loss: 7.2587 - mae: 1.8974 - val_loss: 6.5670 - val_mae: 1.8657\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 0s 534us/step - loss: 6.3536 - mae: 1.8402 - val_loss: 6.3677 - val_mae: 1.8526\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 0s 518us/step - loss: 6.1680 - mae: 1.8130 - val_loss: 6.1104 - val_mae: 1.8030\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 0s 512us/step - loss: 5.9753 - mae: 1.7880 - val_loss: 5.9268 - val_mae: 1.7879\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 0s 528us/step - loss: 5.5645 - mae: 1.7178 - val_loss: 5.7728 - val_mae: 1.7549\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - 0s 540us/step - loss: 5.9364 - mae: 1.7549 - val_loss: 5.6316 - val_mae: 1.7291\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - 0s 537us/step - loss: 5.6196 - mae: 1.7319 - val_loss: 5.4806 - val_mae: 1.6961\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - 0s 510us/step - loss: 5.2990 - mae: 1.6493 - val_loss: 5.3677 - val_mae: 1.6901\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - 0s 532us/step - loss: 5.4649 - mae: 1.7130 - val_loss: 5.2511 - val_mae: 1.6647\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - 0s 537us/step - loss: 4.9094 - mae: 1.6365 - val_loss: 5.1510 - val_mae: 1.6596\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - 0s 513us/step - loss: 4.9306 - mae: 1.6521 - val_loss: 5.0976 - val_mae: 1.6345\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - 0s 531us/step - loss: 4.1629 - mae: 1.5218 - val_loss: 5.0326 - val_mae: 1.6539\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - 0s 543us/step - loss: 4.8867 - mae: 1.6308 - val_loss: 4.9826 - val_mae: 1.6074\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - 0s 524us/step - loss: 5.4155 - mae: 1.7047 - val_loss: 4.9337 - val_mae: 1.6024\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - 0s 510us/step - loss: 4.8187 - mae: 1.5931 - val_loss: 4.8670 - val_mae: 1.5979\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - 0s 559us/step - loss: 4.5833 - mae: 1.5712 - val_loss: 4.8398 - val_mae: 1.5813\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - 0s 528us/step - loss: 4.8667 - mae: 1.6125 - val_loss: 4.8752 - val_mae: 1.5632\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - 0s 534us/step - loss: 4.6765 - mae: 1.5753 - val_loss: 4.7781 - val_mae: 1.5753\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - 0s 533us/step - loss: 4.8782 - mae: 1.6269 - val_loss: 4.8085 - val_mae: 1.5710\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - 0s 534us/step - loss: 4.6845 - mae: 1.5796 - val_loss: 4.7343 - val_mae: 1.5863\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - 0s 525us/step - loss: 4.5880 - mae: 1.5724 - val_loss: 4.7372 - val_mae: 1.5618\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - 0s 528us/step - loss: 4.6576 - mae: 1.5844 - val_loss: 4.6963 - val_mae: 1.5572\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - 0s 513us/step - loss: 4.4620 - mae: 1.5541 - val_loss: 4.6728 - val_mae: 1.5662\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - 0s 524us/step - loss: 4.3587 - mae: 1.5431 - val_loss: 4.6814 - val_mae: 1.5630\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - 0s 525us/step - loss: 4.5528 - mae: 1.5488 - val_loss: 4.6484 - val_mae: 1.5613\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - 0s 512us/step - loss: 4.4184 - mae: 1.5480 - val_loss: 4.6446 - val_mae: 1.5728\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - 0s 526us/step - loss: 4.4316 - mae: 1.5418 - val_loss: 4.6219 - val_mae: 1.5613\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - 0s 520us/step - loss: 4.5646 - mae: 1.5708 - val_loss: 4.6221 - val_mae: 1.5678\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - 0s 526us/step - loss: 4.3918 - mae: 1.5479 - val_loss: 4.6523 - val_mae: 1.5293\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - 0s 512us/step - loss: 4.7123 - mae: 1.5843 - val_loss: 4.5734 - val_mae: 1.5550\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - 0s 505us/step - loss: 4.3657 - mae: 1.5304 - val_loss: 4.5843 - val_mae: 1.5405\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - 0s 521us/step - loss: 4.4461 - mae: 1.5536 - val_loss: 4.6147 - val_mae: 1.5307\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - 0s 516us/step - loss: 4.3659 - mae: 1.5338 - val_loss: 4.5446 - val_mae: 1.5446\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - 0s 518us/step - loss: 4.3735 - mae: 1.5531 - val_loss: 4.5354 - val_mae: 1.5378\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - 0s 519us/step - loss: 4.4426 - mae: 1.5465 - val_loss: 4.5257 - val_mae: 1.5388\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - 0s 527us/step - loss: 4.5389 - mae: 1.5704 - val_loss: 4.5528 - val_mae: 1.5243\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 4.3707 - mae: 1.5176 - val_loss: 4.5261 - val_mae: 1.5168\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 4.3427 - mae: 1.5464 - val_loss: 4.5167 - val_mae: 1.5282\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - 0s 529us/step - loss: 4.3891 - mae: 1.5385 - val_loss: 4.5099 - val_mae: 1.5172\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - 0s 550us/step - loss: 4.4079 - mae: 1.5450 - val_loss: 4.5537 - val_mae: 1.5175\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - 0s 549us/step - loss: 4.1233 - mae: 1.4922 - val_loss: 4.5050 - val_mae: 1.5257\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - 0s 517us/step - loss: 4.0604 - mae: 1.4787 - val_loss: 4.4848 - val_mae: 1.5133\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - 0s 523us/step - loss: 4.2391 - mae: 1.5211 - val_loss: 4.4869 - val_mae: 1.5067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x171f93bb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    metrics=['mae']\n",
    ")\n",
    "model.fit(X_train_norm, y_train, epochs=50, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2fffa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 254us/step - loss: 5.2125 - mae: 1.5566\n",
      "Test Loss: 5.212531089782715\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbeacf",
   "metadata": {},
   "source": [
    "# Keras Tuner\n",
    "\n",
    "The [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner) is a library for hyper-parameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "651f70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b17e7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9b048",
   "metadata": {},
   "source": [
    "Hyperparameters are of two types:\n",
    "1. **Model hyperparameters** like number of units, type of activation or number hidden layers.\n",
    "2. **Algorithm hyperparameters** like the learning rate in adam.\n",
    "\n",
    "The model-building function takes an argument `hp` from which you can sample hyper-parameters.\n",
    "\n",
    "```python\n",
    "def build_model(hp):\n",
    "    ...\n",
    "    return model\n",
    "\n",
    "```\n",
    "\n",
    "- `hp.Int` to sample an integer from a certain range:\n",
    "```python\n",
    "hp.Int('units', min_value=32, max_value=256, step=32, default=64)\n",
    "```\n",
    "- `hp.Float` to sample a float number from a certain range:\n",
    "```python\n",
    "hp.Float('dropout', min_value=0.0, max_value=0.1, default=0.005, step=0.05)\n",
    "```\n",
    "- `hp.Choice` to select values in a list:\n",
    "```python\n",
    "hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "```\n",
    "- [list of hyperparameter methods](https://keras-team.github.io/keras-tuner/documentation/hyperparameters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef99c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    # Sample different number of layers with hp.Int\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        # Sample different number of layers with hp.Int\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=128,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    # Sample different activation functions with hp.Choice \n",
    "    model.add(layers.Dense(1, activation=hp.Choice('output_activation', ['relu', 'linear'])))\n",
    "    \n",
    "    # Sample different activation functions with hp.Choice \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mse',\n",
    "        metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860707be",
   "metadata": {},
   "source": [
    "The Keras Tuner has four [tuners](https://keras-team.github.io/keras-tuner/documentation/tuners/) available  `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8261f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=35,\n",
    "                     factor=2,\n",
    "                     hyperband_iterations=1,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "'''\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=100,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "'''\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "322e674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 Complete [00h 00m 01s]\n",
      "val_loss: 4.72876501083374\n",
      "\n",
      "Best val_loss So Far: 4.565352439880371\n",
      "Total elapsed time: 00h 01m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "{'space': [{'class_name': 'Int', 'config': {'name': 'num_layers', 'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'units_0', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Choice', 'config': {'name': 'output_activation', 'default': 'relu', 'conditions': [], 'values': ['relu', 'linear'], 'ordered': False}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}}, {'class_name': 'Int', 'config': {'name': 'units_1', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'units_2', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}], 'values': {'num_layers': 2, 'units_0': 64, 'output_activation': 'relu', 'learning_rate': 0.01, 'units_1': 32, 'units_2': 64, 'tuner/epochs': 35, 'tuner/initial_epoch': 18, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '8a6d1a6cdc773a3bf1d9caae507d7057'}}\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_norm, y_train, epochs=30, validation_split=0.15, batch_size=32, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d31a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.01\n",
      "Best output activation function: relu\n",
      "Best number of hidden layers: 2\n",
      "Number of units of hidden layer 1: 64\n",
      "Number of units of hidden layer 2: 32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
    "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48fd86",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d06c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 35.3727 - mae: 4.4115 - val_loss: 6.5827 - val_mae: 1.9489\n",
      "Epoch 2/50\n",
      "89/89 [==============================] - 0s 629us/step - loss: 5.8767 - mae: 1.7711 - val_loss: 6.1930 - val_mae: 1.7233\n",
      "Epoch 3/50\n",
      "89/89 [==============================] - 0s 570us/step - loss: 4.8702 - mae: 1.6233 - val_loss: 5.0159 - val_mae: 1.5718\n",
      "Epoch 4/50\n",
      "89/89 [==============================] - 0s 580us/step - loss: 5.0054 - mae: 1.6354 - val_loss: 6.2235 - val_mae: 1.7521\n",
      "Epoch 5/50\n",
      "89/89 [==============================] - 0s 596us/step - loss: 4.6986 - mae: 1.6003 - val_loss: 6.4021 - val_mae: 1.9224\n",
      "Epoch 6/50\n",
      "89/89 [==============================] - 0s 574us/step - loss: 4.8515 - mae: 1.6262 - val_loss: 4.8918 - val_mae: 1.6877\n",
      "Epoch 7/50\n",
      "89/89 [==============================] - 0s 562us/step - loss: 4.4928 - mae: 1.5663 - val_loss: 4.6230 - val_mae: 1.5613\n",
      "Epoch 8/50\n",
      "89/89 [==============================] - 0s 558us/step - loss: 4.4315 - mae: 1.5320 - val_loss: 4.8386 - val_mae: 1.5421\n",
      "Epoch 9/50\n",
      "89/89 [==============================] - 0s 553us/step - loss: 4.4552 - mae: 1.5441 - val_loss: 4.8142 - val_mae: 1.5888\n",
      "Epoch 10/50\n",
      "89/89 [==============================] - 0s 560us/step - loss: 4.2734 - mae: 1.5076 - val_loss: 4.7297 - val_mae: 1.6014\n",
      "Epoch 11/50\n",
      "89/89 [==============================] - 0s 559us/step - loss: 4.1683 - mae: 1.5127 - val_loss: 4.7318 - val_mae: 1.5215\n",
      "Epoch 12/50\n",
      "89/89 [==============================] - 0s 557us/step - loss: 4.5849 - mae: 1.5639 - val_loss: 4.7305 - val_mae: 1.5607\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf0b6314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 332us/step - loss: 5.0798 - mae: 1.5550\n",
      "Test Loss: 5.079763889312744\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de076f71",
   "metadata": {},
   "source": [
    "## Question 4: Try to search with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67375265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 Complete [00h 00m 00s]\n",
      "val_loss: 4.916809558868408\n",
      "\n",
      "Best val_loss So Far: 4.614468097686768\n",
      "Total elapsed time: 00h 01m 59s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "{'space': [{'class_name': 'Int', 'config': {'name': 'num_layers', 'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'units_0', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dp_0', 'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.35, 'step': 0.05, 'sampling': None}}, {'class_name': 'Choice', 'config': {'name': 'output_activation', 'default': 'relu', 'conditions': [], 'values': ['relu', 'linear'], 'ordered': False}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}}, {'class_name': 'Int', 'config': {'name': 'units_1', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dp_1', 'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.35, 'step': 0.05, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'units_2', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dp_2', 'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.35, 'step': 0.05, 'sampling': None}}], 'values': {'num_layers': 1, 'units_0': 32, 'dp_0': 0.0, 'output_activation': 'relu', 'learning_rate': 0.01, 'units_1': 64, 'dp_1': 0.05, 'units_2': 96, 'dp_2': 0.15000000000000002, 'tuner/epochs': 40, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}}\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    # Sample different number of layers with hp.Int\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        # Sample different number of layers with hp.Int\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=128,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "        model.add(layers.Dropout(hp.Float('dp_'+ str(i), min_value=0.0,\n",
    "                  max_value=0.35, default=0.0, step=0.05)))\n",
    "    # Sample different activation functions with hp.Choice\n",
    "    model.add(layers.Dense(1, activation=hp.Choice(\n",
    "        'output_activation', ['relu', 'linear'])))\n",
    "\n",
    "    # Sample different activation functions with hp.Choice\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mse',\n",
    "        metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=40,\n",
    "                     factor=2,\n",
    "                     hyperband_iterations=2,\n",
    "                     directory='my_dir_2',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(X_train_norm, y_train, epochs=30, validation_split=0.15,\n",
    "             batch_size=32, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84e3e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.01\n",
      "Best output activation function: relu\n",
      "Best number of hidden layers: 1\n",
      "Number of units of hidden layer 1: 32\n",
      "Dropout rate of hidden layer 1: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
    "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")\n",
    "    print(f\"Dropout rate of hidden layer {i+1}: {best_hps.get('dp_' + str(i))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49b190f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 60.8838 - mae: 6.6510 - val_loss: 7.6267 - val_mae: 1.9638\n",
      "Epoch 2/50\n",
      "89/89 [==============================] - 0s 569us/step - loss: 7.0301 - mae: 1.9075 - val_loss: 5.8181 - val_mae: 1.7007\n",
      "Epoch 3/50\n",
      "89/89 [==============================] - 0s 572us/step - loss: 5.1473 - mae: 1.6586 - val_loss: 5.3265 - val_mae: 1.6706\n",
      "Epoch 4/50\n",
      "89/89 [==============================] - 0s 558us/step - loss: 4.8221 - mae: 1.6070 - val_loss: 5.2979 - val_mae: 1.6691\n",
      "Epoch 5/50\n",
      "89/89 [==============================] - 0s 550us/step - loss: 4.5664 - mae: 1.5756 - val_loss: 4.9102 - val_mae: 1.6307\n",
      "Epoch 6/50\n",
      "89/89 [==============================] - 0s 563us/step - loss: 4.3458 - mae: 1.5429 - val_loss: 5.0245 - val_mae: 1.5550\n",
      "Epoch 7/50\n",
      "89/89 [==============================] - 0s 558us/step - loss: 4.5852 - mae: 1.5691 - val_loss: 4.9345 - val_mae: 1.5500\n",
      "Epoch 8/50\n",
      "89/89 [==============================] - 0s 570us/step - loss: 4.5432 - mae: 1.5586 - val_loss: 4.9490 - val_mae: 1.6263\n",
      "Epoch 9/50\n",
      "89/89 [==============================] - 0s 560us/step - loss: 4.7297 - mae: 1.5921 - val_loss: 4.8216 - val_mae: 1.5407\n",
      "Epoch 10/50\n",
      "89/89 [==============================] - 0s 559us/step - loss: 4.3937 - mae: 1.5390 - val_loss: 4.8382 - val_mae: 1.6155\n",
      "Epoch 11/50\n",
      "89/89 [==============================] - 0s 573us/step - loss: 4.3746 - mae: 1.5418 - val_loss: 4.7110 - val_mae: 1.5545\n",
      "Epoch 12/50\n",
      "89/89 [==============================] - 0s 560us/step - loss: 4.3985 - mae: 1.5410 - val_loss: 4.8321 - val_mae: 1.5701\n",
      "Epoch 13/50\n",
      "89/89 [==============================] - 0s 559us/step - loss: 4.3728 - mae: 1.5375 - val_loss: 4.7337 - val_mae: 1.5951\n",
      "Epoch 14/50\n",
      "89/89 [==============================] - 0s 566us/step - loss: 4.5639 - mae: 1.5621 - val_loss: 4.9881 - val_mae: 1.6340\n",
      "Epoch 15/50\n",
      "89/89 [==============================] - 0s 569us/step - loss: 4.6949 - mae: 1.5807 - val_loss: 4.6493 - val_mae: 1.5407\n",
      "Epoch 16/50\n",
      "89/89 [==============================] - 0s 553us/step - loss: 4.2455 - mae: 1.5142 - val_loss: 4.6894 - val_mae: 1.5560\n",
      "Epoch 17/50\n",
      "89/89 [==============================] - 0s 535us/step - loss: 4.5148 - mae: 1.5509 - val_loss: 4.9409 - val_mae: 1.6912\n",
      "Epoch 18/50\n",
      "89/89 [==============================] - 0s 543us/step - loss: 4.4042 - mae: 1.5265 - val_loss: 4.7164 - val_mae: 1.6175\n",
      "Epoch 19/50\n",
      "89/89 [==============================] - 0s 692us/step - loss: 4.2187 - mae: 1.5077 - val_loss: 4.6343 - val_mae: 1.5414\n",
      "Epoch 20/50\n",
      "89/89 [==============================] - 0s 938us/step - loss: 4.2495 - mae: 1.5066 - val_loss: 4.6303 - val_mae: 1.5423\n",
      "Epoch 21/50\n",
      "89/89 [==============================] - 0s 657us/step - loss: 4.1519 - mae: 1.5065 - val_loss: 4.6596 - val_mae: 1.5551\n",
      "Epoch 22/50\n",
      "89/89 [==============================] - 0s 627us/step - loss: 4.3631 - mae: 1.5084 - val_loss: 4.8650 - val_mae: 1.5852\n",
      "Epoch 23/50\n",
      "89/89 [==============================] - 0s 537us/step - loss: 4.4721 - mae: 1.5449 - val_loss: 4.8445 - val_mae: 1.5535\n",
      "Epoch 24/50\n",
      "89/89 [==============================] - 0s 521us/step - loss: 4.4973 - mae: 1.5243 - val_loss: 4.5947 - val_mae: 1.5591\n",
      "Epoch 25/50\n",
      "89/89 [==============================] - 0s 524us/step - loss: 4.4902 - mae: 1.5507 - val_loss: 4.6285 - val_mae: 1.5673\n",
      "Epoch 26/50\n",
      "89/89 [==============================] - 0s 578us/step - loss: 4.3604 - mae: 1.5392 - val_loss: 4.6445 - val_mae: 1.5663\n",
      "Epoch 27/50\n",
      "89/89 [==============================] - 0s 583us/step - loss: 4.3200 - mae: 1.5178 - val_loss: 5.3012 - val_mae: 1.6125\n",
      "Epoch 28/50\n",
      "89/89 [==============================] - 0s 642us/step - loss: 4.3110 - mae: 1.4987 - val_loss: 4.6489 - val_mae: 1.5909\n",
      "Epoch 29/50\n",
      "89/89 [==============================] - 0s 536us/step - loss: 3.8964 - mae: 1.4523 - val_loss: 4.6594 - val_mae: 1.5690\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "849eb5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 286us/step - loss: 5.2781 - mae: 1.5969\n",
      "Test Loss: 5.278051376342773\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
